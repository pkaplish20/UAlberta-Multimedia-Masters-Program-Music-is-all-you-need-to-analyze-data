{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.tensorboard as tb\n",
    "from Preprocessing.preprocessing_sorted import PreprocessingTrainingData\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as  plt\n",
    "import os\n",
    "import logging\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#static parameters\n",
    "train_batch_size = 30\n",
    "val_batch_size = 30\n",
    "sequence_length=50\n",
    "test_batch_size = 1\n",
    "input_size = 1\n",
    "hidden_size = 256\n",
    "num_layer = 2\n",
    "output_size = 38\n",
    "clip = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from preprocessing.py\n",
    "dataset_path = os.path.join(os.path.abspath('..'),'Dataset\\\\Clementi dataset\\\\Clementi dataset' )\n",
    "network_input,network_output,max_midi_number,min_midi_number,int_to_note = PreprocessingTrainingData().preprocess_notes(dataset_path)\n",
    "network_input, network_output = network_input.cuda(), network_output.cuda()\n",
    "\n",
    "# print(network_input)\n",
    "#print(network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(37, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(network_output.max())\n",
    "print(network_output.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "89\n",
      "50\n",
      "{0: 50, 1: 52, 2: 53, 3: 54, 4: 55, 5: 56, 6: 57, 7: 58, 8: 59, 9: 60, 10: 61, 11: 62, 12: 63, 13: 64, 14: 65, 15: 66, 16: 67, 17: 68, 18: 69, 19: 70, 20: 71, 21: 72, 22: 73, 23: 74, 24: 75, 25: 76, 26: 77, 27: 78, 28: 79, 29: 80, 30: 81, 31: 82, 32: 83, 33: 84, 34: 85, 35: 86, 36: 88, 37: 89}\n"
     ]
    }
   ],
   "source": [
    "print(network_input.max())\n",
    "print(network_input.min())\n",
    "print(max_midi_number)\n",
    "print(min_midi_number)\n",
    "print(int_to_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# data is highly unbalanced\n",
    "# # '''\n",
    "# sns.distplot(torch.tensor(network_output).cpu())\n",
    "# xx = pd.DataFrame(torch.tensor(network_output).cpu())\n",
    "# xx.groupby(0).size().to_frame(name='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1800, 50, 1])\n",
      "torch.Size([1800])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "to make batch of equal sizes\n",
    "Quick Fix\n",
    "'''\n",
    "network_input = network_input[: -29]\n",
    "network_output = network_output[: -29]\n",
    "\n",
    "print(network_input.shape)\n",
    "print(network_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create Stacked LSTM model\n",
    "'''\n",
    "class Stacked_LSTM(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size = input_size, hidden_size = hidden_size, batch_first = True)\n",
    "        self.lstm2 = nn.LSTM(input_size = hidden_size, hidden_size = output_size,batch_first = True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(output_size, output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hidden1, hidden2,batch_size):\n",
    "        \n",
    "        output, _ = self.lstm1(x)        \n",
    "        #print(output.shape)\n",
    "        \n",
    "        #output = self.dropout(output)\n",
    "        \n",
    "        output, _ = self.lstm2(output)\n",
    "        #print(output.shape)\n",
    "        \n",
    "        # stack up lstm outputs\n",
    "        output = output.contiguous().view(-1, 38)\n",
    "        #print(output.shape)\n",
    "        \n",
    "        output = self.dropout(output)\n",
    "        output = self.linear(output)\n",
    "        #print('Linear Output :-',output.shape)\n",
    "        \n",
    "        #output = F.softmax(output, dim = 1)\n",
    "        #print('SOFTMAX OUTPUT :--', output)\n",
    "        \n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        output = output.view(batch_size, -1)\n",
    "        #print('Reshape to batch size first :-',output.shape)\n",
    "        \n",
    "        output = output[:, -self.output_size:] # get last batch of labels\n",
    "        #print('Final Output :-',output)\n",
    "        #print('RESHAPE SIZE :-', output.shape)\n",
    "        \n",
    "        return output, hidden2\n",
    "    \n",
    "    def hidden_init(self,batch_size):\n",
    "        \n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden1 = (weight.new(1, batch_size, self.hidden_size).zero_().cuda(),\n",
    "          weight.new(1, batch_size, self.hidden_size).zero_().cuda())\n",
    "        \n",
    "        hidden2 = (weight.new(1, batch_size, 38).zero_().cuda(),\n",
    "          weight.new(1, batch_size, 38).zero_().cuda())\n",
    "        return hidden1,hidden2\n",
    "\n",
    "#initialize the weights of LSTM using Xavier initialization    \n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Divide the dataset into train/val \n",
    "'''\n",
    "train_size = 0.8\n",
    "indices = list(range(len(network_input)))\n",
    "split = int(np.floor(train_size*len(network_input)))\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "train_sampler = SequentialSampler(train_idx)\n",
    "val_sampler = SequentialSampler(val_idx)\n",
    "\n",
    "dataset = TensorDataset(network_input,network_output)\n",
    "train_loader = DataLoader(dataset, batch_size= train_batch_size, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset, batch_size= val_batch_size,sampler= val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stacked_LSTM(\n",
       "  (lstm1): LSTM(1, 256, batch_first=True)\n",
       "  (lstm2): LSTM(256, 38, batch_first=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=38, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optimizer\n",
    "\n",
    "model = Stacked_LSTM(input_size,hidden_size,num_layer,output_size)\n",
    "model.apply(init_weights)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optimizer.AdamW(model.parameters())\n",
    "#optimizer = optimizer.RMSprop(model.parameters(), lr = 0.001, weight_decay = 0.01)\n",
    "\n",
    "\n",
    "#make sure to transfer model to GPU after initializing optimizer\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden = model.hidden_init(train_batch_size) \n",
    "#hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTrain Loss: 3.6135258 \tVal Loss:3.3890666 \tTrain Acc: 3.472222% \tVal Acc: 2.5000001%\n",
      "Validation Loss decreased from    inf to 3.389067, saving the model weights\n",
      "Epoch: 1\tTrain Loss: 3.4644557 \tVal Loss:3.2165629 \tTrain Acc: 4.375% \tVal Acc: 8.8888892%\n",
      "Validation Loss decreased from 3.389067 to 3.216563, saving the model weights\n",
      "Epoch: 2\tTrain Loss: 3.3983936 \tVal Loss:3.1819957 \tTrain Acc: 5.0% \tVal Acc: 8.8888892%\n",
      "Validation Loss decreased from 3.216563 to 3.181996, saving the model weights\n",
      "Epoch: 3\tTrain Loss: 3.3525703 \tVal Loss:3.1572540 \tTrain Acc: 4.305556% \tVal Acc: 8.8888892%\n",
      "Validation Loss decreased from 3.181996 to 3.157254, saving the model weights\n",
      "Epoch: 4\tTrain Loss: 3.3574908 \tVal Loss:3.1589651 \tTrain Acc: 5.763889% \tVal Acc: 8.8888892%\n",
      "Epoch: 5\tTrain Loss: 3.3464160 \tVal Loss:3.1547901 \tTrain Acc: 4.444445% \tVal Acc: 8.8888892%\n",
      "Validation Loss decreased from 3.157254 to 3.154790, saving the model weights\n",
      "Epoch: 6\tTrain Loss: 3.3464063 \tVal Loss:3.1507978 \tTrain Acc: 4.305556% \tVal Acc: 8.8888892%\n",
      "Validation Loss decreased from 3.154790 to 3.150798, saving the model weights\n",
      "Epoch: 7\tTrain Loss: 3.3431276 \tVal Loss:3.1529211 \tTrain Acc: 4.027778% \tVal Acc: 8.8888892%\n",
      "Epoch: 8\tTrain Loss: 3.3300240 \tVal Loss:3.1516931 \tTrain Acc: 4.305556% \tVal Acc: 8.8888892%\n",
      "Epoch: 9\tTrain Loss: 3.3250522 \tVal Loss:3.1489608 \tTrain Acc: 5.625% \tVal Acc: 8.8888892%\n",
      "Validation Loss decreased from 3.150798 to 3.148961, saving the model weights\n",
      "Epoch: 10\tTrain Loss: 3.3185408 \tVal Loss:3.1462037 \tTrain Acc: 5.208334% \tVal Acc: 8.8888892%\n",
      "Validation Loss decreased from 3.148961 to 3.146204, saving the model weights\n",
      "Epoch: 11\tTrain Loss: 3.3197669 \tVal Loss:3.1449387 \tTrain Acc: 5.555556% \tVal Acc: 8.8888892%\n",
      "Validation Loss decreased from 3.146204 to 3.144939, saving the model weights\n",
      "Epoch: 12\tTrain Loss: 3.3271099 \tVal Loss:3.1487715 \tTrain Acc: 4.722222% \tVal Acc: 8.8888892%\n",
      "Epoch: 13\tTrain Loss: 3.3183501 \tVal Loss:3.1567255 \tTrain Acc: 4.861111% \tVal Acc: 8.8888892%\n",
      "Epoch: 14\tTrain Loss: 3.3087866 \tVal Loss:3.1516838 \tTrain Acc: 5.277778% \tVal Acc: 8.8888892%\n",
      "Epoch: 15\tTrain Loss: 3.3077677 \tVal Loss:3.1479128 \tTrain Acc: 4.930556% \tVal Acc: 8.8888892%\n",
      "Epoch: 16\tTrain Loss: 3.3080563 \tVal Loss:3.1500592 \tTrain Acc: 5.625% \tVal Acc: 8.8888892%\n",
      "Epoch: 17\tTrain Loss: 3.3076082 \tVal Loss:3.1467627 \tTrain Acc: 5.0% \tVal Acc: 8.8888892%\n",
      "Epoch: 18\tTrain Loss: 3.3145133 \tVal Loss:3.1473611 \tTrain Acc: 4.861111% \tVal Acc: 8.8888892%\n",
      "Epoch: 19\tTrain Loss: 3.2993254 \tVal Loss:3.1425605 \tTrain Acc: 6.111111% \tVal Acc: 8.8888892%\n",
      "Validation Loss decreased from 3.144939 to 3.142561, saving the model weights\n",
      "Epoch: 20\tTrain Loss: 3.3031865 \tVal Loss:3.1428521 \tTrain Acc: 4.861111% \tVal Acc: 8.8888892%\n",
      "Epoch: 21\tTrain Loss: 3.2997846 \tVal Loss:3.1403162 \tTrain Acc: 5.138889% \tVal Acc: 8.8888892%\n",
      "Validation Loss decreased from 3.142561 to 3.140316, saving the model weights\n",
      "Epoch: 22\tTrain Loss: 3.3037738 \tVal Loss:3.1417713 \tTrain Acc: 5.833334% \tVal Acc: 8.8888892%\n",
      "Epoch: 23\tTrain Loss: 3.3010630 \tVal Loss:3.1367712 \tTrain Acc: 5.347222% \tVal Acc: 8.8888892%\n",
      "Validation Loss decreased from 3.140316 to 3.136771, saving the model weights\n",
      "Epoch: 24\tTrain Loss: 3.2980565 \tVal Loss:3.1353312 \tTrain Acc: 5.138889% \tVal Acc: 8.8888892%\n",
      "Validation Loss decreased from 3.136771 to 3.135331, saving the model weights\n",
      "Epoch: 25\tTrain Loss: 3.2905656 \tVal Loss:3.1176831 \tTrain Acc: 4.305556% \tVal Acc: 10.0000004%\n",
      "Validation Loss decreased from 3.135331 to 3.117683, saving the model weights\n",
      "Epoch: 26\tTrain Loss: 3.2804575 \tVal Loss:3.1080610 \tTrain Acc: 5.208334% \tVal Acc: 12.5000005%\n",
      "Validation Loss decreased from 3.117683 to 3.108061, saving the model weights\n",
      "Epoch: 27\tTrain Loss: 3.2568586 \tVal Loss:3.1798699 \tTrain Acc: 6.180556% \tVal Acc: 9.4444447%\n",
      "Epoch: 28\tTrain Loss: 3.3682259 \tVal Loss:3.1319407 \tTrain Acc: 4.652778% \tVal Acc: 8.8888892%\n",
      "Epoch: 29\tTrain Loss: 3.3041900 \tVal Loss:3.1494059 \tTrain Acc: 5.625% \tVal Acc: 8.8888892%\n",
      "Epoch: 30\tTrain Loss: 3.2864459 \tVal Loss:3.1528739 \tTrain Acc: 5.416667% \tVal Acc: 8.8888892%\n",
      "Epoch: 31\tTrain Loss: 3.2957167 \tVal Loss:3.1458607 \tTrain Acc: 4.861111% \tVal Acc: 8.8888892%\n",
      "Epoch: 32\tTrain Loss: 3.2872996 \tVal Loss:3.1397938 \tTrain Acc: 5.277778% \tVal Acc: 8.8888892%\n",
      "Epoch: 33\tTrain Loss: 3.2824476 \tVal Loss:3.1320558 \tTrain Acc: 5.0% \tVal Acc: 8.8888892%\n",
      "Epoch: 34\tTrain Loss: 3.2752713 \tVal Loss:3.1125696 \tTrain Acc: 4.791667% \tVal Acc: 8.8888892%\n",
      "Epoch: 35\tTrain Loss: 3.2527863 \tVal Loss:3.1022724 \tTrain Acc: 4.861111% \tVal Acc: 8.8888892%\n",
      "Validation Loss decreased from 3.108061 to 3.102272, saving the model weights\n",
      "Epoch: 36\tTrain Loss: 3.2400253 \tVal Loss:3.0742360 \tTrain Acc: 6.388889% \tVal Acc: 10.0000003%\n",
      "Validation Loss decreased from 3.102272 to 3.074236, saving the model weights\n",
      "Epoch: 37\tTrain Loss: 3.2171682 \tVal Loss:3.0580443 \tTrain Acc: 6.597222% \tVal Acc: 10.0000002%\n",
      "Validation Loss decreased from 3.074236 to 3.058044, saving the model weights\n",
      "Epoch: 38\tTrain Loss: 3.2091927 \tVal Loss:2.9795339 \tTrain Acc: 6.736111% \tVal Acc: 7.7777781%\n",
      "Validation Loss decreased from 3.058044 to 2.979534, saving the model weights\n",
      "Epoch: 39\tTrain Loss: 3.1718728 \tVal Loss:2.9298021 \tTrain Acc: 7.5% \tVal Acc: 10.0000003%\n",
      "Validation Loss decreased from 2.979534 to 2.929802, saving the model weights\n",
      "Epoch: 40\tTrain Loss: 3.1647304 \tVal Loss:2.9238000 \tTrain Acc: 7.5% \tVal Acc: 11.6666670%\n",
      "Validation Loss decreased from 2.929802 to 2.923800, saving the model weights\n",
      "Epoch: 41\tTrain Loss: 3.1437511 \tVal Loss:2.9108014 \tTrain Acc: 8.611111% \tVal Acc: 10.8333338%\n",
      "Validation Loss decreased from 2.923800 to 2.910801, saving the model weights\n",
      "Epoch: 42\tTrain Loss: 3.1099037 \tVal Loss:2.9663764 \tTrain Acc: 7.569445% \tVal Acc: 10.2777782%\n",
      "Epoch: 43\tTrain Loss: 3.0793660 \tVal Loss:3.1011215 \tTrain Acc: 8.888889% \tVal Acc: 8.0555559%\n",
      "Epoch: 44\tTrain Loss: 3.0900073 \tVal Loss:3.2307576 \tTrain Acc: 8.472222% \tVal Acc: 8.8888891%\n",
      "Epoch: 45\tTrain Loss: 3.0843017 \tVal Loss:3.4637403 \tTrain Acc: 7.916667% \tVal Acc: 6.9444447%\n",
      "Epoch: 46\tTrain Loss: 3.1094133 \tVal Loss:3.4249146 \tTrain Acc: 8.75% \tVal Acc: 6.9444447%\n",
      "Epoch: 47\tTrain Loss: 3.1523555 \tVal Loss:3.1039081 \tTrain Acc: 8.194445% \tVal Acc: 6.9444446%\n",
      "Epoch: 48\tTrain Loss: 3.1010457 \tVal Loss:2.9910898 \tTrain Acc: 8.888889% \tVal Acc: 13.8888893%\n",
      "Epoch: 49\tTrain Loss: 3.0734541 \tVal Loss:2.8840550 \tTrain Acc: 9.305556% \tVal Acc: 15.8333338%\n",
      "Validation Loss decreased from 2.910801 to 2.884055, saving the model weights\n",
      "Epoch: 50\tTrain Loss: 3.0107803 \tVal Loss:2.8232005 \tTrain Acc: 10.0% \tVal Acc: 13.0555559%\n",
      "Validation Loss decreased from 2.884055 to 2.823201, saving the model weights\n",
      "Epoch: 51\tTrain Loss: 2.9306833 \tVal Loss:2.8610633 \tTrain Acc: 12.5% \tVal Acc: 8.6111114%\n",
      "Epoch: 52\tTrain Loss: 2.9272250 \tVal Loss:2.8130904 \tTrain Acc: 10.69444% \tVal Acc: 11.1111113%\n",
      "Validation Loss decreased from 2.823201 to 2.813090, saving the model weights\n",
      "Epoch: 53\tTrain Loss: 2.8866450 \tVal Loss:2.7940598 \tTrain Acc: 12.36111% \tVal Acc: 11.6666669%\n",
      "Validation Loss decreased from 2.813090 to 2.794060, saving the model weights\n",
      "Epoch: 54\tTrain Loss: 2.8506427 \tVal Loss:2.7864174 \tTrain Acc: 12.29167% \tVal Acc: 12.7777780%\n",
      "Validation Loss decreased from 2.794060 to 2.786417, saving the model weights\n",
      "Epoch: 55\tTrain Loss: 2.8178594 \tVal Loss:2.8166751 \tTrain Acc: 13.47222% \tVal Acc: 12.2222225%\n",
      "Epoch: 56\tTrain Loss: 2.8176450 \tVal Loss:2.7513937 \tTrain Acc: 12.70833% \tVal Acc: 13.6111114%\n",
      "Validation Loss decreased from 2.786417 to 2.751394, saving the model weights\n",
      "Epoch: 57\tTrain Loss: 2.7841937 \tVal Loss:2.7712229 \tTrain Acc: 12.98611% \tVal Acc: 13.0555559%\n",
      "Epoch: 58\tTrain Loss: 2.7813519 \tVal Loss:2.7487928 \tTrain Acc: 12.01389% \tVal Acc: 12.5000003%\n",
      "Validation Loss decreased from 2.751394 to 2.748793, saving the model weights\n",
      "Epoch: 59\tTrain Loss: 2.7574981 \tVal Loss:2.7512735 \tTrain Acc: 14.86111% \tVal Acc: 13.6111115%\n",
      "Epoch: 60\tTrain Loss: 2.7503974 \tVal Loss:2.6955146 \tTrain Acc: 14.72222% \tVal Acc: 13.6111116%\n",
      "Validation Loss decreased from 2.748793 to 2.695515, saving the model weights\n",
      "Epoch: 61\tTrain Loss: 2.7252259 \tVal Loss:2.6628675 \tTrain Acc: 14.375% \tVal Acc: 14.4444449%\n",
      "Validation Loss decreased from 2.695515 to 2.662868, saving the model weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62\tTrain Loss: 2.7103421 \tVal Loss:2.6292700 \tTrain Acc: 14.44444% \tVal Acc: 14.4444448%\n",
      "Validation Loss decreased from 2.662868 to 2.629270, saving the model weights\n",
      "Epoch: 63\tTrain Loss: 2.6929862 \tVal Loss:2.6300297 \tTrain Acc: 15.20833% \tVal Acc: 15.2777783%\n",
      "Epoch: 64\tTrain Loss: 2.6864750 \tVal Loss:2.6113246 \tTrain Acc: 17.01389% \tVal Acc: 14.1666671%\n",
      "Validation Loss decreased from 2.629270 to 2.611325, saving the model weights\n",
      "Epoch: 65\tTrain Loss: 2.6801782 \tVal Loss:2.5701243 \tTrain Acc: 15.83333% \tVal Acc: 14.4444449%\n",
      "Validation Loss decreased from 2.611325 to 2.570124, saving the model weights\n",
      "Epoch: 66\tTrain Loss: 2.6774459 \tVal Loss:2.5638383 \tTrain Acc: 15.83333% \tVal Acc: 13.6111115%\n",
      "Validation Loss decreased from 2.570124 to 2.563838, saving the model weights\n",
      "Epoch: 67\tTrain Loss: 2.6465983 \tVal Loss:2.5435428 \tTrain Acc: 16.45833% \tVal Acc: 12.7777781%\n",
      "Validation Loss decreased from 2.563838 to 2.543543, saving the model weights\n",
      "Epoch: 68\tTrain Loss: 2.6102305 \tVal Loss:2.5300756 \tTrain Acc: 17.63889% \tVal Acc: 13.3333338%\n",
      "Validation Loss decreased from 2.543543 to 2.530076, saving the model weights\n",
      "Epoch: 69\tTrain Loss: 2.6188081 \tVal Loss:2.5018048 \tTrain Acc: 17.36111% \tVal Acc: 16.1111115%\n",
      "Validation Loss decreased from 2.530076 to 2.501805, saving the model weights\n",
      "Epoch: 70\tTrain Loss: 2.6010240 \tVal Loss:2.4660469 \tTrain Acc: 16.875% \tVal Acc: 17.2222226%\n",
      "Validation Loss decreased from 2.501805 to 2.466047, saving the model weights\n",
      "Epoch: 71\tTrain Loss: 2.5788222 \tVal Loss:2.4572428 \tTrain Acc: 18.95833% \tVal Acc: 19.1666672%\n",
      "Validation Loss decreased from 2.466047 to 2.457243, saving the model weights\n",
      "Epoch: 72\tTrain Loss: 2.5654278 \tVal Loss:2.4409279 \tTrain Acc: 18.47222% \tVal Acc: 19.4444450%\n",
      "Validation Loss decreased from 2.457243 to 2.440928, saving the model weights\n",
      "Epoch: 73\tTrain Loss: 2.5657569 \tVal Loss:2.4276020 \tTrain Acc: 18.47222% \tVal Acc: 17.2222227%\n",
      "Validation Loss decreased from 2.440928 to 2.427602, saving the model weights\n",
      "Epoch: 74\tTrain Loss: 2.5429056 \tVal Loss:2.4282744 \tTrain Acc: 17.91667% \tVal Acc: 18.8888894%\n",
      "Epoch: 75\tTrain Loss: 2.5392253 \tVal Loss:2.4186601 \tTrain Acc: 19.93056% \tVal Acc: 18.6111116%\n",
      "Validation Loss decreased from 2.427602 to 2.418660, saving the model weights\n",
      "Epoch: 76\tTrain Loss: 2.5336909 \tVal Loss:2.3973200 \tTrain Acc: 18.47222% \tVal Acc: 18.8888894%\n",
      "Validation Loss decreased from 2.418660 to 2.397320, saving the model weights\n",
      "Epoch: 77\tTrain Loss: 2.5351517 \tVal Loss:2.3606724 \tTrain Acc: 18.26389% \tVal Acc: 21.6666674%\n",
      "Validation Loss decreased from 2.397320 to 2.360672, saving the model weights\n",
      "Epoch: 78\tTrain Loss: 2.5291375 \tVal Loss:2.3953154 \tTrain Acc: 19.30556% \tVal Acc: 18.6111116%\n",
      "Epoch: 79\tTrain Loss: 2.4971700 \tVal Loss:2.4196108 \tTrain Acc: 20.76389% \tVal Acc: 22.5000006%\n",
      "Epoch: 80\tTrain Loss: 2.5110697 \tVal Loss:2.5183262 \tTrain Acc: 20.34722% \tVal Acc: 17.2222227%\n",
      "Epoch: 81\tTrain Loss: 2.5115372 \tVal Loss:2.5997107 \tTrain Acc: 19.72222% \tVal Acc: 11.6666669%\n",
      "Epoch: 82\tTrain Loss: 2.4909111 \tVal Loss:2.4572955 \tTrain Acc: 21.73611% \tVal Acc: 18.0555562%\n",
      "Epoch: 83\tTrain Loss: 2.4719801 \tVal Loss:2.4853047 \tTrain Acc: 22.98611% \tVal Acc: 17.7777785%\n",
      "Epoch: 84\tTrain Loss: 2.4737428 \tVal Loss:2.4367739 \tTrain Acc: 20.27778% \tVal Acc: 16.3888895%\n",
      "Epoch: 85\tTrain Loss: 2.4507543 \tVal Loss:2.3715686 \tTrain Acc: 22.63889% \tVal Acc: 19.1666672%\n",
      "Epoch: 86\tTrain Loss: 2.4407463 \tVal Loss:2.3702577 \tTrain Acc: 21.875% \tVal Acc: 20.2777785%\n",
      "Epoch: 87\tTrain Loss: 2.4044774 \tVal Loss:2.3222650 \tTrain Acc: 22.91667% \tVal Acc: 20.0000005%\n",
      "Validation Loss decreased from 2.360672 to 2.322265, saving the model weights\n",
      "Epoch: 88\tTrain Loss: 2.4183340 \tVal Loss:2.3875871 \tTrain Acc: 23.54167% \tVal Acc: 18.8888894%\n",
      "Epoch: 89\tTrain Loss: 2.4274159 \tVal Loss:2.3357447 \tTrain Acc: 23.33333% \tVal Acc: 20.2777784%\n",
      "Epoch: 90\tTrain Loss: 2.4061006 \tVal Loss:2.2577401 \tTrain Acc: 23.95833% \tVal Acc: 24.4444453%\n",
      "Validation Loss decreased from 2.322265 to 2.257740, saving the model weights\n",
      "Epoch: 91\tTrain Loss: 2.4028982 \tVal Loss:2.2387915 \tTrain Acc: 23.47222% \tVal Acc: 24.1666673%\n",
      "Validation Loss decreased from 2.257740 to 2.238791, saving the model weights\n",
      "Epoch: 92\tTrain Loss: 2.3891522 \tVal Loss:2.2169109 \tTrain Acc: 23.54167% \tVal Acc: 24.4444450%\n",
      "Validation Loss decreased from 2.238791 to 2.216911, saving the model weights\n",
      "Epoch: 93\tTrain Loss: 2.3483545 \tVal Loss:2.2003156 \tTrain Acc: 24.86111% \tVal Acc: 25.8333340%\n",
      "Validation Loss decreased from 2.216911 to 2.200316, saving the model weights\n",
      "Epoch: 94\tTrain Loss: 2.3563575 \tVal Loss:2.1993268 \tTrain Acc: 25.41667% \tVal Acc: 24.7222228%\n",
      "Validation Loss decreased from 2.200316 to 2.199327, saving the model weights\n",
      "Epoch: 95\tTrain Loss: 2.3672514 \tVal Loss:2.2277531 \tTrain Acc: 25.69445% \tVal Acc: 25.8333339%\n",
      "Epoch: 96\tTrain Loss: 2.3403046 \tVal Loss:2.1745496 \tTrain Acc: 26.11111% \tVal Acc: 23.3333343%\n",
      "Validation Loss decreased from 2.199327 to 2.174550, saving the model weights\n",
      "Epoch: 97\tTrain Loss: 2.3331811 \tVal Loss:2.1668101 \tTrain Acc: 23.88889% \tVal Acc: 25.8333342%\n",
      "Validation Loss decreased from 2.174550 to 2.166810, saving the model weights\n",
      "Epoch: 98\tTrain Loss: 2.2938236 \tVal Loss:2.1510371 \tTrain Acc: 26.18056% \tVal Acc: 31.1111117%\n",
      "Validation Loss decreased from 2.166810 to 2.151037, saving the model weights\n",
      "Epoch: 99\tTrain Loss: 2.3119554 \tVal Loss:2.1499886 \tTrain Acc: 25.83333% \tVal Acc: 28.0555564%\n",
      "Validation Loss decreased from 2.151037 to 2.149989, saving the model weights\n",
      "Epoch: 100\tTrain Loss: 2.2753632 \tVal Loss:2.1268626 \tTrain Acc: 26.875% \tVal Acc: 30.2777786%\n",
      "Validation Loss decreased from 2.149989 to 2.126863, saving the model weights\n",
      "Epoch: 101\tTrain Loss: 2.2528531 \tVal Loss:2.1751208 \tTrain Acc: 27.70833% \tVal Acc: 25.8333340%\n",
      "Epoch: 102\tTrain Loss: 2.2629787 \tVal Loss:2.1077807 \tTrain Acc: 27.08333% \tVal Acc: 30.0000008%\n",
      "Validation Loss decreased from 2.126863 to 2.107781, saving the model weights\n",
      "Epoch: 103\tTrain Loss: 2.2940299 \tVal Loss:2.2374449 \tTrain Acc: 26.66667% \tVal Acc: 21.3888895%\n",
      "Epoch: 104\tTrain Loss: 2.2651627 \tVal Loss:2.2009552 \tTrain Acc: 28.54167% \tVal Acc: 25.0000006%\n",
      "Epoch: 105\tTrain Loss: 2.2688374 \tVal Loss:2.1217716 \tTrain Acc: 27.70833% \tVal Acc: 32.2222228%\n",
      "Epoch: 106\tTrain Loss: 2.2538500 \tVal Loss:2.1246705 \tTrain Acc: 28.40278% \tVal Acc: 33.0555561%\n",
      "Epoch: 107\tTrain Loss: 2.1774302 \tVal Loss:2.1157628 \tTrain Acc: 30.76389% \tVal Acc: 31.9444451%\n",
      "Epoch: 108\tTrain Loss: 2.2028915 \tVal Loss:2.1206586 \tTrain Acc: 29.375% \tVal Acc: 30.8333339%\n",
      "Epoch: 109\tTrain Loss: 2.1850255 \tVal Loss:2.1452469 \tTrain Acc: 28.81945% \tVal Acc: 28.6111117%\n",
      "Epoch: 110\tTrain Loss: 2.1992791 \tVal Loss:2.0569770 \tTrain Acc: 28.40278% \tVal Acc: 36.3888897%\n",
      "Validation Loss decreased from 2.107781 to 2.056977, saving the model weights\n",
      "Epoch: 111\tTrain Loss: 2.1673538 \tVal Loss:1.9978931 \tTrain Acc: 30.34722% \tVal Acc: 31.9444451%\n",
      "Validation Loss decreased from 2.056977 to 1.997893, saving the model weights\n",
      "Epoch: 112\tTrain Loss: 2.1471836 \tVal Loss:1.9631615 \tTrain Acc: 32.08333% \tVal Acc: 35.8333341%\n",
      "Validation Loss decreased from 1.997893 to 1.963162, saving the model weights\n",
      "Epoch: 113\tTrain Loss: 2.1060366 \tVal Loss:1.9195045 \tTrain Acc: 32.98611% \tVal Acc: 38.0555560%\n",
      "Validation Loss decreased from 1.963162 to 1.919504, saving the model weights\n",
      "Epoch: 114\tTrain Loss: 2.0715864 \tVal Loss:1.9994158 \tTrain Acc: 32.56945% \tVal Acc: 36.1111117%\n",
      "Epoch: 115\tTrain Loss: 2.1622478 \tVal Loss:2.0085969 \tTrain Acc: 30.34722% \tVal Acc: 35.2777787%\n",
      "Epoch: 116\tTrain Loss: 2.0963142 \tVal Loss:1.8635855 \tTrain Acc: 34.30556% \tVal Acc: 43.6111120%\n",
      "Validation Loss decreased from 1.919504 to 1.863586, saving the model weights\n",
      "Epoch: 117\tTrain Loss: 2.0250413 \tVal Loss:1.8794272 \tTrain Acc: 36.25% \tVal Acc: 40.0000010%\n",
      "Epoch: 118\tTrain Loss: 2.0153006 \tVal Loss:1.8106658 \tTrain Acc: 35.97222% \tVal Acc: 47.2222234%\n",
      "Validation Loss decreased from 1.863586 to 1.810666, saving the model weights\n",
      "Epoch: 119\tTrain Loss: 1.9623502 \tVal Loss:1.7781568 \tTrain Acc: 39.30556% \tVal Acc: 47.5000011%\n",
      "Validation Loss decreased from 1.810666 to 1.778157, saving the model weights\n",
      "Epoch: 120\tTrain Loss: 1.9586451 \tVal Loss:1.8214116 \tTrain Acc: 38.125% \tVal Acc: 42.7777783%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 121\tTrain Loss: 1.9644642 \tVal Loss:1.7966507 \tTrain Acc: 37.70833% \tVal Acc: 44.4444458%\n",
      "Epoch: 122\tTrain Loss: 1.9558278 \tVal Loss:1.7268575 \tTrain Acc: 37.43056% \tVal Acc: 46.9444450%\n",
      "Validation Loss decreased from 1.778157 to 1.726858, saving the model weights\n",
      "Epoch: 123\tTrain Loss: 1.9055952 \tVal Loss:1.7248940 \tTrain Acc: 40.48611% \tVal Acc: 47.2222229%\n",
      "Validation Loss decreased from 1.726858 to 1.724894, saving the model weights\n",
      "Epoch: 124\tTrain Loss: 1.8640061 \tVal Loss:1.8001494 \tTrain Acc: 41.31945% \tVal Acc: 45.2777782%\n",
      "Epoch: 125\tTrain Loss: 1.8515469 \tVal Loss:1.7737708 \tTrain Acc: 39.79167% \tVal Acc: 45.0000010%\n",
      "Epoch: 126\tTrain Loss: 1.8364293 \tVal Loss:1.6948985 \tTrain Acc: 41.73611% \tVal Acc: 49.7222231%\n",
      "Validation Loss decreased from 1.724894 to 1.694899, saving the model weights\n",
      "Epoch: 127\tTrain Loss: 1.8300293 \tVal Loss:1.6624904 \tTrain Acc: 40.41667% \tVal Acc: 48.0555565%\n",
      "Validation Loss decreased from 1.694899 to 1.662490, saving the model weights\n",
      "Epoch: 128\tTrain Loss: 1.8065183 \tVal Loss:1.7260333 \tTrain Acc: 42.84722% \tVal Acc: 48.0555564%\n",
      "Epoch: 129\tTrain Loss: 1.8712851 \tVal Loss:1.6232110 \tTrain Acc: 41.875% \tVal Acc: 51.6666668%\n",
      "Validation Loss decreased from 1.662490 to 1.623211, saving the model weights\n",
      "Epoch: 130\tTrain Loss: 1.8154124 \tVal Loss:1.6368341 \tTrain Acc: 42.08333% \tVal Acc: 50.5555561%\n",
      "Epoch: 131\tTrain Loss: 1.7810602 \tVal Loss:1.5762657 \tTrain Acc: 45.0% \tVal Acc: 55.5555557%\n",
      "Validation Loss decreased from 1.623211 to 1.576266, saving the model weights\n",
      "Epoch: 132\tTrain Loss: 1.7647799 \tVal Loss:1.5501576 \tTrain Acc: 44.51389% \tVal Acc: 58.3333341%\n",
      "Validation Loss decreased from 1.576266 to 1.550158, saving the model weights\n",
      "Epoch: 133\tTrain Loss: 1.7077363 \tVal Loss:1.5781548 \tTrain Acc: 46.31945% \tVal Acc: 55.5555563%\n",
      "Epoch: 134\tTrain Loss: 1.7008839 \tVal Loss:1.5343013 \tTrain Acc: 46.45833% \tVal Acc: 56.6666678%\n",
      "Validation Loss decreased from 1.550158 to 1.534301, saving the model weights\n",
      "Epoch: 135\tTrain Loss: 1.6713859 \tVal Loss:1.5994659 \tTrain Acc: 47.29167% \tVal Acc: 53.0555564%\n",
      "Epoch: 136\tTrain Loss: 1.6695297 \tVal Loss:1.5836927 \tTrain Acc: 46.25% \tVal Acc: 54.7222234%\n",
      "Epoch: 137\tTrain Loss: 1.6478931 \tVal Loss:1.5236742 \tTrain Acc: 46.59722% \tVal Acc: 57.5000000%\n",
      "Validation Loss decreased from 1.534301 to 1.523674, saving the model weights\n",
      "Epoch: 138\tTrain Loss: 1.6197873 \tVal Loss:1.5716815 \tTrain Acc: 49.86111% \tVal Acc: 52.5000008%\n",
      "Epoch: 139\tTrain Loss: 1.5750283 \tVal Loss:1.6134806 \tTrain Acc: 50.48611% \tVal Acc: 55.5555557%\n",
      "Epoch: 140\tTrain Loss: 1.6373167 \tVal Loss:1.9117328 \tTrain Acc: 49.30556% \tVal Acc: 41.9444453%\n",
      "Epoch: 141\tTrain Loss: 1.6645625 \tVal Loss:1.7241827 \tTrain Acc: 47.77778% \tVal Acc: 46.9444455%\n",
      "Epoch: 142\tTrain Loss: 1.6873685 \tVal Loss:1.8397516 \tTrain Acc: 45.48611% \tVal Acc: 41.6666674%\n",
      "Epoch: 143\tTrain Loss: 1.7569994 \tVal Loss:1.6186714 \tTrain Acc: 44.09722% \tVal Acc: 47.7777789%\n",
      "Epoch: 144\tTrain Loss: 1.6571227 \tVal Loss:1.5953835 \tTrain Acc: 45.97222% \tVal Acc: 51.3888898%\n",
      "Epoch: 145\tTrain Loss: 1.6688823 \tVal Loss:1.4845475 \tTrain Acc: 47.84722% \tVal Acc: 56.3888895%\n",
      "Validation Loss decreased from 1.523674 to 1.484548, saving the model weights\n",
      "Epoch: 146\tTrain Loss: 1.6810657 \tVal Loss:2.0040178 \tTrain Acc: 47.01389% \tVal Acc: 38.0555565%\n",
      "Epoch: 147\tTrain Loss: 1.8367070 \tVal Loss:1.8900382 \tTrain Acc: 42.77778% \tVal Acc: 41.1111120%\n",
      "Epoch: 148\tTrain Loss: 1.8021978 \tVal Loss:1.6811239 \tTrain Acc: 43.33333% \tVal Acc: 50.8333340%\n",
      "Epoch: 149\tTrain Loss: 1.8546552 \tVal Loss:1.5853270 \tTrain Acc: 41.52778% \tVal Acc: 51.3888894%\n",
      "Epoch: 150\tTrain Loss: 1.6631996 \tVal Loss:1.7380903 \tTrain Acc: 46.66667% \tVal Acc: 47.5000005%\n",
      "Epoch: 151\tTrain Loss: 1.7003029 \tVal Loss:2.0977979 \tTrain Acc: 44.86111% \tVal Acc: 38.3333341%\n",
      "Epoch: 152\tTrain Loss: 1.5982622 \tVal Loss:1.6477464 \tTrain Acc: 49.79167% \tVal Acc: 49.7222232%\n",
      "Epoch: 153\tTrain Loss: 1.5987335 \tVal Loss:1.6119201 \tTrain Acc: 49.93056% \tVal Acc: 53.3333339%\n",
      "Epoch: 154\tTrain Loss: 1.5585442 \tVal Loss:1.6704562 \tTrain Acc: 52.15278% \tVal Acc: 49.1666675%\n",
      "Epoch: 155\tTrain Loss: 1.6298161 \tVal Loss:1.5031720 \tTrain Acc: 49.16667% \tVal Acc: 55.0000007%\n",
      "Epoch: 156\tTrain Loss: 1.5954711 \tVal Loss:1.4192468 \tTrain Acc: 50.97222% \tVal Acc: 56.9444455%\n",
      "Validation Loss decreased from 1.484548 to 1.419247, saving the model weights\n",
      "Epoch: 157\tTrain Loss: 1.6117872 \tVal Loss:1.2776548 \tTrain Acc: 50.13889% \tVal Acc: 63.8888900%\n",
      "Validation Loss decreased from 1.419247 to 1.277655, saving the model weights\n",
      "Epoch: 158\tTrain Loss: 1.4780575 \tVal Loss:1.1803163 \tTrain Acc: 54.16667% \tVal Acc: 69.9999993%\n",
      "Validation Loss decreased from 1.277655 to 1.180316, saving the model weights\n",
      "Epoch: 159\tTrain Loss: 1.4129351 \tVal Loss:1.1525234 \tTrain Acc: 56.31944% \tVal Acc: 69.1666670%\n",
      "Validation Loss decreased from 1.180316 to 1.152523, saving the model weights\n",
      "Epoch: 160\tTrain Loss: 1.3512641 \tVal Loss:1.1224079 \tTrain Acc: 58.68056% \tVal Acc: 68.8888888%\n",
      "Validation Loss decreased from 1.152523 to 1.122408, saving the model weights\n",
      "Epoch: 161\tTrain Loss: 1.3062559 \tVal Loss:1.0934555 \tTrain Acc: 61.11111% \tVal Acc: 71.1111113%\n",
      "Validation Loss decreased from 1.122408 to 1.093456, saving the model weights\n",
      "Epoch: 162\tTrain Loss: 1.2723868 \tVal Loss:1.0529146 \tTrain Acc: 60.90278% \tVal Acc: 72.7777782%\n",
      "Validation Loss decreased from 1.093456 to 1.052915, saving the model weights\n",
      "Epoch: 163\tTrain Loss: 1.2226408 \tVal Loss:1.0406971 \tTrain Acc: 63.54167% \tVal Acc: 72.5000001%\n",
      "Validation Loss decreased from 1.052915 to 1.040697, saving the model weights\n",
      "Epoch: 164\tTrain Loss: 1.2473814 \tVal Loss:1.0024142 \tTrain Acc: 63.68056% \tVal Acc: 76.6666681%\n",
      "Validation Loss decreased from 1.040697 to 1.002414, saving the model weights\n",
      "Epoch: 165\tTrain Loss: 1.2054261 \tVal Loss:1.0054297 \tTrain Acc: 63.05556% \tVal Acc: 74.9999998%\n",
      "Epoch: 166\tTrain Loss: 1.1698300 \tVal Loss:0.9581642 \tTrain Acc: 64.51389% \tVal Acc: 78.0555551%\n",
      "Validation Loss decreased from 1.002414 to 0.958164, saving the model weights\n",
      "Epoch: 167\tTrain Loss: 1.1551879 \tVal Loss:0.9639540 \tTrain Acc: 65.13889% \tVal Acc: 78.6111116%\n",
      "Epoch: 168\tTrain Loss: 1.1385674 \tVal Loss:0.9470984 \tTrain Acc: 65.48611% \tVal Acc: 76.9444436%\n",
      "Validation Loss decreased from 0.958164 to 0.947098, saving the model weights\n",
      "Epoch: 169\tTrain Loss: 1.1513975 \tVal Loss:0.9533711 \tTrain Acc: 67.01389% \tVal Acc: 75.0000000%\n",
      "Epoch: 170\tTrain Loss: 1.1252385 \tVal Loss:0.9420654 \tTrain Acc: 65.90278% \tVal Acc: 75.0000007%\n",
      "Validation Loss decreased from 0.947098 to 0.942065, saving the model weights\n",
      "Epoch: 171\tTrain Loss: 1.1585062 \tVal Loss:0.9632209 \tTrain Acc: 65.13889% \tVal Acc: 73.8888895%\n",
      "Epoch: 172\tTrain Loss: 1.1366390 \tVal Loss:0.9167350 \tTrain Acc: 64.58333% \tVal Acc: 75.5555560%\n",
      "Validation Loss decreased from 0.942065 to 0.916735, saving the model weights\n",
      "Epoch: 173\tTrain Loss: 1.0841323 \tVal Loss:0.8745439 \tTrain Acc: 66.66667% \tVal Acc: 78.3333334%\n",
      "Validation Loss decreased from 0.916735 to 0.874544, saving the model weights\n",
      "Epoch: 174\tTrain Loss: 1.0668953 \tVal Loss:0.8306377 \tTrain Acc: 67.29167% \tVal Acc: 78.3333331%\n",
      "Validation Loss decreased from 0.874544 to 0.830638, saving the model weights\n",
      "Epoch: 175\tTrain Loss: 1.0365364 \tVal Loss:0.8719437 \tTrain Acc: 68.26389% \tVal Acc: 77.4999991%\n",
      "Epoch: 176\tTrain Loss: 1.0520632 \tVal Loss:0.8477041 \tTrain Acc: 67.22222% \tVal Acc: 78.3333326%\n",
      "Epoch: 177\tTrain Loss: 0.9879126 \tVal Loss:0.7912793 \tTrain Acc: 70.13889% \tVal Acc: 79.1666667%\n",
      "Validation Loss decreased from 0.830638 to 0.791279, saving the model weights\n",
      "Epoch: 178\tTrain Loss: 1.0204615 \tVal Loss:0.8067035 \tTrain Acc: 67.77778% \tVal Acc: 80.5555545%\n",
      "Epoch: 179\tTrain Loss: 0.9841325 \tVal Loss:0.8184575 \tTrain Acc: 70.97222% \tVal Acc: 77.7777771%\n",
      "Epoch: 180\tTrain Loss: 1.0041119 \tVal Loss:0.7654537 \tTrain Acc: 70.13889% \tVal Acc: 81.3888883%\n",
      "Validation Loss decreased from 0.791279 to 0.765454, saving the model weights\n",
      "Epoch: 181\tTrain Loss: 0.9819824 \tVal Loss:0.7740941 \tTrain Acc: 70.06944% \tVal Acc: 80.2777777%\n",
      "Epoch: 182\tTrain Loss: 0.9496683 \tVal Loss:0.7343574 \tTrain Acc: 72.15278% \tVal Acc: 80.2777772%\n",
      "Validation Loss decreased from 0.765454 to 0.734357, saving the model weights\n",
      "Epoch: 183\tTrain Loss: 0.9042765 \tVal Loss:0.6875650 \tTrain Acc: 74.375% \tVal Acc: 83.3333328%\n",
      "Validation Loss decreased from 0.734357 to 0.687565, saving the model weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 184\tTrain Loss: 0.9086494 \tVal Loss:0.7386254 \tTrain Acc: 72.56944% \tVal Acc: 81.9444438%\n",
      "Epoch: 185\tTrain Loss: 0.9221551 \tVal Loss:0.7135111 \tTrain Acc: 72.22222% \tVal Acc: 84.4444434%\n",
      "Epoch: 186\tTrain Loss: 0.9053691 \tVal Loss:0.6477178 \tTrain Acc: 72.5% \tVal Acc: 86.3888885%\n",
      "Validation Loss decreased from 0.687565 to 0.647718, saving the model weights\n",
      "Epoch: 187\tTrain Loss: 0.8675247 \tVal Loss:0.6656148 \tTrain Acc: 73.95833% \tVal Acc: 86.3888885%\n",
      "Epoch: 188\tTrain Loss: 0.8723393 \tVal Loss:0.6243101 \tTrain Acc: 75.06944% \tVal Acc: 85.2777774%\n",
      "Validation Loss decreased from 0.647718 to 0.624310, saving the model weights\n",
      "Epoch: 189\tTrain Loss: 0.8459058 \tVal Loss:0.6336020 \tTrain Acc: 73.88889% \tVal Acc: 84.1666664%\n",
      "Epoch: 190\tTrain Loss: 0.8387265 \tVal Loss:0.6217835 \tTrain Acc: 75.55556% \tVal Acc: 88.3333315%\n",
      "Validation Loss decreased from 0.624310 to 0.621783, saving the model weights\n",
      "Epoch: 191\tTrain Loss: 0.8412951 \tVal Loss:0.6378441 \tTrain Acc: 74.58333% \tVal Acc: 86.9444440%\n",
      "Epoch: 192\tTrain Loss: 0.8709646 \tVal Loss:0.7046157 \tTrain Acc: 74.375% \tVal Acc: 84.9999989%\n",
      "Epoch: 193\tTrain Loss: 0.8616037 \tVal Loss:0.6433143 \tTrain Acc: 74.58333% \tVal Acc: 86.3888890%\n",
      "Epoch: 194\tTrain Loss: 0.8707638 \tVal Loss:0.5906544 \tTrain Acc: 73.40278% \tVal Acc: 87.4999995%\n",
      "Validation Loss decreased from 0.621783 to 0.590654, saving the model weights\n",
      "Epoch: 195\tTrain Loss: 0.7714320 \tVal Loss:0.6148574 \tTrain Acc: 76.52778% \tVal Acc: 85.5555549%\n",
      "Epoch: 196\tTrain Loss: 0.7838519 \tVal Loss:0.5297557 \tTrain Acc: 76.80556% \tVal Acc: 88.8888876%\n",
      "Validation Loss decreased from 0.590654 to 0.529756, saving the model weights\n",
      "Epoch: 197\tTrain Loss: 0.7606922 \tVal Loss:0.6163989 \tTrain Acc: 77.91667% \tVal Acc: 85.5555554%\n",
      "Epoch: 198\tTrain Loss: 0.8499207 \tVal Loss:0.5499864 \tTrain Acc: 74.23611% \tVal Acc: 88.0555550%\n",
      "Epoch: 199\tTrain Loss: 0.7704092 \tVal Loss:0.5233385 \tTrain Acc: 77.91667% \tVal Acc: 90.5555546%\n",
      "Validation Loss decreased from 0.529756 to 0.523338, saving the model weights\n",
      "Epoch: 200\tTrain Loss: 0.7374843 \tVal Loss:0.5240392 \tTrain Acc: 78.19444% \tVal Acc: 88.0555550%\n",
      "Epoch: 201\tTrain Loss: 0.7332131 \tVal Loss:0.4805968 \tTrain Acc: 78.05556% \tVal Acc: 91.3888887%\n",
      "Validation Loss decreased from 0.523338 to 0.480597, saving the model weights\n",
      "Epoch: 202\tTrain Loss: 0.6847094 \tVal Loss:0.4753343 \tTrain Acc: 80.0% \tVal Acc: 90.8333326%\n",
      "Validation Loss decreased from 0.480597 to 0.475334, saving the model weights\n",
      "Epoch: 203\tTrain Loss: 0.6390361 \tVal Loss:0.4604750 \tTrain Acc: 82.84722% \tVal Acc: 90.5555541%\n",
      "Validation Loss decreased from 0.475334 to 0.460475, saving the model weights\n",
      "Epoch: 204\tTrain Loss: 0.6503190 \tVal Loss:0.4713170 \tTrain Acc: 81.73611% \tVal Acc: 90.8333316%\n",
      "Epoch: 205\tTrain Loss: 0.6370330 \tVal Loss:0.4391341 \tTrain Acc: 82.63889% \tVal Acc: 92.2222212%\n",
      "Validation Loss decreased from 0.460475 to 0.439134, saving the model weights\n",
      "Epoch: 206\tTrain Loss: 0.7132445 \tVal Loss:0.4587663 \tTrain Acc: 79.02778% \tVal Acc: 90.8333321%\n",
      "Epoch: 207\tTrain Loss: 0.7195353 \tVal Loss:0.4407777 \tTrain Acc: 78.88889% \tVal Acc: 92.4999987%\n",
      "Epoch: 208\tTrain Loss: 0.7475342 \tVal Loss:0.4386873 \tTrain Acc: 78.05556% \tVal Acc: 91.6666662%\n",
      "Validation Loss decreased from 0.439134 to 0.438687, saving the model weights\n",
      "Epoch: 209\tTrain Loss: 0.6776994 \tVal Loss:0.3837105 \tTrain Acc: 80.55556% \tVal Acc: 93.6111098%\n",
      "Validation Loss decreased from 0.438687 to 0.383710, saving the model weights\n",
      "Epoch: 210\tTrain Loss: 0.6398482 \tVal Loss:0.3906578 \tTrain Acc: 81.52778% \tVal Acc: 91.6666662%\n",
      "Epoch: 211\tTrain Loss: 0.6225398 \tVal Loss:0.4256695 \tTrain Acc: 81.45833% \tVal Acc: 91.1111102%\n",
      "Epoch: 212\tTrain Loss: 0.6190635 \tVal Loss:0.3712507 \tTrain Acc: 80.55555% \tVal Acc: 93.6111103%\n",
      "Validation Loss decreased from 0.383710 to 0.371251, saving the model weights\n",
      "Epoch: 213\tTrain Loss: 0.5731631 \tVal Loss:0.3244527 \tTrain Acc: 84.79167% \tVal Acc: 96.1111099%\n",
      "Validation Loss decreased from 0.371251 to 0.324453, saving the model weights\n",
      "Epoch: 214\tTrain Loss: 0.5458075 \tVal Loss:0.2999757 \tTrain Acc: 85.41667% \tVal Acc: 95.2777763%\n",
      "Validation Loss decreased from 0.324453 to 0.299976, saving the model weights\n",
      "Epoch: 215\tTrain Loss: 0.5321782 \tVal Loss:0.2966892 \tTrain Acc: 84.44444% \tVal Acc: 96.6666654%\n",
      "Validation Loss decreased from 0.299976 to 0.296689, saving the model weights\n",
      "Epoch: 216\tTrain Loss: 0.4925486 \tVal Loss:0.4091662 \tTrain Acc: 86.73611% \tVal Acc: 92.4999987%\n",
      "Epoch: 217\tTrain Loss: 0.5711443 \tVal Loss:0.3778764 \tTrain Acc: 83.81944% \tVal Acc: 91.3888877%\n",
      "Epoch: 218\tTrain Loss: 0.5308361 \tVal Loss:0.2986070 \tTrain Acc: 85.41667% \tVal Acc: 94.7222208%\n",
      "Epoch: 219\tTrain Loss: 0.5260504 \tVal Loss:0.2783099 \tTrain Acc: 85.13889% \tVal Acc: 96.3888879%\n",
      "Validation Loss decreased from 0.296689 to 0.278310, saving the model weights\n",
      "Epoch: 220\tTrain Loss: 0.4812120 \tVal Loss:0.2477127 \tTrain Acc: 86.66667% \tVal Acc: 96.9444434%\n",
      "Validation Loss decreased from 0.278310 to 0.247713, saving the model weights\n",
      "Epoch: 221\tTrain Loss: 0.4500745 \tVal Loss:0.2500480 \tTrain Acc: 88.88889% \tVal Acc: 96.6666654%\n",
      "Epoch: 222\tTrain Loss: 0.4445273 \tVal Loss:0.2351664 \tTrain Acc: 88.05555% \tVal Acc: 95.5555543%\n",
      "Validation Loss decreased from 0.247713 to 0.235166, saving the model weights\n",
      "Epoch: 223\tTrain Loss: 0.4310981 \tVal Loss:0.2383986 \tTrain Acc: 89.16667% \tVal Acc: 96.3888884%\n",
      "Epoch: 224\tTrain Loss: 0.4349333 \tVal Loss:0.2328877 \tTrain Acc: 89.02778% \tVal Acc: 96.1111099%\n",
      "Validation Loss decreased from 0.235166 to 0.232888, saving the model weights\n",
      "Epoch: 225\tTrain Loss: 0.4663289 \tVal Loss:0.2343599 \tTrain Acc: 87.08333% \tVal Acc: 95.5555543%\n",
      "Epoch: 226\tTrain Loss: 0.4898255 \tVal Loss:0.2812978 \tTrain Acc: 85.76389% \tVal Acc: 94.1666653%\n",
      "Epoch: 227\tTrain Loss: 0.5157215 \tVal Loss:0.3339211 \tTrain Acc: 85.48611% \tVal Acc: 92.4999992%\n",
      "Epoch: 228\tTrain Loss: 0.5232661 \tVal Loss:0.2498104 \tTrain Acc: 84.72222% \tVal Acc: 94.1666653%\n",
      "Epoch: 229\tTrain Loss: 0.4783886 \tVal Loss:0.2167373 \tTrain Acc: 86.04167% \tVal Acc: 96.9444439%\n",
      "Validation Loss decreased from 0.232888 to 0.216737, saving the model weights\n",
      "Epoch: 230\tTrain Loss: 0.4607509 \tVal Loss:0.2072914 \tTrain Acc: 87.36111% \tVal Acc: 96.9444434%\n",
      "Validation Loss decreased from 0.216737 to 0.207291, saving the model weights\n",
      "Epoch: 231\tTrain Loss: 0.4680243 \tVal Loss:0.2716344 \tTrain Acc: 86.80556% \tVal Acc: 92.7777772%\n",
      "Epoch: 232\tTrain Loss: 0.5095618 \tVal Loss:0.2083906 \tTrain Acc: 86.11111% \tVal Acc: 96.6666659%\n",
      "Epoch: 233\tTrain Loss: 0.4045592 \tVal Loss:0.2020343 \tTrain Acc: 89.58333% \tVal Acc: 96.6666654%\n",
      "Validation Loss decreased from 0.207291 to 0.202034, saving the model weights\n",
      "Epoch: 234\tTrain Loss: 0.4081325 \tVal Loss:0.1829579 \tTrain Acc: 88.88889% \tVal Acc: 98.3333324%\n",
      "Validation Loss decreased from 0.202034 to 0.182958, saving the model weights\n",
      "Epoch: 235\tTrain Loss: 0.3964788 \tVal Loss:0.2303957 \tTrain Acc: 88.61111% \tVal Acc: 96.3888879%\n",
      "Epoch: 236\tTrain Loss: 0.4301109 \tVal Loss:0.1921327 \tTrain Acc: 87.63889% \tVal Acc: 97.7777774%\n",
      "Epoch: 237\tTrain Loss: 0.3783507 \tVal Loss:0.1696204 \tTrain Acc: 91.04167% \tVal Acc: 97.7777769%\n",
      "Validation Loss decreased from 0.182958 to 0.169620, saving the model weights\n",
      "Epoch: 238\tTrain Loss: 0.3681033 \tVal Loss:0.2098869 \tTrain Acc: 90.41667% \tVal Acc: 96.6666664%\n",
      "Epoch: 239\tTrain Loss: 0.3281385 \tVal Loss:0.1819762 \tTrain Acc: 92.56944% \tVal Acc: 97.2222214%\n",
      "Epoch: 240\tTrain Loss: 0.3253019 \tVal Loss:0.1405688 \tTrain Acc: 91.45833% \tVal Acc: 97.4999989%\n",
      "Validation Loss decreased from 0.169620 to 0.140569, saving the model weights\n",
      "Epoch: 241\tTrain Loss: 0.3000271 \tVal Loss:0.1336563 \tTrain Acc: 92.5% \tVal Acc: 98.8888880%\n",
      "Validation Loss decreased from 0.140569 to 0.133656, saving the model weights\n",
      "Epoch: 242\tTrain Loss: 0.2980033 \tVal Loss:0.1434365 \tTrain Acc: 92.15278% \tVal Acc: 98.6111104%\n",
      "Epoch: 243\tTrain Loss: 0.3471427 \tVal Loss:0.1598969 \tTrain Acc: 91.59722% \tVal Acc: 96.9444434%\n",
      "Epoch: 244\tTrain Loss: 0.3845320 \tVal Loss:0.1846175 \tTrain Acc: 90.41667% \tVal Acc: 95.8333318%\n",
      "Epoch: 245\tTrain Loss: 0.4290522 \tVal Loss:0.1766529 \tTrain Acc: 88.54167% \tVal Acc: 96.1111099%\n",
      "Epoch: 246\tTrain Loss: 0.4019630 \tVal Loss:0.2239237 \tTrain Acc: 88.33333% \tVal Acc: 94.7222213%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 247\tTrain Loss: 1.2498454 \tVal Loss:0.9882799 \tTrain Acc: 63.47222% \tVal Acc: 73.8888887%\n",
      "Epoch: 248\tTrain Loss: 1.0910316 \tVal Loss:0.8004567 \tTrain Acc: 67.56944% \tVal Acc: 75.0000005%\n",
      "Epoch: 249\tTrain Loss: 0.8591747 \tVal Loss:0.5122807 \tTrain Acc: 73.75% \tVal Acc: 86.9444440%\n",
      "Epoch: 250\tTrain Loss: 0.5738717 \tVal Loss:0.2516809 \tTrain Acc: 83.54167% \tVal Acc: 93.0555542%\n",
      "Epoch: 251\tTrain Loss: 0.5170367 \tVal Loss:0.2267343 \tTrain Acc: 84.02778% \tVal Acc: 93.0555537%\n",
      "Epoch: 252\tTrain Loss: 0.4459616 \tVal Loss:0.1807300 \tTrain Acc: 86.04167% \tVal Acc: 96.6666659%\n",
      "Epoch: 253\tTrain Loss: 0.3778739 \tVal Loss:0.1740196 \tTrain Acc: 90.13889% \tVal Acc: 95.8333328%\n",
      "Epoch: 254\tTrain Loss: 0.3328993 \tVal Loss:0.1342395 \tTrain Acc: 90.55555% \tVal Acc: 97.2222214%\n",
      "Epoch: 255\tTrain Loss: 0.3023036 \tVal Loss:0.1100277 \tTrain Acc: 92.01389% \tVal Acc: 98.6111100%\n",
      "Validation Loss decreased from 0.133656 to 0.110028, saving the model weights\n",
      "Epoch: 256\tTrain Loss: 0.2802938 \tVal Loss:0.1080169 \tTrain Acc: 93.47222% \tVal Acc: 98.6111104%\n",
      "Validation Loss decreased from 0.110028 to 0.108017, saving the model weights\n",
      "Epoch: 257\tTrain Loss: 0.2884261 \tVal Loss:0.0986842 \tTrain Acc: 92.98611% \tVal Acc: 98.3333319%\n",
      "Validation Loss decreased from 0.108017 to 0.098684, saving the model weights\n",
      "Epoch: 258\tTrain Loss: 0.2541304 \tVal Loss:0.0926512 \tTrain Acc: 94.65278% \tVal Acc: 98.3333319%\n",
      "Validation Loss decreased from 0.098684 to 0.092651, saving the model weights\n",
      "Epoch: 259\tTrain Loss: 0.2341424 \tVal Loss:0.0862434 \tTrain Acc: 94.58333% \tVal Acc: 98.6111100%\n",
      "Validation Loss decreased from 0.092651 to 0.086243, saving the model weights\n",
      "Epoch: 260\tTrain Loss: 0.2236900 \tVal Loss:0.0978820 \tTrain Acc: 95.41667% \tVal Acc: 97.7777764%\n",
      "Epoch: 261\tTrain Loss: 0.2268525 \tVal Loss:0.1072805 \tTrain Acc: 94.93055% \tVal Acc: 96.9444439%\n",
      "Epoch: 262\tTrain Loss: 0.2276171 \tVal Loss:0.0942372 \tTrain Acc: 95.41667% \tVal Acc: 98.3333319%\n",
      "Epoch: 263\tTrain Loss: 0.2207274 \tVal Loss:0.1409071 \tTrain Acc: 95.34722% \tVal Acc: 96.6666659%\n",
      "Epoch: 264\tTrain Loss: 0.2565221 \tVal Loss:0.0820404 \tTrain Acc: 93.19444% \tVal Acc: 98.3333324%\n",
      "Validation Loss decreased from 0.086243 to 0.082040, saving the model weights\n",
      "Epoch: 265\tTrain Loss: 0.2131525 \tVal Loss:0.0754004 \tTrain Acc: 95.34722% \tVal Acc: 98.8888880%\n",
      "Validation Loss decreased from 0.082040 to 0.075400, saving the model weights\n",
      "Epoch: 266\tTrain Loss: 0.2010902 \tVal Loss:0.0901590 \tTrain Acc: 95.41667% \tVal Acc: 97.7777774%\n",
      "Epoch: 267\tTrain Loss: 0.2016688 \tVal Loss:0.0972161 \tTrain Acc: 95.76389% \tVal Acc: 97.7777769%\n",
      "Epoch: 268\tTrain Loss: 0.2014216 \tVal Loss:0.0694827 \tTrain Acc: 95.90278% \tVal Acc: 98.6111100%\n",
      "Validation Loss decreased from 0.075400 to 0.069483, saving the model weights\n",
      "Epoch: 269\tTrain Loss: 0.1848369 \tVal Loss:0.0687745 \tTrain Acc: 96.18055% \tVal Acc: 98.8888885%\n",
      "Validation Loss decreased from 0.069483 to 0.068774, saving the model weights\n",
      "Epoch: 270\tTrain Loss: 0.2074545 \tVal Loss:0.0801578 \tTrain Acc: 94.93055% \tVal Acc: 97.7777774%\n",
      "Epoch: 271\tTrain Loss: 0.2215658 \tVal Loss:0.1227686 \tTrain Acc: 94.93055% \tVal Acc: 97.2222214%\n",
      "Epoch: 272\tTrain Loss: 0.2165028 \tVal Loss:0.1051662 \tTrain Acc: 94.16667% \tVal Acc: 97.7777769%\n",
      "Epoch: 273\tTrain Loss: 0.2154502 \tVal Loss:0.0655251 \tTrain Acc: 94.65278% \tVal Acc: 98.6111104%\n",
      "Validation Loss decreased from 0.068774 to 0.065525, saving the model weights\n",
      "Epoch: 274\tTrain Loss: 0.2082210 \tVal Loss:0.0615699 \tTrain Acc: 95.13889% \tVal Acc: 98.8888880%\n",
      "Validation Loss decreased from 0.065525 to 0.061570, saving the model weights\n",
      "Epoch: 275\tTrain Loss: 0.1865936 \tVal Loss:0.0613482 \tTrain Acc: 95.69444% \tVal Acc: 98.8888885%\n",
      "Validation Loss decreased from 0.061570 to 0.061348, saving the model weights\n",
      "Epoch: 276\tTrain Loss: 0.1762619 \tVal Loss:0.0595438 \tTrain Acc: 95.48611% \tVal Acc: 98.6111104%\n",
      "Validation Loss decreased from 0.061348 to 0.059544, saving the model weights\n",
      "Epoch: 277\tTrain Loss: 0.1660514 \tVal Loss:0.0683665 \tTrain Acc: 97.01389% \tVal Acc: 98.0555539%\n",
      "Epoch: 278\tTrain Loss: 0.1853213 \tVal Loss:0.0611474 \tTrain Acc: 95.625% \tVal Acc: 98.8888880%\n",
      "Epoch: 279\tTrain Loss: 0.1955856 \tVal Loss:0.0575945 \tTrain Acc: 95.48611% \tVal Acc: 99.1666660%\n",
      "Validation Loss decreased from 0.059544 to 0.057595, saving the model weights\n",
      "Epoch: 280\tTrain Loss: 0.2355622 \tVal Loss:0.0874579 \tTrain Acc: 94.02778% \tVal Acc: 97.2222214%\n",
      "Epoch: 281\tTrain Loss: 0.4856826 \tVal Loss:0.2583467 \tTrain Acc: 85.69444% \tVal Acc: 90.5555546%\n",
      "Epoch: 282\tTrain Loss: 0.5336981 \tVal Loss:0.4204181 \tTrain Acc: 83.68056% \tVal Acc: 89.4444436%\n",
      "Epoch: 283\tTrain Loss: 0.7004352 \tVal Loss:0.2695847 \tTrain Acc: 80.55555% \tVal Acc: 92.7777767%\n",
      "Epoch: 284\tTrain Loss: 0.5046127 \tVal Loss:0.1859221 \tTrain Acc: 84.23611% \tVal Acc: 95.8333323%\n",
      "Epoch: 285\tTrain Loss: 0.3148219 \tVal Loss:0.0922072 \tTrain Acc: 90.83333% \tVal Acc: 97.4999989%\n",
      "Epoch: 286\tTrain Loss: 0.2283281 \tVal Loss:0.0649988 \tTrain Acc: 94.44444% \tVal Acc: 98.8888880%\n",
      "Epoch: 287\tTrain Loss: 0.1742498 \tVal Loss:0.0581484 \tTrain Acc: 96.31944% \tVal Acc: 98.8888890%\n",
      "Epoch: 288\tTrain Loss: 0.1760917 \tVal Loss:0.0526076 \tTrain Acc: 96.45833% \tVal Acc: 99.4444445%\n",
      "Validation Loss decreased from 0.057595 to 0.052608, saving the model weights\n",
      "Epoch: 289\tTrain Loss: 0.1703492 \tVal Loss:0.0471117 \tTrain Acc: 95.90278% \tVal Acc: 99.4444445%\n",
      "Validation Loss decreased from 0.052608 to 0.047112, saving the model weights\n",
      "Epoch: 290\tTrain Loss: 0.1594488 \tVal Loss:0.0438688 \tTrain Acc: 96.94444% \tVal Acc: 99.4444445%\n",
      "Validation Loss decreased from 0.047112 to 0.043869, saving the model weights\n",
      "Epoch: 291\tTrain Loss: 0.1535167 \tVal Loss:0.0430247 \tTrain Acc: 96.94444% \tVal Acc: 99.4444445%\n",
      "Validation Loss decreased from 0.043869 to 0.043025, saving the model weights\n",
      "Epoch: 292\tTrain Loss: 0.1426012 \tVal Loss:0.0394616 \tTrain Acc: 97.15278% \tVal Acc: 99.4444440%\n",
      "Validation Loss decreased from 0.043025 to 0.039462, saving the model weights\n",
      "Epoch: 293\tTrain Loss: 0.1514301 \tVal Loss:0.0397528 \tTrain Acc: 96.80555% \tVal Acc: 99.4444440%\n",
      "Epoch: 294\tTrain Loss: 0.1305926 \tVal Loss:0.0395188 \tTrain Acc: 97.77778% \tVal Acc: 99.4444445%\n",
      "Epoch: 295\tTrain Loss: 0.1312629 \tVal Loss:0.0416293 \tTrain Acc: 97.5% \tVal Acc: 99.4444440%\n",
      "Epoch: 296\tTrain Loss: 0.1251097 \tVal Loss:0.0380526 \tTrain Acc: 97.63889% \tVal Acc: 99.4444445%\n",
      "Validation Loss decreased from 0.039462 to 0.038053, saving the model weights\n",
      "Epoch: 297\tTrain Loss: 0.1119494 \tVal Loss:0.0349327 \tTrain Acc: 98.05555% \tVal Acc: 99.4444440%\n",
      "Validation Loss decreased from 0.038053 to 0.034933, saving the model weights\n",
      "Epoch: 298\tTrain Loss: 0.1234434 \tVal Loss:0.0383246 \tTrain Acc: 97.5% \tVal Acc: 99.4444440%\n",
      "Epoch: 299\tTrain Loss: 0.1210952 \tVal Loss:0.0408015 \tTrain Acc: 97.56944% \tVal Acc: 99.4444440%\n",
      "Epoch: 300\tTrain Loss: 0.1235049 \tVal Loss:0.0353445 \tTrain Acc: 97.63889% \tVal Acc: 99.4444440%\n",
      "Epoch: 301\tTrain Loss: 0.1241103 \tVal Loss:0.0380200 \tTrain Acc: 97.22222% \tVal Acc: 99.1666665%\n",
      "Epoch: 302\tTrain Loss: 0.1300476 \tVal Loss:0.0395083 \tTrain Acc: 97.08333% \tVal Acc: 98.8888890%\n",
      "Epoch: 303\tTrain Loss: 0.1380810 \tVal Loss:0.1426100 \tTrain Acc: 97.36111% \tVal Acc: 95.8333323%\n",
      "Epoch: 304\tTrain Loss: 0.2158442 \tVal Loss:0.1966253 \tTrain Acc: 94.375% \tVal Acc: 95.2777768%\n",
      "Epoch: 305\tTrain Loss: 0.3905897 \tVal Loss:0.2662715 \tTrain Acc: 89.375% \tVal Acc: 93.3333322%\n",
      "Epoch: 306\tTrain Loss: 0.3774463 \tVal Loss:0.2278966 \tTrain Acc: 88.61111% \tVal Acc: 94.7222218%\n",
      "Epoch: 307\tTrain Loss: 0.3091533 \tVal Loss:0.1255311 \tTrain Acc: 91.80555% \tVal Acc: 96.9444439%\n",
      "Epoch: 308\tTrain Loss: 0.2450331 \tVal Loss:0.0779198 \tTrain Acc: 93.05555% \tVal Acc: 97.2222214%\n",
      "Epoch: 309\tTrain Loss: 0.1969526 \tVal Loss:0.0464707 \tTrain Acc: 94.72222% \tVal Acc: 99.4444440%\n",
      "Epoch: 310\tTrain Loss: 0.1429687 \tVal Loss:0.0405489 \tTrain Acc: 97.01389% \tVal Acc: 99.4444445%\n",
      "Epoch: 311\tTrain Loss: 0.1382986 \tVal Loss:0.0423582 \tTrain Acc: 97.01389% \tVal Acc: 99.1666660%\n",
      "Epoch: 312\tTrain Loss: 0.1342825 \tVal Loss:0.0435516 \tTrain Acc: 97.08333% \tVal Acc: 98.6111109%\n",
      "Epoch: 313\tTrain Loss: 0.1241545 \tVal Loss:0.0843305 \tTrain Acc: 97.77778% \tVal Acc: 97.2222224%\n",
      "Epoch: 314\tTrain Loss: 0.1749800 \tVal Loss:0.1342479 \tTrain Acc: 95.69444% \tVal Acc: 96.3888884%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 315\tTrain Loss: 0.1947793 \tVal Loss:0.1477610 \tTrain Acc: 96.04167% \tVal Acc: 95.8333328%\n",
      "Epoch: 316\tTrain Loss: 0.1669667 \tVal Loss:0.0666374 \tTrain Acc: 96.11111% \tVal Acc: 98.3333329%\n",
      "Epoch: 317\tTrain Loss: 0.1592778 \tVal Loss:0.0571658 \tTrain Acc: 96.04167% \tVal Acc: 98.0555544%\n",
      "Epoch: 318\tTrain Loss: 0.1619946 \tVal Loss:0.0527016 \tTrain Acc: 95.55555% \tVal Acc: 97.7777774%\n",
      "Epoch: 319\tTrain Loss: 0.1808147 \tVal Loss:0.0480860 \tTrain Acc: 95.0% \tVal Acc: 98.8888885%\n",
      "Epoch: 320\tTrain Loss: 0.2145300 \tVal Loss:0.0599384 \tTrain Acc: 94.30555% \tVal Acc: 98.6111104%\n",
      "Epoch: 321\tTrain Loss: 0.1795963 \tVal Loss:0.0384059 \tTrain Acc: 95.20833% \tVal Acc: 99.1666660%\n",
      "Epoch: 322\tTrain Loss: 0.1363067 \tVal Loss:0.0357381 \tTrain Acc: 97.08333% \tVal Acc: 99.1666665%\n",
      "Epoch: 323\tTrain Loss: 0.1232877 \tVal Loss:0.0343166 \tTrain Acc: 97.5% \tVal Acc: 98.8888890%\n",
      "Validation Loss decreased from 0.034933 to 0.034317, saving the model weights\n",
      "Epoch: 324\tTrain Loss: 0.1026344 \tVal Loss:0.0358769 \tTrain Acc: 97.84722% \tVal Acc: 98.6111109%\n",
      "Epoch: 325\tTrain Loss: 0.1018905 \tVal Loss:0.0283290 \tTrain Acc: 98.05556% \tVal Acc: 99.1666665%\n",
      "Validation Loss decreased from 0.034317 to 0.028329, saving the model weights\n",
      "Epoch: 326\tTrain Loss: 0.1031511 \tVal Loss:0.0245759 \tTrain Acc: 98.05555% \tVal Acc: 99.7222220%\n",
      "Validation Loss decreased from 0.028329 to 0.024576, saving the model weights\n",
      "Epoch: 327\tTrain Loss: 0.0896913 \tVal Loss:0.0259000 \tTrain Acc: 98.54167% \tVal Acc: 99.1666665%\n",
      "Epoch: 328\tTrain Loss: 0.0858706 \tVal Loss:0.0251572 \tTrain Acc: 98.54167% \tVal Acc: 99.1666665%\n",
      "Epoch: 329\tTrain Loss: 0.0925346 \tVal Loss:0.0237865 \tTrain Acc: 98.40278% \tVal Acc: 99.4444445%\n",
      "Validation Loss decreased from 0.024576 to 0.023787, saving the model weights\n",
      "Epoch: 330\tTrain Loss: 0.0897951 \tVal Loss:0.0229748 \tTrain Acc: 97.98611% \tVal Acc: 99.4444445%\n",
      "Validation Loss decreased from 0.023787 to 0.022975, saving the model weights\n",
      "Epoch: 331\tTrain Loss: 0.0868979 \tVal Loss:0.0227194 \tTrain Acc: 98.125% \tVal Acc: 99.4444440%\n",
      "Validation Loss decreased from 0.022975 to 0.022719, saving the model weights\n",
      "Epoch: 332\tTrain Loss: 0.0871328 \tVal Loss:0.0332185 \tTrain Acc: 98.61111% \tVal Acc: 98.6111104%\n",
      "Epoch: 333\tTrain Loss: 0.0990098 \tVal Loss:0.0261773 \tTrain Acc: 97.63889% \tVal Acc: 99.4444440%\n",
      "Epoch: 334\tTrain Loss: 0.0964042 \tVal Loss:0.0515893 \tTrain Acc: 98.125% \tVal Acc: 98.0555549%\n",
      "Epoch: 335\tTrain Loss: 0.1237411 \tVal Loss:0.0737232 \tTrain Acc: 96.94444% \tVal Acc: 97.7777774%\n",
      "Epoch: 336\tTrain Loss: 0.1364367 \tVal Loss:0.0584923 \tTrain Acc: 96.31944% \tVal Acc: 98.3333334%\n",
      "Epoch: 337\tTrain Loss: 0.1582560 \tVal Loss:0.0314922 \tTrain Acc: 96.45833% \tVal Acc: 99.4444440%\n",
      "Epoch: 338\tTrain Loss: 0.1595148 \tVal Loss:0.0537525 \tTrain Acc: 95.83333% \tVal Acc: 98.3333329%\n",
      "Epoch: 339\tTrain Loss: 0.1390430 \tVal Loss:0.0769447 \tTrain Acc: 96.11111% \tVal Acc: 97.7777774%\n",
      "Epoch: 340\tTrain Loss: 0.1353908 \tVal Loss:0.0308283 \tTrain Acc: 96.80555% \tVal Acc: 99.1666665%\n",
      "Epoch: 341\tTrain Loss: 0.1757993 \tVal Loss:0.1253415 \tTrain Acc: 95.48611% \tVal Acc: 94.7222218%\n",
      "Epoch: 342\tTrain Loss: 0.8209407 \tVal Loss:1.0365392 \tTrain Acc: 78.125% \tVal Acc: 73.6111104%\n",
      "Epoch: 343\tTrain Loss: 1.6607687 \tVal Loss:0.9880487 \tTrain Acc: 57.56944% \tVal Acc: 71.3888884%\n",
      "Epoch: 344\tTrain Loss: 1.5485972 \tVal Loss:1.1644614 \tTrain Acc: 59.09722% \tVal Acc: 67.5000009%\n",
      "Epoch: 345\tTrain Loss: 1.0895115 \tVal Loss:0.3232704 \tTrain Acc: 67.77778% \tVal Acc: 90.5555551%\n",
      "Epoch: 346\tTrain Loss: 0.4826200 \tVal Loss:0.0870193 \tTrain Acc: 84.86111% \tVal Acc: 98.3333329%\n",
      "Epoch: 347\tTrain Loss: 0.3206854 \tVal Loss:0.0472885 \tTrain Acc: 91.38889% \tVal Acc: 99.4444445%\n",
      "Epoch: 348\tTrain Loss: 0.2051248 \tVal Loss:0.0452844 \tTrain Acc: 95.27778% \tVal Acc: 98.8888890%\n",
      "Epoch: 349\tTrain Loss: 0.1607996 \tVal Loss:0.0342781 \tTrain Acc: 96.66667% \tVal Acc: 99.4444440%\n",
      "Epoch: 350\tTrain Loss: 0.1332787 \tVal Loss:0.0308158 \tTrain Acc: 97.84722% \tVal Acc: 99.4444440%\n",
      "Epoch: 351\tTrain Loss: 0.1162213 \tVal Loss:0.0289631 \tTrain Acc: 97.63889% \tVal Acc: 99.4444440%\n",
      "Epoch: 352\tTrain Loss: 0.1229597 \tVal Loss:0.0271463 \tTrain Acc: 97.43055% \tVal Acc: 99.4444440%\n",
      "Epoch: 353\tTrain Loss: 0.1098857 \tVal Loss:0.0256821 \tTrain Acc: 97.98611% \tVal Acc: 99.7222220%\n",
      "Epoch: 354\tTrain Loss: 0.1085883 \tVal Loss:0.0247788 \tTrain Acc: 98.05555% \tVal Acc: 99.4444440%\n",
      "Epoch: 355\tTrain Loss: 0.0969769 \tVal Loss:0.0256630 \tTrain Acc: 98.40278% \tVal Acc: 99.1666665%\n",
      "Epoch: 356\tTrain Loss: 0.0896810 \tVal Loss:0.0241778 \tTrain Acc: 98.54167% \tVal Acc: 99.4444440%\n",
      "Epoch: 357\tTrain Loss: 0.0970845 \tVal Loss:0.0220867 \tTrain Acc: 98.26389% \tVal Acc: 99.7222220%\n",
      "Validation Loss decreased from 0.022719 to 0.022087, saving the model weights\n",
      "Epoch: 358\tTrain Loss: 0.0927902 \tVal Loss:0.0222442 \tTrain Acc: 98.54167% \tVal Acc: 99.4444445%\n",
      "Epoch: 359\tTrain Loss: 0.0929541 \tVal Loss:0.0218723 \tTrain Acc: 98.47222% \tVal Acc: 99.1666665%\n",
      "Validation Loss decreased from 0.022087 to 0.021872, saving the model weights\n",
      "Epoch: 360\tTrain Loss: 0.0916880 \tVal Loss:0.0228537 \tTrain Acc: 98.61111% \tVal Acc: 99.4444440%\n",
      "Epoch: 361\tTrain Loss: 0.0930330 \tVal Loss:0.0268150 \tTrain Acc: 98.125% \tVal Acc: 99.1666665%\n",
      "Epoch: 362\tTrain Loss: 0.0894372 \tVal Loss:0.0202893 \tTrain Acc: 97.70833% \tVal Acc: 99.4444445%\n",
      "Validation Loss decreased from 0.021872 to 0.020289, saving the model weights\n",
      "Epoch: 363\tTrain Loss: 0.0793922 \tVal Loss:0.0193868 \tTrain Acc: 98.33333% \tVal Acc: 99.4444445%\n",
      "Validation Loss decreased from 0.020289 to 0.019387, saving the model weights\n",
      "Epoch: 364\tTrain Loss: 0.0845262 \tVal Loss:0.0198322 \tTrain Acc: 98.26389% \tVal Acc: 99.4444440%\n",
      "Epoch: 365\tTrain Loss: 0.0794260 \tVal Loss:0.0264665 \tTrain Acc: 98.68056% \tVal Acc: 99.1666665%\n",
      "Epoch: 366\tTrain Loss: 0.0913826 \tVal Loss:0.0873636 \tTrain Acc: 98.05555% \tVal Acc: 97.4999999%\n",
      "Epoch: 367\tTrain Loss: 0.1455232 \tVal Loss:0.1485011 \tTrain Acc: 96.11111% \tVal Acc: 96.9444439%\n",
      "Epoch: 368\tTrain Loss: 0.1368977 \tVal Loss:0.1092108 \tTrain Acc: 97.29167% \tVal Acc: 96.3888889%\n",
      "Epoch: 369\tTrain Loss: 0.1205463 \tVal Loss:0.0959421 \tTrain Acc: 97.08333% \tVal Acc: 96.9444444%\n",
      "Epoch: 370\tTrain Loss: 0.1119029 \tVal Loss:0.0529671 \tTrain Acc: 97.29167% \tVal Acc: 97.4999999%\n",
      "Epoch: 371\tTrain Loss: 0.0897838 \tVal Loss:0.0271958 \tTrain Acc: 98.05556% \tVal Acc: 98.8888885%\n",
      "Epoch: 372\tTrain Loss: 0.0766182 \tVal Loss:0.0209895 \tTrain Acc: 98.88889% \tVal Acc: 99.4444440%\n",
      "Epoch: 373\tTrain Loss: 0.0768785 \tVal Loss:0.0227007 \tTrain Acc: 98.47222% \tVal Acc: 99.4444440%\n",
      "Epoch: 374\tTrain Loss: 0.0795096 \tVal Loss:0.0197933 \tTrain Acc: 98.05555% \tVal Acc: 99.4444440%\n",
      "Epoch: 375\tTrain Loss: 0.0668530 \tVal Loss:0.0183670 \tTrain Acc: 98.75% \tVal Acc: 99.4444445%\n",
      "Validation Loss decreased from 0.019387 to 0.018367, saving the model weights\n",
      "Epoch: 376\tTrain Loss: 0.0666008 \tVal Loss:0.0173529 \tTrain Acc: 98.61111% \tVal Acc: 99.4444440%\n",
      "Validation Loss decreased from 0.018367 to 0.017353, saving the model weights\n",
      "Epoch: 377\tTrain Loss: 0.0630561 \tVal Loss:0.0178795 \tTrain Acc: 98.81944% \tVal Acc: 99.4444440%\n",
      "Epoch: 378\tTrain Loss: 0.0595385 \tVal Loss:0.0167887 \tTrain Acc: 99.02778% \tVal Acc: 99.7222220%\n",
      "Validation Loss decreased from 0.017353 to 0.016789, saving the model weights\n",
      "Epoch: 379\tTrain Loss: 0.0749655 \tVal Loss:0.0174472 \tTrain Acc: 98.33333% \tVal Acc: 99.4444445%\n",
      "Epoch: 380\tTrain Loss: 0.0601428 \tVal Loss:0.0173485 \tTrain Acc: 98.88889% \tVal Acc: 99.4444445%\n",
      "Epoch: 381\tTrain Loss: 0.0679068 \tVal Loss:0.0169094 \tTrain Acc: 98.61111% \tVal Acc: 99.4444445%\n",
      "Epoch: 382\tTrain Loss: 0.0575147 \tVal Loss:0.0159215 \tTrain Acc: 99.09722% \tVal Acc: 99.4444445%\n",
      "Validation Loss decreased from 0.016789 to 0.015921, saving the model weights\n",
      "Epoch: 383\tTrain Loss: 0.0708662 \tVal Loss:0.0201598 \tTrain Acc: 98.19444% \tVal Acc: 99.4444440%\n",
      "Epoch: 384\tTrain Loss: 0.0647619 \tVal Loss:0.0175428 \tTrain Acc: 98.75% \tVal Acc: 99.4444440%\n",
      "Epoch: 385\tTrain Loss: 0.0593702 \tVal Loss:0.0165104 \tTrain Acc: 98.95833% \tVal Acc: 99.4444445%\n",
      "Epoch: 386\tTrain Loss: 0.0616064 \tVal Loss:0.0171929 \tTrain Acc: 98.75% \tVal Acc: 99.4444445%\n",
      "Epoch: 387\tTrain Loss: 0.1122315 \tVal Loss:0.0378289 \tTrain Acc: 97.29167% \tVal Acc: 98.8888880%\n",
      "Epoch: 388\tTrain Loss: 0.1572972 \tVal Loss:0.0324466 \tTrain Acc: 95.69444% \tVal Acc: 98.8888880%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 389\tTrain Loss: 0.1358666 \tVal Loss:0.0374672 \tTrain Acc: 96.52778% \tVal Acc: 98.6111100%\n",
      "Epoch: 390\tTrain Loss: 0.1126697 \tVal Loss:0.0240070 \tTrain Acc: 97.15278% \tVal Acc: 98.8888885%\n",
      "Epoch: 391\tTrain Loss: 0.1020878 \tVal Loss:0.0190240 \tTrain Acc: 97.15278% \tVal Acc: 99.4444440%\n",
      "Epoch: 392\tTrain Loss: 0.1133993 \tVal Loss:0.0267511 \tTrain Acc: 96.52778% \tVal Acc: 98.8888890%\n",
      "Epoch: 393\tTrain Loss: 0.1092082 \tVal Loss:0.0312570 \tTrain Acc: 97.36111% \tVal Acc: 98.8888885%\n",
      "Epoch: 394\tTrain Loss: 0.1377105 \tVal Loss:0.0234293 \tTrain Acc: 96.11111% \tVal Acc: 99.4444440%\n",
      "Epoch: 395\tTrain Loss: 0.2052409 \tVal Loss:0.0547640 \tTrain Acc: 95.0% \tVal Acc: 98.0555549%\n",
      "Epoch: 396\tTrain Loss: 0.2612975 \tVal Loss:0.5201087 \tTrain Acc: 93.19444% \tVal Acc: 86.1111109%\n",
      "Epoch: 397\tTrain Loss: 0.4315081 \tVal Loss:0.2917226 \tTrain Acc: 87.29167% \tVal Acc: 89.9999991%\n",
      "Epoch: 398\tTrain Loss: 0.3449282 \tVal Loss:0.1498595 \tTrain Acc: 90.20833% \tVal Acc: 95.5555553%\n",
      "Epoch: 399\tTrain Loss: 0.2731484 \tVal Loss:0.0623408 \tTrain Acc: 92.43055% \tVal Acc: 98.3333324%\n",
      "Epoch: 400\tTrain Loss: 0.1389160 \tVal Loss:0.0274052 \tTrain Acc: 95.90278% \tVal Acc: 99.4444445%\n",
      "Epoch: 401\tTrain Loss: 0.0859051 \tVal Loss:0.0199664 \tTrain Acc: 98.33333% \tVal Acc: 99.4444440%\n",
      "Epoch: 402\tTrain Loss: 0.0819802 \tVal Loss:0.0167829 \tTrain Acc: 98.19444% \tVal Acc: 99.4444440%\n",
      "Epoch: 403\tTrain Loss: 0.0674378 \tVal Loss:0.0187966 \tTrain Acc: 99.02778% \tVal Acc: 99.1666665%\n",
      "Epoch: 404\tTrain Loss: 0.0684814 \tVal Loss:0.0184956 \tTrain Acc: 98.68055% \tVal Acc: 99.4444445%\n",
      "Epoch: 405\tTrain Loss: 0.0681228 \tVal Loss:0.0153994 \tTrain Acc: 98.61111% \tVal Acc: 99.7222220%\n",
      "Validation Loss decreased from 0.015921 to 0.015399, saving the model weights\n",
      "Epoch: 406\tTrain Loss: 0.0595947 \tVal Loss:0.0171245 \tTrain Acc: 99.30556% \tVal Acc: 99.4444440%\n",
      "Epoch: 407\tTrain Loss: 0.0576681 \tVal Loss:0.0157269 \tTrain Acc: 99.02778% \tVal Acc: 99.4444445%\n",
      "Epoch: 408\tTrain Loss: 0.0633956 \tVal Loss:0.0135477 \tTrain Acc: 98.40278% \tVal Acc: 99.7222220%\n",
      "Validation Loss decreased from 0.015399 to 0.013548, saving the model weights\n",
      "Epoch: 409\tTrain Loss: 0.0568236 \tVal Loss:0.0138863 \tTrain Acc: 98.88889% \tVal Acc: 99.4444440%\n",
      "Epoch: 410\tTrain Loss: 0.0583482 \tVal Loss:0.0223071 \tTrain Acc: 98.68055% \tVal Acc: 99.4444440%\n",
      "Epoch: 411\tTrain Loss: 0.0587438 \tVal Loss:0.0163906 \tTrain Acc: 98.61111% \tVal Acc: 99.4444445%\n",
      "Epoch: 412\tTrain Loss: 0.0618463 \tVal Loss:0.0152956 \tTrain Acc: 98.81944% \tVal Acc: 99.4444440%\n",
      "Epoch: 413\tTrain Loss: 0.0658763 \tVal Loss:0.0159101 \tTrain Acc: 98.68056% \tVal Acc: 99.1666665%\n",
      "Epoch: 414\tTrain Loss: 0.0588706 \tVal Loss:0.0187435 \tTrain Acc: 98.88889% \tVal Acc: 99.1666665%\n",
      "Epoch: 415\tTrain Loss: 0.0606247 \tVal Loss:0.0169774 \tTrain Acc: 98.75% \tVal Acc: 99.4444445%\n",
      "Epoch: 416\tTrain Loss: 0.0569585 \tVal Loss:0.0178404 \tTrain Acc: 98.81944% \tVal Acc: 99.4444440%\n",
      "Epoch: 417\tTrain Loss: 0.0463231 \tVal Loss:0.0134028 \tTrain Acc: 99.16667% \tVal Acc: 99.7222220%\n",
      "Validation Loss decreased from 0.013548 to 0.013403, saving the model weights\n",
      "Epoch: 418\tTrain Loss: 0.0531649 \tVal Loss:0.0662150 \tTrain Acc: 99.02778% \tVal Acc: 97.7777774%\n",
      "Epoch: 419\tTrain Loss: 0.0751816 \tVal Loss:0.0574413 \tTrain Acc: 98.33333% \tVal Acc: 97.4999994%\n",
      "Epoch: 420\tTrain Loss: 0.0817857 \tVal Loss:0.0557541 \tTrain Acc: 97.98611% \tVal Acc: 97.7777774%\n",
      "Epoch: 421\tTrain Loss: 0.0811418 \tVal Loss:0.0295852 \tTrain Acc: 98.40278% \tVal Acc: 99.1666665%\n",
      "Epoch: 422\tTrain Loss: 0.0797441 \tVal Loss:0.0168360 \tTrain Acc: 98.47222% \tVal Acc: 99.4444440%\n",
      "Epoch: 423\tTrain Loss: 0.0702736 \tVal Loss:0.0204844 \tTrain Acc: 98.47222% \tVal Acc: 98.8888885%\n",
      "Epoch: 424\tTrain Loss: 0.0740504 \tVal Loss:0.0324003 \tTrain Acc: 98.61111% \tVal Acc: 98.6111109%\n",
      "Epoch: 425\tTrain Loss: 0.0662707 \tVal Loss:0.0723180 \tTrain Acc: 98.75% \tVal Acc: 97.4999999%\n",
      "Epoch: 426\tTrain Loss: 0.0640962 \tVal Loss:0.0645714 \tTrain Acc: 98.54167% \tVal Acc: 97.4999999%\n",
      "Epoch: 427\tTrain Loss: 0.2038682 \tVal Loss:0.1074033 \tTrain Acc: 95.06944% \tVal Acc: 96.3888879%\n",
      "Epoch: 428\tTrain Loss: 0.3023001 \tVal Loss:0.2443401 \tTrain Acc: 91.45833% \tVal Acc: 91.6666662%\n",
      "Epoch: 429\tTrain Loss: 0.5102744 \tVal Loss:0.4280021 \tTrain Acc: 85.69444% \tVal Acc: 86.9444440%\n",
      "Epoch: 430\tTrain Loss: 0.4661910 \tVal Loss:0.0660015 \tTrain Acc: 86.25% \tVal Acc: 98.6111100%\n",
      "Epoch: 431\tTrain Loss: 0.2070928 \tVal Loss:0.0885529 \tTrain Acc: 93.47222% \tVal Acc: 96.9444439%\n",
      "Epoch: 432\tTrain Loss: 0.1224969 \tVal Loss:0.0290135 \tTrain Acc: 96.80555% \tVal Acc: 99.1666665%\n",
      "Epoch: 433\tTrain Loss: 0.0883004 \tVal Loss:0.0176666 \tTrain Acc: 98.26389% \tVal Acc: 99.4444440%\n",
      "Epoch: 434\tTrain Loss: 0.0632725 \tVal Loss:0.0177601 \tTrain Acc: 98.81944% \tVal Acc: 99.4444440%\n",
      "Epoch: 435\tTrain Loss: 0.0610355 \tVal Loss:0.0157048 \tTrain Acc: 98.81944% \tVal Acc: 99.4444440%\n",
      "Epoch: 436\tTrain Loss: 0.0610527 \tVal Loss:0.0148107 \tTrain Acc: 99.30556% \tVal Acc: 99.7222220%\n",
      "Epoch: 437\tTrain Loss: 0.0651758 \tVal Loss:0.0136962 \tTrain Acc: 98.26389% \tVal Acc: 99.7222220%\n",
      "Epoch: 438\tTrain Loss: 0.0566736 \tVal Loss:0.0148106 \tTrain Acc: 98.47222% \tVal Acc: 99.7222220%\n",
      "Epoch: 439\tTrain Loss: 0.0546495 \tVal Loss:0.0151155 \tTrain Acc: 99.16667% \tVal Acc: 99.1666660%\n",
      "Epoch: 440\tTrain Loss: 0.0529243 \tVal Loss:0.0122911 \tTrain Acc: 99.09722% \tVal Acc: 99.4444445%\n",
      "Validation Loss decreased from 0.013403 to 0.012291, saving the model weights\n",
      "Epoch: 441\tTrain Loss: 0.0552550 \tVal Loss:0.0120177 \tTrain Acc: 98.61111% \tVal Acc: 99.7222220%\n",
      "Validation Loss decreased from 0.012291 to 0.012018, saving the model weights\n",
      "Epoch: 442\tTrain Loss: 0.0491451 \tVal Loss:0.0138097 \tTrain Acc: 98.95833% \tVal Acc: 99.7222220%\n",
      "Epoch: 443\tTrain Loss: 0.0470048 \tVal Loss:0.0122526 \tTrain Acc: 99.23611% \tVal Acc: 99.7222220%\n",
      "Epoch: 444\tTrain Loss: 0.0507831 \tVal Loss:0.0117805 \tTrain Acc: 98.95833% \tVal Acc: 99.7222220%\n",
      "Validation Loss decreased from 0.012018 to 0.011781, saving the model weights\n",
      "Epoch: 445\tTrain Loss: 0.0456950 \tVal Loss:0.0119697 \tTrain Acc: 99.02778% \tVal Acc: 99.4444445%\n",
      "Epoch: 446\tTrain Loss: 0.0476023 \tVal Loss:0.0145922 \tTrain Acc: 99.02778% \tVal Acc: 99.1666665%\n",
      "Epoch: 447\tTrain Loss: 0.0504893 \tVal Loss:0.0120241 \tTrain Acc: 98.88889% \tVal Acc: 99.7222220%\n",
      "Epoch: 448\tTrain Loss: 0.0386266 \tVal Loss:0.0136770 \tTrain Acc: 99.375% \tVal Acc: 99.4444445%\n",
      "Epoch: 449\tTrain Loss: 0.0391706 \tVal Loss:0.0109956 \tTrain Acc: 99.44444% \tVal Acc: 99.4444440%\n",
      "Validation Loss decreased from 0.011781 to 0.010996, saving the model weights\n",
      "Epoch: 450\tTrain Loss: 0.0471663 \tVal Loss:0.0109290 \tTrain Acc: 98.88889% \tVal Acc: 99.4444440%\n",
      "Validation Loss decreased from 0.010996 to 0.010929, saving the model weights\n",
      "Epoch: 451\tTrain Loss: 0.0527281 \tVal Loss:0.0122952 \tTrain Acc: 98.81944% \tVal Acc: 99.4444445%\n",
      "Epoch: 452\tTrain Loss: 0.0505251 \tVal Loss:0.0147469 \tTrain Acc: 98.75% \tVal Acc: 99.4444440%\n",
      "Epoch: 453\tTrain Loss: 0.0394711 \tVal Loss:0.0137620 \tTrain Acc: 99.44444% \tVal Acc: 99.4444440%\n",
      "Epoch: 454\tTrain Loss: 0.0497697 \tVal Loss:0.0147608 \tTrain Acc: 98.81944% \tVal Acc: 99.4444440%\n",
      "Epoch: 455\tTrain Loss: 0.0584399 \tVal Loss:0.0131009 \tTrain Acc: 99.02778% \tVal Acc: 99.4444445%\n",
      "Epoch: 456\tTrain Loss: 0.0506789 \tVal Loss:0.0148434 \tTrain Acc: 99.16667% \tVal Acc: 99.1666665%\n",
      "Epoch: 457\tTrain Loss: 0.0528594 \tVal Loss:0.0135901 \tTrain Acc: 99.16667% \tVal Acc: 99.4444445%\n",
      "Epoch: 458\tTrain Loss: 0.0475577 \tVal Loss:0.0120488 \tTrain Acc: 99.30555% \tVal Acc: 99.4444440%\n",
      "Epoch: 459\tTrain Loss: 0.0407637 \tVal Loss:0.0193056 \tTrain Acc: 99.09722% \tVal Acc: 99.1666665%\n",
      "Epoch: 460\tTrain Loss: 0.0444909 \tVal Loss:0.0855190 \tTrain Acc: 99.02778% \tVal Acc: 97.4999999%\n",
      "Epoch: 461\tTrain Loss: 0.0709306 \tVal Loss:0.0946378 \tTrain Acc: 97.70833% \tVal Acc: 97.2222219%\n",
      "Epoch: 462\tTrain Loss: 0.1140326 \tVal Loss:0.0500371 \tTrain Acc: 96.66667% \tVal Acc: 97.7777779%\n",
      "Epoch: 463\tTrain Loss: 0.2527558 \tVal Loss:0.0896608 \tTrain Acc: 94.09722% \tVal Acc: 96.6666664%\n",
      "Epoch: 464\tTrain Loss: 0.4454364 \tVal Loss:0.1121190 \tTrain Acc: 87.5% \tVal Acc: 97.4999999%\n",
      "Epoch: 465\tTrain Loss: 0.4967183 \tVal Loss:0.6957005 \tTrain Acc: 86.25% \tVal Acc: 83.3333318%\n",
      "Epoch: 466\tTrain Loss: 1.0843005 \tVal Loss:0.4927420 \tTrain Acc: 71.66667% \tVal Acc: 83.8888879%\n",
      "Epoch: 467\tTrain Loss: 0.9113448 \tVal Loss:0.3982976 \tTrain Acc: 74.65278% \tVal Acc: 86.6666660%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 468\tTrain Loss: 0.5681535 \tVal Loss:0.2033309 \tTrain Acc: 84.16667% \tVal Acc: 94.7222213%\n",
      "Epoch: 469\tTrain Loss: 0.2986304 \tVal Loss:0.2527193 \tTrain Acc: 92.36111% \tVal Acc: 93.8888888%\n",
      "Epoch: 470\tTrain Loss: 0.2354663 \tVal Loss:0.0452364 \tTrain Acc: 93.33333% \tVal Acc: 99.1666665%\n",
      "Epoch: 471\tTrain Loss: 0.1317320 \tVal Loss:0.0282157 \tTrain Acc: 96.38889% \tVal Acc: 99.1666660%\n",
      "Epoch: 472\tTrain Loss: 0.1038918 \tVal Loss:0.0184738 \tTrain Acc: 97.36111% \tVal Acc: 99.7222220%\n",
      "Epoch: 473\tTrain Loss: 0.0854752 \tVal Loss:0.0166349 \tTrain Acc: 98.19444% \tVal Acc: 99.4444445%\n",
      "Epoch: 474\tTrain Loss: 0.0709813 \tVal Loss:0.0157174 \tTrain Acc: 99.09722% \tVal Acc: 99.4444445%\n",
      "Epoch: 475\tTrain Loss: 0.0607323 \tVal Loss:0.0148515 \tTrain Acc: 99.23611% \tVal Acc: 99.4444445%\n",
      "Epoch: 476\tTrain Loss: 0.0662410 \tVal Loss:0.0142134 \tTrain Acc: 98.61111% \tVal Acc: 99.4444440%\n",
      "Epoch: 477\tTrain Loss: 0.0658739 \tVal Loss:0.0146787 \tTrain Acc: 98.61111% \tVal Acc: 99.4444445%\n",
      "Epoch: 478\tTrain Loss: 0.0584033 \tVal Loss:0.0139498 \tTrain Acc: 98.95833% \tVal Acc: 99.4444440%\n",
      "Epoch: 479\tTrain Loss: 0.0569991 \tVal Loss:0.0125750 \tTrain Acc: 98.54167% \tVal Acc: 99.7222220%\n",
      "Epoch: 480\tTrain Loss: 0.0499495 \tVal Loss:0.0121452 \tTrain Acc: 99.375% \tVal Acc: 99.7222220%\n",
      "Epoch: 481\tTrain Loss: 0.0528936 \tVal Loss:0.0130255 \tTrain Acc: 99.16667% \tVal Acc: 99.4444440%\n",
      "Epoch: 482\tTrain Loss: 0.0455097 \tVal Loss:0.0125079 \tTrain Acc: 99.375% \tVal Acc: 99.7222220%\n",
      "Epoch: 483\tTrain Loss: 0.0524145 \tVal Loss:0.0125471 \tTrain Acc: 98.88889% \tVal Acc: 99.7222220%\n",
      "Epoch: 484\tTrain Loss: 0.0525151 \tVal Loss:0.0118394 \tTrain Acc: 98.61111% \tVal Acc: 99.7222220%\n",
      "Epoch: 485\tTrain Loss: 0.0458887 \tVal Loss:0.0140036 \tTrain Acc: 99.09722% \tVal Acc: 99.4444445%\n",
      "Epoch: 486\tTrain Loss: 0.0499901 \tVal Loss:0.0118280 \tTrain Acc: 99.09722% \tVal Acc: 99.4444440%\n",
      "Epoch: 487\tTrain Loss: 0.0482959 \tVal Loss:0.0147424 \tTrain Acc: 99.16667% \tVal Acc: 99.1666665%\n",
      "Epoch: 488\tTrain Loss: 0.0527808 \tVal Loss:0.0160735 \tTrain Acc: 98.47222% \tVal Acc: 99.4444445%\n",
      "Epoch: 489\tTrain Loss: 0.0474368 \tVal Loss:0.0136958 \tTrain Acc: 98.95833% \tVal Acc: 99.7222220%\n",
      "Epoch: 490\tTrain Loss: 0.0448280 \tVal Loss:0.0118505 \tTrain Acc: 99.375% \tVal Acc: 99.4444445%\n",
      "Epoch: 491\tTrain Loss: 0.0472145 \tVal Loss:0.0108757 \tTrain Acc: 99.16667% \tVal Acc: 99.7222220%\n",
      "Validation Loss decreased from 0.010929 to 0.010876, saving the model weights\n",
      "Epoch: 492\tTrain Loss: 0.0438128 \tVal Loss:0.0125188 \tTrain Acc: 99.02778% \tVal Acc: 99.4444445%\n",
      "Epoch: 493\tTrain Loss: 0.0438417 \tVal Loss:0.0138842 \tTrain Acc: 99.23611% \tVal Acc: 99.4444445%\n",
      "Epoch: 494\tTrain Loss: 0.0433097 \tVal Loss:0.0120307 \tTrain Acc: 99.16667% \tVal Acc: 99.4444440%\n",
      "Epoch: 495\tTrain Loss: 0.0448700 \tVal Loss:0.0111329 \tTrain Acc: 98.81944% \tVal Acc: 99.4444445%\n",
      "Epoch: 496\tTrain Loss: 0.0404610 \tVal Loss:0.0101655 \tTrain Acc: 99.09722% \tVal Acc: 99.7222220%\n",
      "Validation Loss decreased from 0.010876 to 0.010165, saving the model weights\n",
      "Epoch: 497\tTrain Loss: 0.0404012 \tVal Loss:0.0111413 \tTrain Acc: 99.375% \tVal Acc: 99.7222220%\n",
      "Epoch: 498\tTrain Loss: 0.0399286 \tVal Loss:0.0102753 \tTrain Acc: 99.30556% \tVal Acc: 99.7222220%\n",
      "Epoch: 499\tTrain Loss: 0.0411487 \tVal Loss:0.0104218 \tTrain Acc: 98.95833% \tVal Acc: 99.7222220%\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "min_val_loss = np.Inf\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    train_accuracy = 0\n",
    "    val_accuracy = 0\n",
    "    \n",
    "    \n",
    "    hidden1, hidden2 = model.hidden_init(train_batch_size)    \n",
    "    #print('hidden[0].shape:- ',hidden[0].shape)\n",
    "    \n",
    "    for inputs,labels in train_loader:\n",
    "        #print(inputs.shape)\n",
    "\n",
    "        '''\n",
    "        Creating new variables for the hidden state, otherwise\n",
    "        we'd backprop through the entire training history\n",
    "        '''\n",
    "        #h = tuple([each.data for each in hidden])\n",
    "        \n",
    "        h1 = tuple([each.data for each in hidden1])\n",
    "        h2 = tuple([each.data for each in hidden2])\n",
    "        \n",
    "        # zero accumulated gradients\n",
    "        model.zero_grad()\n",
    "       \n",
    "        # get the output from the model\n",
    "        output, _ = model.forward(inputs, h1, h2, train_batch_size)\n",
    "        #print('OUTPUT', output)\n",
    "        \n",
    "        \n",
    "        #print('Labels Shape :-', (torch.max(labels, 1)[1]).shape)\n",
    "    \n",
    "        # calculate the loss and perform backprop\n",
    "        #print('Labels Long :-', labels.long())\n",
    "        loss = criterion(output,labels.long())\n",
    "        #print('LOSS IS :-', loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #calculate training accuracy\n",
    "        output = F.softmax(output, dim = 1)\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "        logging.debug(' top probab {} top class {}'.format(top_p.view(-1, top_p.shape[0]), top_class.view(-1, top_p.shape[0])))\n",
    "\n",
    "        equals = top_class == labels.long().view(*top_class.shape)\n",
    "        train_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        \n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        #nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        #print(train_loss)\n",
    "              \n",
    "    model.eval()\n",
    "    for inputs, labels in val_loader:\n",
    "                \n",
    "        val_h1 = tuple([each.data for each in hidden1])\n",
    "        val_h2 = tuple([each.data for each in hidden2])\n",
    "        \n",
    "        output, _ = model.forward(inputs, val_h1, val_h2,val_batch_size)\n",
    "       \n",
    "        loss = criterion(output,labels.long())\n",
    "        \n",
    "        val_loss += loss.item()\n",
    "        \n",
    "        #calculate validation accuracy\n",
    "        output = F.softmax(output, dim = 1)\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "        \n",
    "        #logging.debug(output)\n",
    "        #logging.debug('VALIDATION top probab {} VALIDATION top class {}'.format(top_p.view(-1, top_p.shape[0]), top_class.view(-1, top_p.shape[0])))\n",
    "\n",
    "        #print('Top Class:- ',top_class)\n",
    "        equals = top_class == labels.long().view(*top_class.shape)\n",
    "        #print('Equals:- ', equals)\n",
    "        val_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    #Averaging losses\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    val_loss = val_loss/len(val_loader)\n",
    "    val_accuracy = val_accuracy/len(val_loader)\n",
    "    train_accuracy = train_accuracy/len(train_loader)\n",
    "    \n",
    "    print('Epoch: {}\\tTrain Loss: {:.7f} \\tVal Loss:{:.7f} \\tTrain Acc: {:.7}% \\tVal Acc: {:.7f}%'.format(e, train_loss, val_loss, train_accuracy*100,val_accuracy*100))\n",
    "    \n",
    "    #saving the model if validation loss is decreased\n",
    "    if val_loss <= min_val_loss:\n",
    "        print('Validation Loss decreased from {:6f} to {:6f}, saving the model weights'.format(min_val_loss, val_loss))\n",
    "        torch.save(model.state_dict(), 'lstm_state_256-38-removed_Ht_Ct_sorted.pt')\n",
    "        min_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUSIC GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stacked_LSTM(\n",
       "  (lstm1): LSTM(1, 256, batch_first=True)\n",
       "  (lstm2): LSTM(256, 38, batch_first=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=38, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights\n",
    "test_model = Stacked_LSTM(input_size,hidden_size,num_layer,output_size)\n",
    "test_model.load_state_dict(torch.load('lstm_state_256-38-removed_Ht_Ct_sorted.pt'))\n",
    "test_model.eval()\n",
    "test_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load population database\n",
    "#testing_data = np.ones(200)*1\n",
    "testing_data = list(range(50,90))\n",
    "testing_data.extend(testing_data[::-1])\n",
    "testing_data_rev = testing_data[::-1]\n",
    "testing_data_rev.extend(testing_data)\n",
    "testing_data_rev.extend(testing_data_rev)\n",
    "testing_data = testing_data_rev\n",
    "\n",
    "\n",
    "testing_data = np.asarray(testing_data)\n",
    "testing_data = testing_data.reshape(testing_data.shape[0],1)\n",
    "\n",
    "initial_seq = [network_input[0][1:].cpu().numpy().tolist()]\n",
    "\n",
    "testing_data_unnorm = testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "testing_data=testing_data.tolist()\n",
    "for i in range(len(testing_data)):\n",
    "    list1.extend(testing_data[i])\n",
    "\n",
    "#list1\n",
    "\n",
    "for i in range(len(list1)):\n",
    "    list1[i]=(list1[i]-50)/(89-50)\n",
    "\n",
    "list1 = np.asarray(list1)\n",
    "list1 = list1.reshape(list1.shape[0],1)\n",
    "testing_data = list1\n",
    "#list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting\n",
    "def prediction_with_influence(influence,int2note,initial_seq, max_note, test_batch_size = 1):\n",
    "\n",
    "    predicted_notes = []\n",
    "    initial_seq[0].extend([[0]]*len(testing_data))\n",
    "    test_seq = torch.Tensor(initial_seq).cuda()\n",
    "    \n",
    "    h1, h2 = test_model.hidden_init(test_batch_size)\n",
    "\n",
    "    \n",
    "    for i in range(len(influence)):\n",
    "        \n",
    "        test_seq[0][sequence_length - 1 + i][0] = float(influence[i])\n",
    "        \n",
    "        test_slice = test_seq[0][i : i + sequence_length]        \n",
    "        test_slice = test_slice.view(1, test_slice.shape[0], test_slice.shape[1])\n",
    "                \n",
    "        test_hidden1 = tuple([each.data for each in h1])\n",
    "        test_hidden2 = tuple([each.data for each in h2])\n",
    "        \n",
    "        test_output,_ = test_model.forward(test_slice, test_hidden1, test_hidden2, test_batch_size)\n",
    "    \n",
    "        test_output = F.softmax(test_output, dim = 1)\n",
    "        top_p, top_class = test_output.topk(1,dim =1)\n",
    "        test_seq[0][sequence_length - 1 + i][0] = int2note[top_class.item()]/max_note\n",
    "        \n",
    "        predicted_notes.append(int2note[top_class.item()])\n",
    "        \n",
    "    return predicted_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_notes_lst = prediction_with_influence(testing_data,int_to_note,initial_seq, max_midi_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_notes_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2973cb0a668>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 369
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(list(np.ones(200)*89))\n",
    "\n",
    "#plt.plot(list(np.ones(200)*50))\n",
    "#plt.plot(list(np.ones(20)*50))\n",
    "plt.plot(testing_data_unnorm)\n",
    "plt.plot(predicted_notes_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({72: 16,\n",
       "         74: 103,\n",
       "         76: 6,\n",
       "         73: 2,\n",
       "         71: 73,\n",
       "         84: 42,\n",
       "         86: 7,\n",
       "         77: 35,\n",
       "         83: 4,\n",
       "         81: 5,\n",
       "         70: 16,\n",
       "         79: 2,\n",
       "         55: 4,\n",
       "         60: 4,\n",
       "         62: 1})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter(predicted_notes_lst)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
