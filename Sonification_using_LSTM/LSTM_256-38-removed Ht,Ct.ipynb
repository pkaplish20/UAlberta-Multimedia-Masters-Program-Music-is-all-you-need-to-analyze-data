{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.tensorboard as tb\n",
    "from Preprocessing.preprocessing import PreprocessingTrainingData\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as  plt\n",
    "import os\n",
    "import logging\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#static parameters\n",
    "train_batch_size = 170\n",
    "val_batch_size = 170\n",
    "sequence_length=50\n",
    "test_batch_size = 1\n",
    "input_size = 1\n",
    "hidden_size = 256\n",
    "num_layer = 2\n",
    "output_size = 38\n",
    "clip = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from preprocessing.py\n",
    "dataset_path = os.path.join(os.path.abspath('..'),'Dataset\\\\Clementi dataset\\\\Clementi dataset' )\n",
    "network_input,network_output,max_midi_number,min_midi_number,int_to_note = PreprocessingTrainingData().preprocess_notes(dataset_path)\n",
    "network_input, network_output = network_input.cuda(), network_output.cuda()\n",
    "\n",
    "# print(network_input)\n",
    "#print(network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(37, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(network_output.max())\n",
    "print(network_output.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "89\n",
      "50\n",
      "{0: 50, 1: 52, 2: 53, 3: 54, 4: 55, 5: 56, 6: 57, 7: 58, 8: 59, 9: 60, 10: 61, 11: 62, 12: 63, 13: 64, 14: 65, 15: 66, 16: 67, 17: 68, 18: 69, 19: 70, 20: 71, 21: 72, 22: 73, 23: 74, 24: 75, 25: 76, 26: 77, 27: 78, 28: 79, 29: 80, 30: 81, 31: 82, 32: 83, 33: 84, 34: 85, 35: 86, 36: 88, 37: 89}\n"
     ]
    }
   ],
   "source": [
    "print(network_input.max())\n",
    "print(network_input.min())\n",
    "print(max_midi_number)\n",
    "print(min_midi_number)\n",
    "print(int_to_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata is highly unbalanced\\n# '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data is highly unbalanced\n",
    "# '''\n",
    "# sns.distplot(torch.tensor(network_output).cpu())\n",
    "# xx = pd.DataFrame(torch.tensor(network_output).cpu())\n",
    "# xx.groupby(0).size().to_frame(name='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8500, 50, 1])\n",
      "torch.Size([8500])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "to make batch of equal sizes\n",
    "Quick Fix\n",
    "'''\n",
    "network_input = network_input[: -117]\n",
    "network_output = network_output[: -117]\n",
    "\n",
    "print(network_input.shape)\n",
    "print(network_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create Stacked LSTM model\n",
    "'''\n",
    "class Stacked_LSTM(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size = input_size, hidden_size = hidden_size, batch_first = True)\n",
    "        self.lstm2 = nn.LSTM(input_size = hidden_size, hidden_size = output_size,batch_first = True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(output_size, output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hidden1, hidden2,batch_size):\n",
    "        \n",
    "        output, _ = self.lstm1(x)        \n",
    "        #print(output.shape)\n",
    "        \n",
    "        #output = self.dropout(output)\n",
    "        \n",
    "        output, _ = self.lstm2(output)\n",
    "        #print(output.shape)\n",
    "        \n",
    "        # stack up lstm outputs\n",
    "        output = output.contiguous().view(-1, 38)\n",
    "        #print(output.shape)\n",
    "        \n",
    "        output = self.dropout(output)\n",
    "        output = self.linear(output)\n",
    "        #print('Linear Output :-',output.shape)\n",
    "        \n",
    "        #output = F.softmax(output, dim = 1)\n",
    "        #print('SOFTMAX OUTPUT :--', output)\n",
    "        \n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        output = output.view(batch_size, -1)\n",
    "        #print('Reshape to batch size first :-',output.shape)\n",
    "        \n",
    "        output = output[:, -self.output_size:] # get last batch of labels\n",
    "        #print('Final Output :-',output)\n",
    "        #print('RESHAPE SIZE :-', output.shape)\n",
    "        \n",
    "        return output, hidden2\n",
    "    \n",
    "    def hidden_init(self,batch_size):\n",
    "        \n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden1 = (weight.new(1, batch_size, self.hidden_size).zero_().cuda(),\n",
    "          weight.new(1, batch_size, self.hidden_size).zero_().cuda())\n",
    "        \n",
    "        hidden2 = (weight.new(1, batch_size, 38).zero_().cuda(),\n",
    "          weight.new(1, batch_size, 38).zero_().cuda())\n",
    "        return hidden1,hidden2\n",
    "\n",
    "#initialize the weights of LSTM using Xavier initialization    \n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Divide the dataset into train/val \n",
    "'''\n",
    "train_size = 0.8\n",
    "indices = list(range(len(network_input)))\n",
    "split = int(np.floor(train_size*len(network_input)))\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "train_sampler = SequentialSampler(train_idx)\n",
    "val_sampler = SequentialSampler(val_idx)\n",
    "\n",
    "dataset = TensorDataset(network_input,network_output)\n",
    "train_loader = DataLoader(dataset, batch_size= train_batch_size, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset, batch_size= val_batch_size,sampler= val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stacked_LSTM(\n",
       "  (lstm1): LSTM(1, 256, batch_first=True)\n",
       "  (lstm2): LSTM(256, 38, batch_first=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=38, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optimizer\n",
    "\n",
    "model = Stacked_LSTM(input_size,hidden_size,num_layer,output_size)\n",
    "model.apply(init_weights)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optimizer.AdamW(model.parameters())\n",
    "#optimizer = optimizer.RMSprop(model.parameters(), lr = 0.001, weight_decay = 0.01)\n",
    "\n",
    "\n",
    "#make sure to transfer model to GPU after initializing optimizer\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden = model.hidden_init(train_batch_size) \n",
    "#hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTrain Loss: 3.3479235 \tVal Loss:3.0259093 \tTrain Acc: 8.514706% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from    inf to 3.025909, saving the model weights\n",
      "Epoch: 1\tTrain Loss: 3.1590553 \tVal Loss:2.9777230 \tTrain Acc: 8.617647% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from 3.025909 to 2.977723, saving the model weights\n",
      "Epoch: 2\tTrain Loss: 3.1271409 \tVal Loss:2.9652464 \tTrain Acc: 9.014706% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from 2.977723 to 2.965246, saving the model weights\n",
      "Epoch: 3\tTrain Loss: 3.1119785 \tVal Loss:2.9602911 \tTrain Acc: 8.602941% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from 2.965246 to 2.960291, saving the model weights\n",
      "Epoch: 4\tTrain Loss: 3.1020215 \tVal Loss:2.9553184 \tTrain Acc: 8.882353% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from 2.960291 to 2.955318, saving the model weights\n",
      "Epoch: 5\tTrain Loss: 3.0890726 \tVal Loss:2.9467849 \tTrain Acc: 9.014706% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from 2.955318 to 2.946785, saving the model weights\n",
      "Epoch: 6\tTrain Loss: 3.0843426 \tVal Loss:2.9447741 \tTrain Acc: 9.058824% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from 2.946785 to 2.944774, saving the model weights\n",
      "Epoch: 7\tTrain Loss: 3.0740010 \tVal Loss:2.9422285 \tTrain Acc: 9.191177% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from 2.944774 to 2.942228, saving the model weights\n",
      "Epoch: 8\tTrain Loss: 3.0680945 \tVal Loss:2.9412205 \tTrain Acc: 9.558824% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from 2.942228 to 2.941220, saving the model weights\n",
      "Epoch: 9\tTrain Loss: 3.0669609 \tVal Loss:2.9398259 \tTrain Acc: 9.191177% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from 2.941220 to 2.939826, saving the model weights\n",
      "Epoch: 10\tTrain Loss: 3.0617884 \tVal Loss:2.9368841 \tTrain Acc: 9.617647% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from 2.939826 to 2.936884, saving the model weights\n",
      "Epoch: 11\tTrain Loss: 3.0516531 \tVal Loss:2.9339388 \tTrain Acc: 9.941177% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from 2.936884 to 2.933939, saving the model weights\n",
      "Epoch: 12\tTrain Loss: 3.0548330 \tVal Loss:2.9353508 \tTrain Acc: 10.10294% \tVal Acc: 11.4117651%\n",
      "Epoch: 13\tTrain Loss: 3.0517972 \tVal Loss:2.9391382 \tTrain Acc: 9.191177% \tVal Acc: 11.4117651%\n",
      "Epoch: 14\tTrain Loss: 3.0484711 \tVal Loss:2.9304879 \tTrain Acc: 9.897059% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from 2.933939 to 2.930488, saving the model weights\n",
      "Epoch: 15\tTrain Loss: 3.0336892 \tVal Loss:2.9088474 \tTrain Acc: 10.10294% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from 2.930488 to 2.908847, saving the model weights\n",
      "Epoch: 16\tTrain Loss: 3.0297039 \tVal Loss:2.9167881 \tTrain Acc: 10.04412% \tVal Acc: 11.4117651%\n",
      "Epoch: 17\tTrain Loss: 2.9866478 \tVal Loss:2.9254881 \tTrain Acc: 11.01471% \tVal Acc: 11.4117651%\n",
      "Epoch: 18\tTrain Loss: 2.9746591 \tVal Loss:2.8236745 \tTrain Acc: 10.89706% \tVal Acc: 14.2352945%\n",
      "Validation Loss decreased from 2.908847 to 2.823674, saving the model weights\n",
      "Epoch: 19\tTrain Loss: 2.9100480 \tVal Loss:2.7725797 \tTrain Acc: 12.38235% \tVal Acc: 12.9411768%\n",
      "Validation Loss decreased from 2.823674 to 2.772580, saving the model weights\n",
      "Epoch: 20\tTrain Loss: 2.8335505 \tVal Loss:2.6932548 \tTrain Acc: 13.32353% \tVal Acc: 13.7647063%\n",
      "Validation Loss decreased from 2.772580 to 2.693255, saving the model weights\n",
      "Epoch: 21\tTrain Loss: 2.7970162 \tVal Loss:2.6865203 \tTrain Acc: 13.11765% \tVal Acc: 13.0588240%\n",
      "Validation Loss decreased from 2.693255 to 2.686520, saving the model weights\n",
      "Epoch: 22\tTrain Loss: 2.7407544 \tVal Loss:2.6061289 \tTrain Acc: 13.85294% \tVal Acc: 15.1764710%\n",
      "Validation Loss decreased from 2.686520 to 2.606129, saving the model weights\n",
      "Epoch: 23\tTrain Loss: 2.6923936 \tVal Loss:2.5695527 \tTrain Acc: 14.82353% \tVal Acc: 14.8823534%\n",
      "Validation Loss decreased from 2.606129 to 2.569553, saving the model weights\n",
      "Epoch: 24\tTrain Loss: 2.6528209 \tVal Loss:2.5897174 \tTrain Acc: 15.08824% \tVal Acc: 14.3529416%\n",
      "Epoch: 25\tTrain Loss: 2.6300391 \tVal Loss:2.5637043 \tTrain Acc: 16.16177% \tVal Acc: 14.6470592%\n",
      "Validation Loss decreased from 2.569553 to 2.563704, saving the model weights\n",
      "Epoch: 26\tTrain Loss: 2.6186994 \tVal Loss:2.5557495 \tTrain Acc: 15.45588% \tVal Acc: 14.6470592%\n",
      "Validation Loss decreased from 2.563704 to 2.555749, saving the model weights\n",
      "Epoch: 27\tTrain Loss: 2.5902919 \tVal Loss:2.5122956 \tTrain Acc: 16.07353% \tVal Acc: 15.4705886%\n",
      "Validation Loss decreased from 2.555749 to 2.512296, saving the model weights\n",
      "Epoch: 28\tTrain Loss: 2.5768295 \tVal Loss:2.5080571 \tTrain Acc: 15.67647% \tVal Acc: 15.0000004%\n",
      "Validation Loss decreased from 2.512296 to 2.508057, saving the model weights\n",
      "Epoch: 29\tTrain Loss: 2.5566387 \tVal Loss:2.4921247 \tTrain Acc: 15.88235% \tVal Acc: 16.0000003%\n",
      "Validation Loss decreased from 2.508057 to 2.492125, saving the model weights\n",
      "Epoch: 30\tTrain Loss: 2.5313597 \tVal Loss:2.4662707 \tTrain Acc: 16.77941% \tVal Acc: 14.8235297%\n",
      "Validation Loss decreased from 2.492125 to 2.466271, saving the model weights\n",
      "Epoch: 31\tTrain Loss: 2.5249443 \tVal Loss:2.4675631 \tTrain Acc: 17.33824% \tVal Acc: 15.1764709%\n",
      "Epoch: 32\tTrain Loss: 2.5119660 \tVal Loss:2.4514397 \tTrain Acc: 16.91177% \tVal Acc: 14.9411768%\n",
      "Validation Loss decreased from 2.466271 to 2.451440, saving the model weights\n",
      "Epoch: 33\tTrain Loss: 2.5005055 \tVal Loss:2.4457517 \tTrain Acc: 17.0% \tVal Acc: 15.0000003%\n",
      "Validation Loss decreased from 2.451440 to 2.445752, saving the model weights\n",
      "Epoch: 34\tTrain Loss: 2.4921707 \tVal Loss:2.4259550 \tTrain Acc: 17.19118% \tVal Acc: 15.2941179%\n",
      "Validation Loss decreased from 2.445752 to 2.425955, saving the model weights\n",
      "Epoch: 35\tTrain Loss: 2.4894646 \tVal Loss:2.4313455 \tTrain Acc: 16.64706% \tVal Acc: 15.0000002%\n",
      "Epoch: 36\tTrain Loss: 2.4768881 \tVal Loss:2.4272601 \tTrain Acc: 17.55882% \tVal Acc: 15.3529415%\n",
      "Epoch: 37\tTrain Loss: 2.4746889 \tVal Loss:2.4272104 \tTrain Acc: 17.38235% \tVal Acc: 15.4705886%\n",
      "Epoch: 38\tTrain Loss: 2.4704330 \tVal Loss:2.4118322 \tTrain Acc: 17.95588% \tVal Acc: 15.5882357%\n",
      "Validation Loss decreased from 2.425955 to 2.411832, saving the model weights\n",
      "Epoch: 39\tTrain Loss: 2.4608487 \tVal Loss:2.4155136 \tTrain Acc: 17.79412% \tVal Acc: 15.1764710%\n",
      "Epoch: 40\tTrain Loss: 2.4615610 \tVal Loss:2.4075206 \tTrain Acc: 17.41177% \tVal Acc: 15.4117651%\n",
      "Validation Loss decreased from 2.411832 to 2.407521, saving the model weights\n",
      "Epoch: 41\tTrain Loss: 2.4497225 \tVal Loss:2.4219792 \tTrain Acc: 17.86765% \tVal Acc: 15.3529415%\n",
      "Epoch: 42\tTrain Loss: 2.4486336 \tVal Loss:2.4033945 \tTrain Acc: 18.04412% \tVal Acc: 15.6470592%\n",
      "Validation Loss decreased from 2.407521 to 2.403394, saving the model weights\n",
      "Epoch: 43\tTrain Loss: 2.4443974 \tVal Loss:2.4063249 \tTrain Acc: 17.75% \tVal Acc: 16.5294121%\n",
      "Epoch: 44\tTrain Loss: 2.4408319 \tVal Loss:2.3921066 \tTrain Acc: 18.39706% \tVal Acc: 17.1764711%\n",
      "Validation Loss decreased from 2.403394 to 2.392107, saving the model weights\n",
      "Epoch: 45\tTrain Loss: 2.4328207 \tVal Loss:2.4107228 \tTrain Acc: 18.75% \tVal Acc: 15.7058828%\n",
      "Epoch: 46\tTrain Loss: 2.4398418 \tVal Loss:2.3899750 \tTrain Acc: 17.95588% \tVal Acc: 16.1764710%\n",
      "Validation Loss decreased from 2.392107 to 2.389975, saving the model weights\n",
      "Epoch: 47\tTrain Loss: 2.4265464 \tVal Loss:2.4069794 \tTrain Acc: 18.60294% \tVal Acc: 16.1764710%\n",
      "Epoch: 48\tTrain Loss: 2.4237128 \tVal Loss:2.3838681 \tTrain Acc: 18.82353% \tVal Acc: 16.8235298%\n",
      "Validation Loss decreased from 2.389975 to 2.383868, saving the model weights\n",
      "Epoch: 49\tTrain Loss: 2.4204800 \tVal Loss:2.3844896 \tTrain Acc: 19.13235% \tVal Acc: 16.7058828%\n",
      "Epoch: 50\tTrain Loss: 2.4136046 \tVal Loss:2.3977876 \tTrain Acc: 18.98529% \tVal Acc: 17.7058828%\n",
      "Epoch: 51\tTrain Loss: 2.4075907 \tVal Loss:2.3742711 \tTrain Acc: 19.55882% \tVal Acc: 18.4117651%\n",
      "Validation Loss decreased from 2.383868 to 2.374271, saving the model weights\n",
      "Epoch: 52\tTrain Loss: 2.3987862 \tVal Loss:2.3745515 \tTrain Acc: 19.83824% \tVal Acc: 18.9411770%\n",
      "Epoch: 53\tTrain Loss: 2.4039874 \tVal Loss:2.3478771 \tTrain Acc: 19.05882% \tVal Acc: 19.1176476%\n",
      "Validation Loss decreased from 2.374271 to 2.347877, saving the model weights\n",
      "Epoch: 54\tTrain Loss: 2.3842149 \tVal Loss:2.3496882 \tTrain Acc: 20.26471% \tVal Acc: 19.5294121%\n",
      "Epoch: 55\tTrain Loss: 2.3821046 \tVal Loss:2.3276790 \tTrain Acc: 20.17647% \tVal Acc: 20.2352946%\n",
      "Validation Loss decreased from 2.347877 to 2.327679, saving the model weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56\tTrain Loss: 2.3844979 \tVal Loss:2.3331686 \tTrain Acc: 20.23529% \tVal Acc: 20.2352946%\n",
      "Epoch: 57\tTrain Loss: 2.3737416 \tVal Loss:2.3185664 \tTrain Acc: 20.61765% \tVal Acc: 21.8235298%\n",
      "Validation Loss decreased from 2.327679 to 2.318566, saving the model weights\n",
      "Epoch: 58\tTrain Loss: 2.3621731 \tVal Loss:2.3364659 \tTrain Acc: 21.36765% \tVal Acc: 21.1764710%\n",
      "Epoch: 59\tTrain Loss: 2.3706397 \tVal Loss:2.3167745 \tTrain Acc: 20.88235% \tVal Acc: 21.6470592%\n",
      "Validation Loss decreased from 2.318566 to 2.316775, saving the model weights\n",
      "Epoch: 60\tTrain Loss: 2.3524439 \tVal Loss:2.3072916 \tTrain Acc: 21.72059% \tVal Acc: 21.3529414%\n",
      "Validation Loss decreased from 2.316775 to 2.307292, saving the model weights\n",
      "Epoch: 61\tTrain Loss: 2.3396824 \tVal Loss:2.2948423 \tTrain Acc: 21.88235% \tVal Acc: 22.8235297%\n",
      "Validation Loss decreased from 2.307292 to 2.294842, saving the model weights\n",
      "Epoch: 62\tTrain Loss: 2.3295479 \tVal Loss:2.2802748 \tTrain Acc: 22.5% \tVal Acc: 25.1176478%\n",
      "Validation Loss decreased from 2.294842 to 2.280275, saving the model weights\n",
      "Epoch: 63\tTrain Loss: 2.3236538 \tVal Loss:2.2767827 \tTrain Acc: 23.04412% \tVal Acc: 22.9411772%\n",
      "Validation Loss decreased from 2.280275 to 2.276783, saving the model weights\n",
      "Epoch: 64\tTrain Loss: 2.3129126 \tVal Loss:2.2642164 \tTrain Acc: 23.69118% \tVal Acc: 24.7058831%\n",
      "Validation Loss decreased from 2.276783 to 2.264216, saving the model weights\n",
      "Epoch: 65\tTrain Loss: 2.2961721 \tVal Loss:2.2693761 \tTrain Acc: 23.91177% \tVal Acc: 23.8235301%\n",
      "Epoch: 66\tTrain Loss: 2.3105008 \tVal Loss:2.2660287 \tTrain Acc: 23.95588% \tVal Acc: 21.4705887%\n",
      "Epoch: 67\tTrain Loss: 2.2917732 \tVal Loss:2.2448122 \tTrain Acc: 24.29412% \tVal Acc: 23.0588241%\n",
      "Validation Loss decreased from 2.264216 to 2.244812, saving the model weights\n",
      "Epoch: 68\tTrain Loss: 2.2901344 \tVal Loss:2.2995386 \tTrain Acc: 23.80882% \tVal Acc: 23.0588239%\n",
      "Epoch: 69\tTrain Loss: 2.3130679 \tVal Loss:2.2755561 \tTrain Acc: 22.73529% \tVal Acc: 23.2941182%\n",
      "Epoch: 70\tTrain Loss: 2.3101997 \tVal Loss:2.4870751 \tTrain Acc: 23.08824% \tVal Acc: 16.1764710%\n",
      "Epoch: 71\tTrain Loss: 2.4067775 \tVal Loss:2.3099846 \tTrain Acc: 21.52941% \tVal Acc: 19.3529415%\n",
      "Epoch: 72\tTrain Loss: 2.3155235 \tVal Loss:2.3024765 \tTrain Acc: 23.07353% \tVal Acc: 21.4705887%\n",
      "Epoch: 73\tTrain Loss: 2.2894842 \tVal Loss:2.2858526 \tTrain Acc: 24.23529% \tVal Acc: 21.1176476%\n",
      "Epoch: 74\tTrain Loss: 2.2802352 \tVal Loss:2.2437323 \tTrain Acc: 24.66177% \tVal Acc: 24.1176479%\n",
      "Validation Loss decreased from 2.244812 to 2.243732, saving the model weights\n",
      "Epoch: 75\tTrain Loss: 2.2656181 \tVal Loss:2.2623341 \tTrain Acc: 24.79412% \tVal Acc: 21.6470595%\n",
      "Epoch: 76\tTrain Loss: 2.2559815 \tVal Loss:2.2762244 \tTrain Acc: 25.47059% \tVal Acc: 21.1764713%\n",
      "Epoch: 77\tTrain Loss: 2.2575587 \tVal Loss:2.2609091 \tTrain Acc: 25.66177% \tVal Acc: 21.8823536%\n",
      "Epoch: 78\tTrain Loss: 2.2601087 \tVal Loss:2.2288826 \tTrain Acc: 24.97059% \tVal Acc: 25.4705893%\n",
      "Validation Loss decreased from 2.243732 to 2.228883, saving the model weights\n",
      "Epoch: 79\tTrain Loss: 2.2539203 \tVal Loss:2.2803542 \tTrain Acc: 25.0% \tVal Acc: 20.4117654%\n",
      "Epoch: 80\tTrain Loss: 2.2423887 \tVal Loss:2.2180793 \tTrain Acc: 26.01471% \tVal Acc: 23.7647066%\n",
      "Validation Loss decreased from 2.228883 to 2.218079, saving the model weights\n",
      "Epoch: 81\tTrain Loss: 2.2315553 \tVal Loss:2.2024420 \tTrain Acc: 26.39706% \tVal Acc: 24.8235300%\n",
      "Validation Loss decreased from 2.218079 to 2.202442, saving the model weights\n",
      "Epoch: 82\tTrain Loss: 2.2296120 \tVal Loss:2.2692159 \tTrain Acc: 26.91177% \tVal Acc: 21.0000005%\n",
      "Epoch: 83\tTrain Loss: 2.2231063 \tVal Loss:2.2598866 \tTrain Acc: 27.13235% \tVal Acc: 20.4117651%\n",
      "Epoch: 84\tTrain Loss: 2.2098768 \tVal Loss:2.1966104 \tTrain Acc: 26.86765% \tVal Acc: 24.6470593%\n",
      "Validation Loss decreased from 2.202442 to 2.196610, saving the model weights\n",
      "Epoch: 85\tTrain Loss: 2.2035043 \tVal Loss:2.2524355 \tTrain Acc: 26.61765% \tVal Acc: 22.1764712%\n",
      "Epoch: 86\tTrain Loss: 2.2075637 \tVal Loss:2.2428931 \tTrain Acc: 26.44118% \tVal Acc: 22.7647063%\n",
      "Epoch: 87\tTrain Loss: 2.2127660 \tVal Loss:2.2245062 \tTrain Acc: 26.22059% \tVal Acc: 23.0000006%\n",
      "Epoch: 88\tTrain Loss: 2.2087871 \tVal Loss:2.2663006 \tTrain Acc: 26.64706% \tVal Acc: 22.2941183%\n",
      "Epoch: 89\tTrain Loss: 2.2373992 \tVal Loss:2.2418875 \tTrain Acc: 25.55882% \tVal Acc: 22.6470594%\n",
      "Epoch: 90\tTrain Loss: 2.2311272 \tVal Loss:2.1979233 \tTrain Acc: 26.04412% \tVal Acc: 24.6470594%\n",
      "Epoch: 91\tTrain Loss: 2.2061655 \tVal Loss:2.1536241 \tTrain Acc: 26.42647% \tVal Acc: 26.8823536%\n",
      "Validation Loss decreased from 2.196610 to 2.153624, saving the model weights\n",
      "Epoch: 92\tTrain Loss: 2.2032728 \tVal Loss:2.1508977 \tTrain Acc: 26.98529% \tVal Acc: 26.7058833%\n",
      "Validation Loss decreased from 2.153624 to 2.150898, saving the model weights\n",
      "Epoch: 93\tTrain Loss: 2.1777514 \tVal Loss:2.1462990 \tTrain Acc: 27.64706% \tVal Acc: 28.2941186%\n",
      "Validation Loss decreased from 2.150898 to 2.146299, saving the model weights\n",
      "Epoch: 94\tTrain Loss: 2.1683912 \tVal Loss:2.1382321 \tTrain Acc: 28.29412% \tVal Acc: 28.1176478%\n",
      "Validation Loss decreased from 2.146299 to 2.138232, saving the model weights\n",
      "Epoch: 95\tTrain Loss: 2.1558301 \tVal Loss:2.1132296 \tTrain Acc: 28.42647% \tVal Acc: 30.2352951%\n",
      "Validation Loss decreased from 2.138232 to 2.113230, saving the model weights\n",
      "Epoch: 96\tTrain Loss: 2.1493436 \tVal Loss:2.0903691 \tTrain Acc: 28.69118% \tVal Acc: 30.4705893%\n",
      "Validation Loss decreased from 2.113230 to 2.090369, saving the model weights\n",
      "Epoch: 97\tTrain Loss: 2.1304870 \tVal Loss:2.0911189 \tTrain Acc: 30.01471% \tVal Acc: 31.4705892%\n",
      "Epoch: 98\tTrain Loss: 2.1134704 \tVal Loss:2.1077360 \tTrain Acc: 30.70588% \tVal Acc: 28.6470599%\n",
      "Epoch: 99\tTrain Loss: 2.1208893 \tVal Loss:2.1114931 \tTrain Acc: 30.72059% \tVal Acc: 29.0000011%\n",
      "Epoch: 100\tTrain Loss: 2.1040459 \tVal Loss:2.0867596 \tTrain Acc: 30.58824% \tVal Acc: 30.8823541%\n",
      "Validation Loss decreased from 2.090369 to 2.086760, saving the model weights\n",
      "Epoch: 101\tTrain Loss: 2.1110884 \tVal Loss:2.0900619 \tTrain Acc: 30.69118% \tVal Acc: 30.7647069%\n",
      "Epoch: 102\tTrain Loss: 2.0939943 \tVal Loss:2.0644015 \tTrain Acc: 30.85294% \tVal Acc: 31.1176479%\n",
      "Validation Loss decreased from 2.086760 to 2.064402, saving the model weights\n",
      "Epoch: 103\tTrain Loss: 2.0782421 \tVal Loss:2.0513026 \tTrain Acc: 31.52941% \tVal Acc: 32.0000011%\n",
      "Validation Loss decreased from 2.064402 to 2.051303, saving the model weights\n",
      "Epoch: 104\tTrain Loss: 2.0695016 \tVal Loss:2.0664877 \tTrain Acc: 31.88235% \tVal Acc: 30.9411776%\n",
      "Epoch: 105\tTrain Loss: 2.0700978 \tVal Loss:2.0510224 \tTrain Acc: 32.51471% \tVal Acc: 32.4117656%\n",
      "Validation Loss decreased from 2.051303 to 2.051022, saving the model weights\n",
      "Epoch: 106\tTrain Loss: 2.0492335 \tVal Loss:2.0386198 \tTrain Acc: 32.73529% \tVal Acc: 30.7058834%\n",
      "Validation Loss decreased from 2.051022 to 2.038620, saving the model weights\n",
      "Epoch: 107\tTrain Loss: 2.0310643 \tVal Loss:2.0734469 \tTrain Acc: 33.42647% \tVal Acc: 30.2941187%\n",
      "Epoch: 108\tTrain Loss: 2.0558503 \tVal Loss:2.0593419 \tTrain Acc: 32.20588% \tVal Acc: 30.9411775%\n",
      "Epoch: 109\tTrain Loss: 2.0380316 \tVal Loss:2.0199072 \tTrain Acc: 32.61765% \tVal Acc: 31.7647070%\n",
      "Validation Loss decreased from 2.038620 to 2.019907, saving the model weights\n",
      "Epoch: 110\tTrain Loss: 2.0396380 \tVal Loss:2.0633885 \tTrain Acc: 32.67647% \tVal Acc: 30.1764718%\n",
      "Epoch: 111\tTrain Loss: 2.0403788 \tVal Loss:2.0525941 \tTrain Acc: 32.66177% \tVal Acc: 29.8823540%\n",
      "Epoch: 112\tTrain Loss: 2.0314442 \tVal Loss:2.0027550 \tTrain Acc: 33.30882% \tVal Acc: 32.4705891%\n",
      "Validation Loss decreased from 2.019907 to 2.002755, saving the model weights\n",
      "Epoch: 113\tTrain Loss: 2.0236147 \tVal Loss:2.0356046 \tTrain Acc: 33.20588% \tVal Acc: 31.2352952%\n",
      "Epoch: 114\tTrain Loss: 2.0066971 \tVal Loss:2.0283847 \tTrain Acc: 34.38235% \tVal Acc: 31.5882364%\n",
      "Epoch: 115\tTrain Loss: 1.9855689 \tVal Loss:1.9829602 \tTrain Acc: 34.39706% \tVal Acc: 33.8235304%\n",
      "Validation Loss decreased from 2.002755 to 1.982960, saving the model weights\n",
      "Epoch: 116\tTrain Loss: 1.9951336 \tVal Loss:1.9946854 \tTrain Acc: 34.58824% \tVal Acc: 32.8823540%\n",
      "Epoch: 117\tTrain Loss: 2.0134252 \tVal Loss:2.0408753 \tTrain Acc: 34.42647% \tVal Acc: 31.2941186%\n",
      "Epoch: 118\tTrain Loss: 1.9874704 \tVal Loss:2.0889110 \tTrain Acc: 33.75% \tVal Acc: 30.4705893%\n",
      "Epoch: 119\tTrain Loss: 2.0000155 \tVal Loss:2.0918629 \tTrain Acc: 34.36765% \tVal Acc: 30.4705891%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120\tTrain Loss: 1.9771446 \tVal Loss:2.0567003 \tTrain Acc: 34.61765% \tVal Acc: 31.8823539%\n",
      "Epoch: 121\tTrain Loss: 1.9675423 \tVal Loss:2.0594134 \tTrain Acc: 35.94118% \tVal Acc: 31.5882362%\n",
      "Epoch: 122\tTrain Loss: 1.9996448 \tVal Loss:2.0373172 \tTrain Acc: 34.60294% \tVal Acc: 33.0000010%\n",
      "Epoch: 123\tTrain Loss: 1.9988202 \tVal Loss:2.0386911 \tTrain Acc: 34.60294% \tVal Acc: 32.4705891%\n",
      "Epoch: 124\tTrain Loss: 2.0203782 \tVal Loss:2.0451034 \tTrain Acc: 33.77941% \tVal Acc: 32.1176481%\n",
      "Epoch: 125\tTrain Loss: 2.0059780 \tVal Loss:2.1394418 \tTrain Acc: 34.42647% \tVal Acc: 29.7647066%\n",
      "Epoch: 126\tTrain Loss: 2.0516317 \tVal Loss:2.0179561 \tTrain Acc: 33.60294% \tVal Acc: 35.0588244%\n",
      "Epoch: 127\tTrain Loss: 2.0269356 \tVal Loss:1.9187212 \tTrain Acc: 33.75% \tVal Acc: 38.1176478%\n",
      "Validation Loss decreased from 1.982960 to 1.918721, saving the model weights\n",
      "Epoch: 128\tTrain Loss: 2.0088487 \tVal Loss:1.9355093 \tTrain Acc: 34.44118% \tVal Acc: 37.6470596%\n",
      "Epoch: 129\tTrain Loss: 1.9918451 \tVal Loss:1.9164649 \tTrain Acc: 34.52941% \tVal Acc: 38.5882360%\n",
      "Validation Loss decreased from 1.918721 to 1.916465, saving the model weights\n",
      "Epoch: 130\tTrain Loss: 1.9344335 \tVal Loss:1.9467520 \tTrain Acc: 36.80882% \tVal Acc: 36.2352948%\n",
      "Epoch: 131\tTrain Loss: 1.9237946 \tVal Loss:1.8967893 \tTrain Acc: 37.16177% \tVal Acc: 39.2941183%\n",
      "Validation Loss decreased from 1.916465 to 1.896789, saving the model weights\n",
      "Epoch: 132\tTrain Loss: 1.8670546 \tVal Loss:1.8107455 \tTrain Acc: 38.54412% \tVal Acc: 41.4705887%\n",
      "Validation Loss decreased from 1.896789 to 1.810746, saving the model weights\n",
      "Epoch: 133\tTrain Loss: 1.8454001 \tVal Loss:1.7830119 \tTrain Acc: 40.0% \tVal Acc: 41.5882358%\n",
      "Validation Loss decreased from 1.810746 to 1.783012, saving the model weights\n",
      "Epoch: 134\tTrain Loss: 1.8114610 \tVal Loss:1.7192677 \tTrain Acc: 40.89706% \tVal Acc: 44.1764709%\n",
      "Validation Loss decreased from 1.783012 to 1.719268, saving the model weights\n",
      "Epoch: 135\tTrain Loss: 1.7769958 \tVal Loss:1.7258947 \tTrain Acc: 42.23529% \tVal Acc: 45.0588241%\n",
      "Epoch: 136\tTrain Loss: 1.7849174 \tVal Loss:1.6745627 \tTrain Acc: 41.95588% \tVal Acc: 45.9411767%\n",
      "Validation Loss decreased from 1.719268 to 1.674563, saving the model weights\n",
      "Epoch: 137\tTrain Loss: 1.7604547 \tVal Loss:1.6871543 \tTrain Acc: 42.86765% \tVal Acc: 45.7647064%\n",
      "Epoch: 138\tTrain Loss: 1.7569504 \tVal Loss:1.6580607 \tTrain Acc: 42.55882% \tVal Acc: 48.4705886%\n",
      "Validation Loss decreased from 1.674563 to 1.658061, saving the model weights\n",
      "Epoch: 139\tTrain Loss: 1.7370210 \tVal Loss:1.6835664 \tTrain Acc: 44.04412% \tVal Acc: 46.3529420%\n",
      "Epoch: 140\tTrain Loss: 1.7363207 \tVal Loss:1.6418199 \tTrain Acc: 43.51471% \tVal Acc: 48.2352945%\n",
      "Validation Loss decreased from 1.658061 to 1.641820, saving the model weights\n",
      "Epoch: 141\tTrain Loss: 1.7183021 \tVal Loss:1.6458353 \tTrain Acc: 44.76471% \tVal Acc: 47.3529416%\n",
      "Epoch: 142\tTrain Loss: 1.7161788 \tVal Loss:1.6339329 \tTrain Acc: 45.08824% \tVal Acc: 47.8235298%\n",
      "Validation Loss decreased from 1.641820 to 1.633933, saving the model weights\n",
      "Epoch: 143\tTrain Loss: 1.6900308 \tVal Loss:1.6192706 \tTrain Acc: 44.88235% \tVal Acc: 47.7058831%\n",
      "Validation Loss decreased from 1.633933 to 1.619271, saving the model weights\n",
      "Epoch: 144\tTrain Loss: 1.6700958 \tVal Loss:1.5646158 \tTrain Acc: 46.22059% \tVal Acc: 51.5294120%\n",
      "Validation Loss decreased from 1.619271 to 1.564616, saving the model weights\n",
      "Epoch: 145\tTrain Loss: 1.6730250 \tVal Loss:1.5939053 \tTrain Acc: 45.85294% \tVal Acc: 50.2352947%\n",
      "Epoch: 146\tTrain Loss: 1.6520374 \tVal Loss:1.5801600 \tTrain Acc: 46.44118% \tVal Acc: 50.2941188%\n",
      "Epoch: 147\tTrain Loss: 1.6478289 \tVal Loss:1.5868174 \tTrain Acc: 46.52941% \tVal Acc: 50.0588247%\n",
      "Epoch: 148\tTrain Loss: 1.6619134 \tVal Loss:1.5298415 \tTrain Acc: 46.22059% \tVal Acc: 53.4705892%\n",
      "Validation Loss decreased from 1.564616 to 1.529842, saving the model weights\n",
      "Epoch: 149\tTrain Loss: 1.6383161 \tVal Loss:1.5421666 \tTrain Acc: 47.11765% \tVal Acc: 51.2352949%\n",
      "Epoch: 150\tTrain Loss: 1.5904516 \tVal Loss:1.5369951 \tTrain Acc: 48.83824% \tVal Acc: 51.4705887%\n",
      "Epoch: 151\tTrain Loss: 1.6035757 \tVal Loss:1.5263280 \tTrain Acc: 49.05882% \tVal Acc: 51.8235302%\n",
      "Validation Loss decreased from 1.529842 to 1.526328, saving the model weights\n",
      "Epoch: 152\tTrain Loss: 1.5977934 \tVal Loss:1.5106016 \tTrain Acc: 48.41177% \tVal Acc: 52.8235298%\n",
      "Validation Loss decreased from 1.526328 to 1.510602, saving the model weights\n",
      "Epoch: 153\tTrain Loss: 1.5900881 \tVal Loss:1.4980268 \tTrain Acc: 47.94118% \tVal Acc: 51.5294126%\n",
      "Validation Loss decreased from 1.510602 to 1.498027, saving the model weights\n",
      "Epoch: 154\tTrain Loss: 1.5797827 \tVal Loss:1.4900261 \tTrain Acc: 49.23529% \tVal Acc: 54.3529424%\n",
      "Validation Loss decreased from 1.498027 to 1.490026, saving the model weights\n",
      "Epoch: 155\tTrain Loss: 1.5650464 \tVal Loss:1.4763898 \tTrain Acc: 50.17647% \tVal Acc: 54.2941183%\n",
      "Validation Loss decreased from 1.490026 to 1.476390, saving the model weights\n",
      "Epoch: 156\tTrain Loss: 1.5353677 \tVal Loss:1.4915118 \tTrain Acc: 50.94118% \tVal Acc: 53.4117654%\n",
      "Epoch: 157\tTrain Loss: 1.5346706 \tVal Loss:1.4090683 \tTrain Acc: 50.51471% \tVal Acc: 57.2352946%\n",
      "Validation Loss decreased from 1.476390 to 1.409068, saving the model weights\n",
      "Epoch: 158\tTrain Loss: 1.5251161 \tVal Loss:1.4795183 \tTrain Acc: 51.45588% \tVal Acc: 53.5294127%\n",
      "Epoch: 159\tTrain Loss: 1.5074857 \tVal Loss:1.5347091 \tTrain Acc: 51.70588% \tVal Acc: 51.5294120%\n",
      "Epoch: 160\tTrain Loss: 1.5387336 \tVal Loss:1.5471745 \tTrain Acc: 50.19118% \tVal Acc: 49.4705886%\n",
      "Epoch: 161\tTrain Loss: 1.5002450 \tVal Loss:1.4473182 \tTrain Acc: 50.97059% \tVal Acc: 55.4117650%\n",
      "Epoch: 162\tTrain Loss: 1.4390617 \tVal Loss:1.4882122 \tTrain Acc: 53.51471% \tVal Acc: 53.5294124%\n",
      "Epoch: 163\tTrain Loss: 1.4711479 \tVal Loss:1.5115472 \tTrain Acc: 52.91177% \tVal Acc: 52.8235304%\n",
      "Epoch: 164\tTrain Loss: 1.4511728 \tVal Loss:1.3560942 \tTrain Acc: 53.75% \tVal Acc: 59.0588251%\n",
      "Validation Loss decreased from 1.409068 to 1.356094, saving the model weights\n",
      "Epoch: 165\tTrain Loss: 1.4065360 \tVal Loss:1.3277646 \tTrain Acc: 55.20588% \tVal Acc: 60.0588241%\n",
      "Validation Loss decreased from 1.356094 to 1.327765, saving the model weights\n",
      "Epoch: 166\tTrain Loss: 1.4229271 \tVal Loss:1.3325635 \tTrain Acc: 55.0% \tVal Acc: 60.5294117%\n",
      "Epoch: 167\tTrain Loss: 1.4292326 \tVal Loss:1.3914871 \tTrain Acc: 55.0% \tVal Acc: 57.7058831%\n",
      "Epoch: 168\tTrain Loss: 1.4343616 \tVal Loss:1.3343760 \tTrain Acc: 54.01471% \tVal Acc: 57.7058837%\n",
      "Epoch: 169\tTrain Loss: 1.3728030 \tVal Loss:1.2410863 \tTrain Acc: 55.91177% \tVal Acc: 63.7647069%\n",
      "Validation Loss decreased from 1.327765 to 1.241086, saving the model weights\n",
      "Epoch: 170\tTrain Loss: 1.3346054 \tVal Loss:1.2538459 \tTrain Acc: 57.58824% \tVal Acc: 60.7647070%\n",
      "Epoch: 171\tTrain Loss: 1.3272722 \tVal Loss:1.2253591 \tTrain Acc: 58.17647% \tVal Acc: 63.5294127%\n",
      "Validation Loss decreased from 1.241086 to 1.225359, saving the model weights\n",
      "Epoch: 172\tTrain Loss: 1.2986581 \tVal Loss:1.1837576 \tTrain Acc: 58.77941% \tVal Acc: 64.5294121%\n",
      "Validation Loss decreased from 1.225359 to 1.183758, saving the model weights\n",
      "Epoch: 173\tTrain Loss: 1.2663142 \tVal Loss:1.2040535 \tTrain Acc: 60.04412% \tVal Acc: 63.7058830%\n",
      "Epoch: 174\tTrain Loss: 1.2676524 \tVal Loss:1.2118792 \tTrain Acc: 59.79412% \tVal Acc: 62.5294125%\n",
      "Epoch: 175\tTrain Loss: 1.2809542 \tVal Loss:1.1308354 \tTrain Acc: 59.70588% \tVal Acc: 66.9411778%\n",
      "Validation Loss decreased from 1.183758 to 1.130835, saving the model weights\n",
      "Epoch: 176\tTrain Loss: 1.2618028 \tVal Loss:1.1899255 \tTrain Acc: 60.27941% \tVal Acc: 62.4117649%\n",
      "Epoch: 177\tTrain Loss: 1.2488750 \tVal Loss:1.1719689 \tTrain Acc: 60.13235% \tVal Acc: 65.2352947%\n",
      "Epoch: 178\tTrain Loss: 1.2557320 \tVal Loss:1.1599738 \tTrain Acc: 59.89706% \tVal Acc: 65.5882353%\n",
      "Epoch: 179\tTrain Loss: 1.2337703 \tVal Loss:1.1101613 \tTrain Acc: 60.55882% \tVal Acc: 65.7647067%\n",
      "Validation Loss decreased from 1.130835 to 1.110161, saving the model weights\n",
      "Epoch: 180\tTrain Loss: 1.2260785 \tVal Loss:1.1210850 \tTrain Acc: 61.11765% \tVal Acc: 65.4705894%\n",
      "Epoch: 181\tTrain Loss: 1.2045266 \tVal Loss:1.1155038 \tTrain Acc: 62.25% \tVal Acc: 66.2941176%\n",
      "Epoch: 182\tTrain Loss: 1.2181545 \tVal Loss:1.1281702 \tTrain Acc: 61.69118% \tVal Acc: 65.2941179%\n",
      "Epoch: 183\tTrain Loss: 1.2073272 \tVal Loss:1.0554416 \tTrain Acc: 61.92647% \tVal Acc: 70.5294114%\n",
      "Validation Loss decreased from 1.110161 to 1.055442, saving the model weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 184\tTrain Loss: 1.1526139 \tVal Loss:1.0428177 \tTrain Acc: 63.79412% \tVal Acc: 70.3529418%\n",
      "Validation Loss decreased from 1.055442 to 1.042818, saving the model weights\n",
      "Epoch: 185\tTrain Loss: 1.1500479 \tVal Loss:1.0034060 \tTrain Acc: 64.48529% \tVal Acc: 68.9999998%\n",
      "Validation Loss decreased from 1.042818 to 1.003406, saving the model weights\n",
      "Epoch: 186\tTrain Loss: 1.1605620 \tVal Loss:0.9731079 \tTrain Acc: 63.75% \tVal Acc: 71.9999999%\n",
      "Validation Loss decreased from 1.003406 to 0.973108, saving the model weights\n",
      "Epoch: 187\tTrain Loss: 1.1285251 \tVal Loss:0.9957729 \tTrain Acc: 65.0% \tVal Acc: 70.7058823%\n",
      "Epoch: 188\tTrain Loss: 1.1266726 \tVal Loss:1.0095059 \tTrain Acc: 64.57353% \tVal Acc: 70.6470585%\n",
      "Epoch: 189\tTrain Loss: 1.1541574 \tVal Loss:0.9908749 \tTrain Acc: 63.85294% \tVal Acc: 72.1764708%\n",
      "Epoch: 190\tTrain Loss: 1.1243684 \tVal Loss:0.9373568 \tTrain Acc: 64.23529% \tVal Acc: 72.5294119%\n",
      "Validation Loss decreased from 0.973108 to 0.937357, saving the model weights\n",
      "Epoch: 191\tTrain Loss: 1.1014417 \tVal Loss:0.9147727 \tTrain Acc: 65.82353% \tVal Acc: 73.9999998%\n",
      "Validation Loss decreased from 0.937357 to 0.914773, saving the model weights\n",
      "Epoch: 192\tTrain Loss: 1.0836713 \tVal Loss:0.8826951 \tTrain Acc: 66.26471% \tVal Acc: 75.5294114%\n",
      "Validation Loss decreased from 0.914773 to 0.882695, saving the model weights\n",
      "Epoch: 193\tTrain Loss: 1.0268761 \tVal Loss:1.0177661 \tTrain Acc: 67.98529% \tVal Acc: 70.7647067%\n",
      "Epoch: 194\tTrain Loss: 1.0394701 \tVal Loss:1.0077698 \tTrain Acc: 66.75% \tVal Acc: 71.1176467%\n",
      "Epoch: 195\tTrain Loss: 1.0270274 \tVal Loss:0.9385520 \tTrain Acc: 67.67647% \tVal Acc: 73.5294122%\n",
      "Epoch: 196\tTrain Loss: 1.0205084 \tVal Loss:0.8239271 \tTrain Acc: 68.01471% \tVal Acc: 76.9411767%\n",
      "Validation Loss decreased from 0.882695 to 0.823927, saving the model weights\n",
      "Epoch: 197\tTrain Loss: 0.9868947 \tVal Loss:0.7871264 \tTrain Acc: 69.41177% \tVal Acc: 78.5294110%\n",
      "Validation Loss decreased from 0.823927 to 0.787126, saving the model weights\n",
      "Epoch: 198\tTrain Loss: 0.9398918 \tVal Loss:0.7667549 \tTrain Acc: 71.16177% \tVal Acc: 79.2941171%\n",
      "Validation Loss decreased from 0.787126 to 0.766755, saving the model weights\n",
      "Epoch: 199\tTrain Loss: 0.9443332 \tVal Loss:0.7928355 \tTrain Acc: 70.70588% \tVal Acc: 77.6470590%\n",
      "Epoch: 200\tTrain Loss: 0.9424716 \tVal Loss:0.8897514 \tTrain Acc: 70.89706% \tVal Acc: 73.9411759%\n",
      "Epoch: 201\tTrain Loss: 0.9470334 \tVal Loss:0.7998960 \tTrain Acc: 70.23529% \tVal Acc: 77.7058822%\n",
      "Epoch: 202\tTrain Loss: 0.9190933 \tVal Loss:0.7430307 \tTrain Acc: 70.77941% \tVal Acc: 79.1764706%\n",
      "Validation Loss decreased from 0.766755 to 0.743031, saving the model weights\n",
      "Epoch: 203\tTrain Loss: 0.8982674 \tVal Loss:0.6920851 \tTrain Acc: 72.33824% \tVal Acc: 82.1176463%\n",
      "Validation Loss decreased from 0.743031 to 0.692085, saving the model weights\n",
      "Epoch: 204\tTrain Loss: 0.8804841 \tVal Loss:0.7314474 \tTrain Acc: 72.70588% \tVal Acc: 80.8235288%\n",
      "Epoch: 205\tTrain Loss: 0.8768533 \tVal Loss:0.7112596 \tTrain Acc: 72.51471% \tVal Acc: 81.1176461%\n",
      "Epoch: 206\tTrain Loss: 0.8787560 \tVal Loss:0.6766452 \tTrain Acc: 72.36765% \tVal Acc: 81.4117640%\n",
      "Validation Loss decreased from 0.692085 to 0.676645, saving the model weights\n",
      "Epoch: 207\tTrain Loss: 0.8532252 \tVal Loss:0.6907511 \tTrain Acc: 73.52941% \tVal Acc: 81.4117640%\n",
      "Epoch: 208\tTrain Loss: 0.8368349 \tVal Loss:0.6747783 \tTrain Acc: 73.89706% \tVal Acc: 82.2352928%\n",
      "Validation Loss decreased from 0.676645 to 0.674778, saving the model weights\n",
      "Epoch: 209\tTrain Loss: 0.8184471 \tVal Loss:0.6825882 \tTrain Acc: 74.51471% \tVal Acc: 81.7647046%\n",
      "Epoch: 210\tTrain Loss: 0.8133064 \tVal Loss:0.7089970 \tTrain Acc: 75.08824% \tVal Acc: 80.4117638%\n",
      "Epoch: 211\tTrain Loss: 0.8264514 \tVal Loss:0.6005996 \tTrain Acc: 74.5% \tVal Acc: 84.8235285%\n",
      "Validation Loss decreased from 0.674778 to 0.600600, saving the model weights\n",
      "Epoch: 212\tTrain Loss: 0.7933058 \tVal Loss:0.6571984 \tTrain Acc: 75.44118% \tVal Acc: 82.5882351%\n",
      "Epoch: 213\tTrain Loss: 0.7874150 \tVal Loss:0.5502055 \tTrain Acc: 75.60294% \tVal Acc: 86.7058814%\n",
      "Validation Loss decreased from 0.600600 to 0.550205, saving the model weights\n",
      "Epoch: 214\tTrain Loss: 0.7449294 \tVal Loss:0.4967006 \tTrain Acc: 77.17647% \tVal Acc: 88.5294110%\n",
      "Validation Loss decreased from 0.550205 to 0.496701, saving the model weights\n",
      "Epoch: 215\tTrain Loss: 0.7352765 \tVal Loss:0.4995288 \tTrain Acc: 77.51471% \tVal Acc: 88.1764698%\n",
      "Epoch: 216\tTrain Loss: 0.7281273 \tVal Loss:0.4839916 \tTrain Acc: 77.76471% \tVal Acc: 88.8235289%\n",
      "Validation Loss decreased from 0.496701 to 0.483992, saving the model weights\n",
      "Epoch: 217\tTrain Loss: 0.7315928 \tVal Loss:0.5046734 \tTrain Acc: 77.82353% \tVal Acc: 87.8235286%\n",
      "Epoch: 218\tTrain Loss: 0.7536057 \tVal Loss:0.5387161 \tTrain Acc: 76.94118% \tVal Acc: 87.6470578%\n",
      "Epoch: 219\tTrain Loss: 0.7244059 \tVal Loss:0.5535058 \tTrain Acc: 77.23529% \tVal Acc: 85.8823532%\n",
      "Epoch: 220\tTrain Loss: 0.7299363 \tVal Loss:0.5712123 \tTrain Acc: 77.08824% \tVal Acc: 85.2941173%\n",
      "Epoch: 221\tTrain Loss: 0.7045541 \tVal Loss:0.6015032 \tTrain Acc: 78.13235% \tVal Acc: 84.1764694%\n",
      "Epoch: 222\tTrain Loss: 0.7027607 \tVal Loss:0.6395287 \tTrain Acc: 78.14706% \tVal Acc: 82.7058810%\n",
      "Epoch: 223\tTrain Loss: 0.7080208 \tVal Loss:0.5553448 \tTrain Acc: 78.07353% \tVal Acc: 86.1176461%\n",
      "Epoch: 224\tTrain Loss: 0.6784986 \tVal Loss:0.6435863 \tTrain Acc: 79.05882% \tVal Acc: 83.3529401%\n",
      "Epoch: 225\tTrain Loss: 0.6612329 \tVal Loss:0.4648849 \tTrain Acc: 79.64706% \tVal Acc: 89.4117635%\n",
      "Validation Loss decreased from 0.483992 to 0.464885, saving the model weights\n",
      "Epoch: 226\tTrain Loss: 0.6737977 \tVal Loss:0.4697095 \tTrain Acc: 79.33824% \tVal Acc: 89.1764700%\n",
      "Epoch: 227\tTrain Loss: 0.6437494 \tVal Loss:0.4406641 \tTrain Acc: 80.30882% \tVal Acc: 88.7058812%\n",
      "Validation Loss decreased from 0.464885 to 0.440664, saving the model weights\n",
      "Epoch: 228\tTrain Loss: 0.6232037 \tVal Loss:0.3973210 \tTrain Acc: 81.23529% \tVal Acc: 91.1176455%\n",
      "Validation Loss decreased from 0.440664 to 0.397321, saving the model weights\n",
      "Epoch: 229\tTrain Loss: 0.6162950 \tVal Loss:0.3743591 \tTrain Acc: 81.17647% \tVal Acc: 91.8235278%\n",
      "Validation Loss decreased from 0.397321 to 0.374359, saving the model weights\n",
      "Epoch: 230\tTrain Loss: 0.5868389 \tVal Loss:0.4557010 \tTrain Acc: 82.08823% \tVal Acc: 89.5294112%\n",
      "Epoch: 231\tTrain Loss: 0.5706961 \tVal Loss:0.4579890 \tTrain Acc: 82.61765% \tVal Acc: 88.5294116%\n",
      "Epoch: 232\tTrain Loss: 0.5771401 \tVal Loss:0.3763023 \tTrain Acc: 83.08823% \tVal Acc: 91.4705878%\n",
      "Epoch: 233\tTrain Loss: 0.5487863 \tVal Loss:0.3504608 \tTrain Acc: 83.86765% \tVal Acc: 92.0588237%\n",
      "Validation Loss decreased from 0.374359 to 0.350461, saving the model weights\n",
      "Epoch: 234\tTrain Loss: 0.5393983 \tVal Loss:0.2979671 \tTrain Acc: 83.86765% \tVal Acc: 94.2941159%\n",
      "Validation Loss decreased from 0.350461 to 0.297967, saving the model weights\n",
      "Epoch: 235\tTrain Loss: 0.5351642 \tVal Loss:0.3620508 \tTrain Acc: 83.85294% \tVal Acc: 92.0588219%\n",
      "Epoch: 236\tTrain Loss: 0.5204902 \tVal Loss:0.3102785 \tTrain Acc: 84.5% \tVal Acc: 92.6470578%\n",
      "Epoch: 237\tTrain Loss: 0.5377753 \tVal Loss:0.3265046 \tTrain Acc: 83.48529% \tVal Acc: 93.6470574%\n",
      "Epoch: 238\tTrain Loss: 0.5638251 \tVal Loss:0.4084201 \tTrain Acc: 83.61765% \tVal Acc: 90.3529394%\n",
      "Epoch: 239\tTrain Loss: 0.5443568 \tVal Loss:0.4041259 \tTrain Acc: 83.07353% \tVal Acc: 89.3529397%\n",
      "Epoch: 240\tTrain Loss: 0.5452621 \tVal Loss:0.3454764 \tTrain Acc: 83.75% \tVal Acc: 90.9411746%\n",
      "Epoch: 241\tTrain Loss: 0.5226683 \tVal Loss:0.3202899 \tTrain Acc: 84.29412% \tVal Acc: 93.1176472%\n",
      "Epoch: 242\tTrain Loss: 0.5094186 \tVal Loss:0.3100411 \tTrain Acc: 84.5% \tVal Acc: 93.6470574%\n",
      "Epoch: 243\tTrain Loss: 0.4764624 \tVal Loss:0.2658556 \tTrain Acc: 85.86765% \tVal Acc: 94.2352933%\n",
      "Validation Loss decreased from 0.297967 to 0.265856, saving the model weights\n",
      "Epoch: 244\tTrain Loss: 0.4531473 \tVal Loss:0.2561229 \tTrain Acc: 86.32353% \tVal Acc: 94.8235285%\n",
      "Validation Loss decreased from 0.265856 to 0.256123, saving the model weights\n",
      "Epoch: 245\tTrain Loss: 0.4488908 \tVal Loss:0.2260496 \tTrain Acc: 86.77941% \tVal Acc: 95.9411746%\n",
      "Validation Loss decreased from 0.256123 to 0.226050, saving the model weights\n",
      "Epoch: 246\tTrain Loss: 0.4611075 \tVal Loss:0.3064417 \tTrain Acc: 86.35294% \tVal Acc: 92.9411763%\n",
      "Epoch: 247\tTrain Loss: 0.4982252 \tVal Loss:0.2641590 \tTrain Acc: 84.82353% \tVal Acc: 94.8235279%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 248\tTrain Loss: 0.4725954 \tVal Loss:0.2737461 \tTrain Acc: 85.94118% \tVal Acc: 93.8823521%\n",
      "Epoch: 249\tTrain Loss: 0.4660373 \tVal Loss:0.2745495 \tTrain Acc: 86.14706% \tVal Acc: 93.6470574%\n",
      "Epoch: 250\tTrain Loss: 0.4645251 \tVal Loss:0.3275952 \tTrain Acc: 85.98529% \tVal Acc: 91.0588217%\n",
      "Epoch: 251\tTrain Loss: 0.4793014 \tVal Loss:0.3410774 \tTrain Acc: 85.92647% \tVal Acc: 91.1176455%\n",
      "Epoch: 252\tTrain Loss: 0.4808467 \tVal Loss:0.2791814 \tTrain Acc: 85.48529% \tVal Acc: 93.0588222%\n",
      "Epoch: 253\tTrain Loss: 0.4707140 \tVal Loss:0.2471502 \tTrain Acc: 85.52941% \tVal Acc: 94.7058821%\n",
      "Epoch: 254\tTrain Loss: 0.4407174 \tVal Loss:0.2275843 \tTrain Acc: 87.10294% \tVal Acc: 95.5882335%\n",
      "Epoch: 255\tTrain Loss: 0.4192215 \tVal Loss:0.1943141 \tTrain Acc: 87.44118% \tVal Acc: 96.1176461%\n",
      "Validation Loss decreased from 0.226050 to 0.194314, saving the model weights\n",
      "Epoch: 256\tTrain Loss: 0.3825817 \tVal Loss:0.1647053 \tTrain Acc: 88.70588% \tVal Acc: 97.2352928%\n",
      "Validation Loss decreased from 0.194314 to 0.164705, saving the model weights\n",
      "Epoch: 257\tTrain Loss: 0.3624867 \tVal Loss:0.1632145 \tTrain Acc: 89.26471% \tVal Acc: 97.6470584%\n",
      "Validation Loss decreased from 0.164705 to 0.163214, saving the model weights\n",
      "Epoch: 258\tTrain Loss: 0.3643717 \tVal Loss:0.1654367 \tTrain Acc: 89.64706% \tVal Acc: 96.9411755%\n",
      "Epoch: 259\tTrain Loss: 0.3520510 \tVal Loss:0.1408887 \tTrain Acc: 90.08823% \tVal Acc: 97.3529398%\n",
      "Validation Loss decreased from 0.163214 to 0.140889, saving the model weights\n",
      "Epoch: 260\tTrain Loss: 0.3316369 \tVal Loss:0.1547856 \tTrain Acc: 90.94118% \tVal Acc: 97.2352916%\n",
      "Epoch: 261\tTrain Loss: 0.3349247 \tVal Loss:0.1599721 \tTrain Acc: 90.48529% \tVal Acc: 96.7647046%\n",
      "Epoch: 262\tTrain Loss: 0.3436656 \tVal Loss:0.1763249 \tTrain Acc: 90.27941% \tVal Acc: 96.0588229%\n",
      "Epoch: 263\tTrain Loss: 0.3219672 \tVal Loss:0.1378735 \tTrain Acc: 90.92647% \tVal Acc: 97.8235286%\n",
      "Validation Loss decreased from 0.140889 to 0.137873, saving the model weights\n",
      "Epoch: 264\tTrain Loss: 0.3136375 \tVal Loss:0.1438064 \tTrain Acc: 91.25% \tVal Acc: 96.9999975%\n",
      "Epoch: 265\tTrain Loss: 0.3189059 \tVal Loss:0.1366809 \tTrain Acc: 90.83823% \tVal Acc: 97.7058810%\n",
      "Validation Loss decreased from 0.137873 to 0.136681, saving the model weights\n",
      "Epoch: 266\tTrain Loss: 0.3370586 \tVal Loss:0.1435897 \tTrain Acc: 90.36765% \tVal Acc: 97.5294101%\n",
      "Epoch: 267\tTrain Loss: 0.3475137 \tVal Loss:0.1672582 \tTrain Acc: 90.04412% \tVal Acc: 96.5294105%\n",
      "Epoch: 268\tTrain Loss: 0.3834984 \tVal Loss:0.2024688 \tTrain Acc: 88.54412% \tVal Acc: 95.1764691%\n",
      "Epoch: 269\tTrain Loss: 0.3876522 \tVal Loss:0.2491002 \tTrain Acc: 88.27941% \tVal Acc: 94.4705874%\n",
      "Epoch: 270\tTrain Loss: 0.3751743 \tVal Loss:0.2078966 \tTrain Acc: 88.97059% \tVal Acc: 94.7058809%\n",
      "Epoch: 271\tTrain Loss: 0.3569171 \tVal Loss:0.1596957 \tTrain Acc: 89.42647% \tVal Acc: 96.8823510%\n",
      "Epoch: 272\tTrain Loss: 0.3153542 \tVal Loss:0.1442163 \tTrain Acc: 90.60294% \tVal Acc: 96.8823522%\n",
      "Epoch: 273\tTrain Loss: 0.2984576 \tVal Loss:0.1315348 \tTrain Acc: 91.88235% \tVal Acc: 97.4117637%\n",
      "Validation Loss decreased from 0.136681 to 0.131535, saving the model weights\n",
      "Epoch: 274\tTrain Loss: 0.2796461 \tVal Loss:0.1106119 \tTrain Acc: 91.97059% \tVal Acc: 97.8823519%\n",
      "Validation Loss decreased from 0.131535 to 0.110612, saving the model weights\n",
      "Epoch: 275\tTrain Loss: 0.2840663 \tVal Loss:0.1593053 \tTrain Acc: 91.69118% \tVal Acc: 96.8823516%\n",
      "Epoch: 276\tTrain Loss: 0.2914070 \tVal Loss:0.1420618 \tTrain Acc: 91.55882% \tVal Acc: 97.1176457%\n",
      "Epoch: 277\tTrain Loss: 0.2692495 \tVal Loss:0.1078461 \tTrain Acc: 92.97059% \tVal Acc: 98.1764698%\n",
      "Validation Loss decreased from 0.110612 to 0.107846, saving the model weights\n",
      "Epoch: 278\tTrain Loss: 0.2762232 \tVal Loss:0.1011273 \tTrain Acc: 91.89706% \tVal Acc: 98.3529395%\n",
      "Validation Loss decreased from 0.107846 to 0.101127, saving the model weights\n",
      "Epoch: 279\tTrain Loss: 0.2649213 \tVal Loss:0.1374131 \tTrain Acc: 92.67647% \tVal Acc: 97.2941166%\n",
      "Epoch: 280\tTrain Loss: 0.2609892 \tVal Loss:0.1201508 \tTrain Acc: 92.86765% \tVal Acc: 97.7647054%\n",
      "Epoch: 281\tTrain Loss: 0.2912297 \tVal Loss:0.2171059 \tTrain Acc: 92.0% \tVal Acc: 94.7058815%\n",
      "Epoch: 282\tTrain Loss: 0.3954622 \tVal Loss:0.2974984 \tTrain Acc: 88.69118% \tVal Acc: 91.5294099%\n",
      "Epoch: 283\tTrain Loss: 0.4028443 \tVal Loss:0.2305017 \tTrain Acc: 87.61765% \tVal Acc: 94.1176456%\n",
      "Epoch: 284\tTrain Loss: 0.3808575 \tVal Loss:0.2421846 \tTrain Acc: 88.13235% \tVal Acc: 93.4705871%\n",
      "Epoch: 285\tTrain Loss: 0.3436727 \tVal Loss:0.1583993 \tTrain Acc: 89.72059% \tVal Acc: 96.4705867%\n",
      "Epoch: 286\tTrain Loss: 0.2974378 \tVal Loss:0.1633696 \tTrain Acc: 91.14706% \tVal Acc: 96.5294105%\n",
      "Epoch: 287\tTrain Loss: 0.2645786 \tVal Loss:0.1396657 \tTrain Acc: 92.23529% \tVal Acc: 96.8235284%\n",
      "Epoch: 288\tTrain Loss: 0.2519476 \tVal Loss:0.1091005 \tTrain Acc: 92.82353% \tVal Acc: 98.0588216%\n",
      "Epoch: 289\tTrain Loss: 0.2296372 \tVal Loss:0.1048715 \tTrain Acc: 93.97059% \tVal Acc: 98.1764698%\n",
      "Epoch: 290\tTrain Loss: 0.2291938 \tVal Loss:0.1167789 \tTrain Acc: 93.61765% \tVal Acc: 97.9999989%\n",
      "Epoch: 291\tTrain Loss: 0.2162004 \tVal Loss:0.1137434 \tTrain Acc: 94.29412% \tVal Acc: 97.7647054%\n",
      "Epoch: 292\tTrain Loss: 0.2263579 \tVal Loss:0.1822608 \tTrain Acc: 93.82353% \tVal Acc: 95.2352929%\n",
      "Epoch: 293\tTrain Loss: 0.2303858 \tVal Loss:0.1327508 \tTrain Acc: 93.52941% \tVal Acc: 97.4117625%\n",
      "Epoch: 294\tTrain Loss: 0.2408748 \tVal Loss:0.1318987 \tTrain Acc: 93.16176% \tVal Acc: 96.7647040%\n",
      "Epoch: 295\tTrain Loss: 0.2495497 \tVal Loss:0.1251328 \tTrain Acc: 92.77941% \tVal Acc: 96.7647052%\n",
      "Epoch: 296\tTrain Loss: 0.2523559 \tVal Loss:0.1302139 \tTrain Acc: 93.0% \tVal Acc: 97.0588231%\n",
      "Epoch: 297\tTrain Loss: 0.2586616 \tVal Loss:0.0952183 \tTrain Acc: 92.38235% \tVal Acc: 98.4705865%\n",
      "Validation Loss decreased from 0.101127 to 0.095218, saving the model weights\n",
      "Epoch: 298\tTrain Loss: 0.2584331 \tVal Loss:0.1408370 \tTrain Acc: 92.80882% \tVal Acc: 96.7647052%\n",
      "Epoch: 299\tTrain Loss: 0.2478335 \tVal Loss:0.1390537 \tTrain Acc: 92.88235% \tVal Acc: 96.4705878%\n",
      "Epoch: 300\tTrain Loss: 0.2375003 \tVal Loss:0.0996879 \tTrain Acc: 93.07353% \tVal Acc: 97.8823519%\n",
      "Epoch: 301\tTrain Loss: 0.2450940 \tVal Loss:0.0933494 \tTrain Acc: 93.29412% \tVal Acc: 98.4117639%\n",
      "Validation Loss decreased from 0.095218 to 0.093349, saving the model weights\n",
      "Epoch: 302\tTrain Loss: 0.2122461 \tVal Loss:0.0881077 \tTrain Acc: 93.92647% \tVal Acc: 98.2352930%\n",
      "Validation Loss decreased from 0.093349 to 0.088108, saving the model weights\n",
      "Epoch: 303\tTrain Loss: 0.2104636 \tVal Loss:0.0736920 \tTrain Acc: 94.02941% \tVal Acc: 98.8235271%\n",
      "Validation Loss decreased from 0.088108 to 0.073692, saving the model weights\n",
      "Epoch: 304\tTrain Loss: 0.2031636 \tVal Loss:0.0821985 \tTrain Acc: 94.35294% \tVal Acc: 97.9999983%\n",
      "Epoch: 305\tTrain Loss: 0.1871695 \tVal Loss:0.0604833 \tTrain Acc: 95.11765% \tVal Acc: 99.1176456%\n",
      "Validation Loss decreased from 0.073692 to 0.060483, saving the model weights\n",
      "Epoch: 306\tTrain Loss: 0.1897264 \tVal Loss:0.0685100 \tTrain Acc: 94.94118% \tVal Acc: 98.6470580%\n",
      "Epoch: 307\tTrain Loss: 0.1999538 \tVal Loss:0.0552652 \tTrain Acc: 94.22059% \tVal Acc: 99.1176462%\n",
      "Validation Loss decreased from 0.060483 to 0.055265, saving the model weights\n",
      "Epoch: 308\tTrain Loss: 0.1936124 \tVal Loss:0.0707559 \tTrain Acc: 94.57353% \tVal Acc: 98.3529401%\n",
      "Epoch: 309\tTrain Loss: 0.2028270 \tVal Loss:0.0795554 \tTrain Acc: 94.13235% \tVal Acc: 98.6470568%\n",
      "Epoch: 310\tTrain Loss: 0.1920133 \tVal Loss:0.0614827 \tTrain Acc: 94.69118% \tVal Acc: 98.7647051%\n",
      "Epoch: 311\tTrain Loss: 0.1970964 \tVal Loss:0.0965440 \tTrain Acc: 94.5147% \tVal Acc: 98.3529395%\n",
      "Epoch: 312\tTrain Loss: 0.3168827 \tVal Loss:0.2121791 \tTrain Acc: 90.75% \tVal Acc: 94.1764700%\n",
      "Epoch: 313\tTrain Loss: 0.4208558 \tVal Loss:0.2411126 \tTrain Acc: 87.41176% \tVal Acc: 92.8235281%\n",
      "Epoch: 314\tTrain Loss: 0.3666450 \tVal Loss:0.1655715 \tTrain Acc: 88.63235% \tVal Acc: 95.9411752%\n",
      "Epoch: 315\tTrain Loss: 0.3162468 \tVal Loss:0.1376987 \tTrain Acc: 90.17647% \tVal Acc: 96.7058808%\n",
      "Epoch: 316\tTrain Loss: 0.2539621 \tVal Loss:0.0860437 \tTrain Acc: 92.58823% \tVal Acc: 98.2941169%\n",
      "Epoch: 317\tTrain Loss: 0.2090826 \tVal Loss:0.0630662 \tTrain Acc: 93.98529% \tVal Acc: 98.9999986%\n",
      "Epoch: 318\tTrain Loss: 0.1914387 \tVal Loss:0.0493013 \tTrain Acc: 94.67647% \tVal Acc: 99.1764683%\n",
      "Validation Loss decreased from 0.055265 to 0.049301, saving the model weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 319\tTrain Loss: 0.1629860 \tVal Loss:0.0533994 \tTrain Acc: 95.77941% \tVal Acc: 99.0588224%\n",
      "Epoch: 320\tTrain Loss: 0.1576117 \tVal Loss:0.0450137 \tTrain Acc: 95.94118% \tVal Acc: 99.1176462%\n",
      "Validation Loss decreased from 0.049301 to 0.045014, saving the model weights\n",
      "Epoch: 321\tTrain Loss: 0.1462356 \tVal Loss:0.0550387 \tTrain Acc: 96.39706% \tVal Acc: 98.8823515%\n",
      "Epoch: 322\tTrain Loss: 0.1413833 \tVal Loss:0.0474521 \tTrain Acc: 96.14706% \tVal Acc: 98.7647045%\n",
      "Epoch: 323\tTrain Loss: 0.1458784 \tVal Loss:0.0458538 \tTrain Acc: 96.23529% \tVal Acc: 99.1764700%\n",
      "Epoch: 324\tTrain Loss: 0.1335913 \tVal Loss:0.0371756 \tTrain Acc: 96.79412% \tVal Acc: 99.2352927%\n",
      "Validation Loss decreased from 0.045014 to 0.037176, saving the model weights\n",
      "Epoch: 325\tTrain Loss: 0.1329009 \tVal Loss:0.0476142 \tTrain Acc: 96.67647% \tVal Acc: 98.9999986%\n",
      "Epoch: 326\tTrain Loss: 0.1256817 \tVal Loss:0.0289845 \tTrain Acc: 96.60294% \tVal Acc: 99.5294112%\n",
      "Validation Loss decreased from 0.037176 to 0.028985, saving the model weights\n",
      "Epoch: 327\tTrain Loss: 0.1231444 \tVal Loss:0.0291386 \tTrain Acc: 97.04412% \tVal Acc: 99.5294106%\n",
      "Epoch: 328\tTrain Loss: 0.1286110 \tVal Loss:0.0261357 \tTrain Acc: 96.72059% \tVal Acc: 99.5294106%\n",
      "Validation Loss decreased from 0.028985 to 0.026136, saving the model weights\n",
      "Epoch: 329\tTrain Loss: 0.1183060 \tVal Loss:0.0244039 \tTrain Acc: 96.88235% \tVal Acc: 99.4705880%\n",
      "Validation Loss decreased from 0.026136 to 0.024404, saving the model weights\n",
      "Epoch: 330\tTrain Loss: 0.1109302 \tVal Loss:0.0280289 \tTrain Acc: 97.17647% \tVal Acc: 99.4705868%\n",
      "Epoch: 331\tTrain Loss: 0.1043459 \tVal Loss:0.0268856 \tTrain Acc: 97.30882% \tVal Acc: 99.3529403%\n",
      "Epoch: 332\tTrain Loss: 0.1056271 \tVal Loss:0.0244348 \tTrain Acc: 97.48529% \tVal Acc: 99.5294106%\n",
      "Epoch: 333\tTrain Loss: 0.1068906 \tVal Loss:0.0231570 \tTrain Acc: 97.2647% \tVal Acc: 99.4705880%\n",
      "Validation Loss decreased from 0.024404 to 0.023157, saving the model weights\n",
      "Epoch: 334\tTrain Loss: 0.0988458 \tVal Loss:0.0253382 \tTrain Acc: 97.89706% \tVal Acc: 99.4117647%\n",
      "Epoch: 335\tTrain Loss: 0.1074941 \tVal Loss:0.0273363 \tTrain Acc: 97.23529% \tVal Acc: 99.3529403%\n",
      "Epoch: 336\tTrain Loss: 0.1030491 \tVal Loss:0.0219442 \tTrain Acc: 97.48529% \tVal Acc: 99.5294106%\n",
      "Validation Loss decreased from 0.023157 to 0.021944, saving the model weights\n",
      "Epoch: 337\tTrain Loss: 0.1011161 \tVal Loss:0.0254817 \tTrain Acc: 97.45588% \tVal Acc: 99.3529403%\n",
      "Epoch: 338\tTrain Loss: 0.1127564 \tVal Loss:0.0271283 \tTrain Acc: 97.07353% \tVal Acc: 99.4705874%\n",
      "Epoch: 339\tTrain Loss: 0.1139135 \tVal Loss:0.0278208 \tTrain Acc: 96.82353% \tVal Acc: 99.4705874%\n",
      "Epoch: 340\tTrain Loss: 0.1143987 \tVal Loss:0.0346028 \tTrain Acc: 97.25% \tVal Acc: 99.1176456%\n",
      "Epoch: 341\tTrain Loss: 0.1234189 \tVal Loss:0.0425819 \tTrain Acc: 96.72059% \tVal Acc: 99.0588224%\n",
      "Epoch: 342\tTrain Loss: 0.1417219 \tVal Loss:0.0746495 \tTrain Acc: 95.91176% \tVal Acc: 98.4117645%\n",
      "Epoch: 343\tTrain Loss: 0.1699122 \tVal Loss:0.0962671 \tTrain Acc: 94.83823% \tVal Acc: 96.8823516%\n",
      "Epoch: 344\tTrain Loss: 0.4170242 \tVal Loss:0.4430205 \tTrain Acc: 87.94118% \tVal Acc: 87.5294107%\n",
      "Epoch: 345\tTrain Loss: 0.7666250 \tVal Loss:0.7843775 \tTrain Acc: 77.82353% \tVal Acc: 77.5882351%\n",
      "Epoch: 346\tTrain Loss: 0.8773389 \tVal Loss:0.4748095 \tTrain Acc: 74.11765% \tVal Acc: 86.8823522%\n",
      "Epoch: 347\tTrain Loss: 0.6946672 \tVal Loss:0.3625121 \tTrain Acc: 79.16176% \tVal Acc: 89.5882344%\n",
      "Epoch: 348\tTrain Loss: 0.4493974 \tVal Loss:0.1410936 \tTrain Acc: 85.57353% \tVal Acc: 96.2941164%\n",
      "Epoch: 349\tTrain Loss: 0.2645594 \tVal Loss:0.0708076 \tTrain Acc: 92.2647% \tVal Acc: 98.5294098%\n",
      "Epoch: 350\tTrain Loss: 0.1956251 \tVal Loss:0.0576975 \tTrain Acc: 94.29412% \tVal Acc: 98.9411747%\n",
      "Epoch: 351\tTrain Loss: 0.1663116 \tVal Loss:0.0343783 \tTrain Acc: 95.48529% \tVal Acc: 99.4705868%\n",
      "Epoch: 352\tTrain Loss: 0.1386082 \tVal Loss:0.0306731 \tTrain Acc: 96.35294% \tVal Acc: 99.4705868%\n",
      "Epoch: 353\tTrain Loss: 0.1313885 \tVal Loss:0.0289602 \tTrain Acc: 96.79412% \tVal Acc: 99.6470582%\n",
      "Epoch: 354\tTrain Loss: 0.1265871 \tVal Loss:0.0252157 \tTrain Acc: 96.89706% \tVal Acc: 99.6470577%\n",
      "Epoch: 355\tTrain Loss: 0.1208003 \tVal Loss:0.0269329 \tTrain Acc: 97.17647% \tVal Acc: 99.4117641%\n",
      "Epoch: 356\tTrain Loss: 0.1184302 \tVal Loss:0.0262315 \tTrain Acc: 97.13235% \tVal Acc: 99.4705868%\n",
      "Epoch: 357\tTrain Loss: 0.1122691 \tVal Loss:0.0290721 \tTrain Acc: 97.25% \tVal Acc: 99.2941171%\n",
      "Epoch: 358\tTrain Loss: 0.1124622 \tVal Loss:0.0304740 \tTrain Acc: 97.14706% \tVal Acc: 99.3529397%\n",
      "Epoch: 359\tTrain Loss: 0.1099384 \tVal Loss:0.0248385 \tTrain Acc: 97.13235% \tVal Acc: 99.4117635%\n",
      "Epoch: 360\tTrain Loss: 0.0960056 \tVal Loss:0.0197577 \tTrain Acc: 97.7647% \tVal Acc: 99.6470577%\n",
      "Validation Loss decreased from 0.021944 to 0.019758, saving the model weights\n",
      "Epoch: 361\tTrain Loss: 0.0979590 \tVal Loss:0.0193053 \tTrain Acc: 97.58823% \tVal Acc: 99.5882344%\n",
      "Validation Loss decreased from 0.019758 to 0.019305, saving the model weights\n",
      "Epoch: 362\tTrain Loss: 0.0904268 \tVal Loss:0.0169269 \tTrain Acc: 97.91176% \tVal Acc: 99.5882344%\n",
      "Validation Loss decreased from 0.019305 to 0.016927, saving the model weights\n",
      "Epoch: 363\tTrain Loss: 0.0894527 \tVal Loss:0.0169592 \tTrain Acc: 97.91176% \tVal Acc: 99.7058815%\n",
      "Epoch: 364\tTrain Loss: 0.0882997 \tVal Loss:0.0166762 \tTrain Acc: 97.88235% \tVal Acc: 99.7058815%\n",
      "Validation Loss decreased from 0.016927 to 0.016676, saving the model weights\n",
      "Epoch: 365\tTrain Loss: 0.0820109 \tVal Loss:0.0173692 \tTrain Acc: 98.0% \tVal Acc: 99.5882344%\n",
      "Epoch: 366\tTrain Loss: 0.0833601 \tVal Loss:0.0182130 \tTrain Acc: 97.98529% \tVal Acc: 99.5882344%\n",
      "Epoch: 367\tTrain Loss: 0.0857584 \tVal Loss:0.0154615 \tTrain Acc: 98.02941% \tVal Acc: 99.6470582%\n",
      "Validation Loss decreased from 0.016676 to 0.015462, saving the model weights\n",
      "Epoch: 368\tTrain Loss: 0.0800531 \tVal Loss:0.0162708 \tTrain Acc: 98.29412% \tVal Acc: 99.6470577%\n",
      "Epoch: 369\tTrain Loss: 0.0787434 \tVal Loss:0.0150911 \tTrain Acc: 98.42647% \tVal Acc: 99.6470577%\n",
      "Validation Loss decreased from 0.015462 to 0.015091, saving the model weights\n",
      "Epoch: 370\tTrain Loss: 0.0825421 \tVal Loss:0.0161650 \tTrain Acc: 97.86765% \tVal Acc: 99.7058815%\n",
      "Epoch: 371\tTrain Loss: 0.0775987 \tVal Loss:0.0148466 \tTrain Acc: 98.23529% \tVal Acc: 99.5882350%\n",
      "Validation Loss decreased from 0.015091 to 0.014847, saving the model weights\n",
      "Epoch: 372\tTrain Loss: 0.0738541 \tVal Loss:0.0134196 \tTrain Acc: 98.2647% \tVal Acc: 99.6470582%\n",
      "Validation Loss decreased from 0.014847 to 0.013420, saving the model weights\n",
      "Epoch: 373\tTrain Loss: 0.0731738 \tVal Loss:0.0143560 \tTrain Acc: 98.44118% \tVal Acc: 99.6470577%\n",
      "Epoch: 374\tTrain Loss: 0.0755241 \tVal Loss:0.0152202 \tTrain Acc: 98.10294% \tVal Acc: 99.6470577%\n",
      "Epoch: 375\tTrain Loss: 0.0716221 \tVal Loss:0.0149700 \tTrain Acc: 98.42647% \tVal Acc: 99.6470577%\n",
      "Epoch: 376\tTrain Loss: 0.0743506 \tVal Loss:0.0121174 \tTrain Acc: 98.19118% \tVal Acc: 99.7058815%\n",
      "Validation Loss decreased from 0.013420 to 0.012117, saving the model weights\n",
      "Epoch: 377\tTrain Loss: 0.0754926 \tVal Loss:0.0129657 \tTrain Acc: 98.2647% \tVal Acc: 99.7058815%\n",
      "Epoch: 378\tTrain Loss: 0.0776207 \tVal Loss:0.0184924 \tTrain Acc: 97.94117% \tVal Acc: 99.5294106%\n",
      "Epoch: 379\tTrain Loss: 0.0823289 \tVal Loss:0.0176409 \tTrain Acc: 97.75% \tVal Acc: 99.5294106%\n",
      "Epoch: 380\tTrain Loss: 0.0840247 \tVal Loss:0.0207973 \tTrain Acc: 97.88235% \tVal Acc: 99.5882344%\n",
      "Epoch: 381\tTrain Loss: 0.0883261 \tVal Loss:0.0200365 \tTrain Acc: 97.92647% \tVal Acc: 99.4117635%\n",
      "Epoch: 382\tTrain Loss: 0.0893143 \tVal Loss:0.0250898 \tTrain Acc: 97.72059% \tVal Acc: 99.2352921%\n",
      "Epoch: 383\tTrain Loss: 0.0898264 \tVal Loss:0.0231621 \tTrain Acc: 97.54412% \tVal Acc: 99.3529403%\n",
      "Epoch: 384\tTrain Loss: 0.1024840 \tVal Loss:0.0303081 \tTrain Acc: 97.08823% \tVal Acc: 99.1764700%\n",
      "Epoch: 385\tTrain Loss: 0.1082991 \tVal Loss:0.0397176 \tTrain Acc: 97.04412% \tVal Acc: 99.0588218%\n",
      "Epoch: 386\tTrain Loss: 0.1288035 \tVal Loss:0.0564021 \tTrain Acc: 96.57353% \tVal Acc: 98.4705871%\n",
      "Epoch: 387\tTrain Loss: 0.2401169 \tVal Loss:0.3146895 \tTrain Acc: 92.48529% \tVal Acc: 90.5882341%\n",
      "Epoch: 388\tTrain Loss: 0.5308518 \tVal Loss:0.3750424 \tTrain Acc: 84.48529% \tVal Acc: 88.8823521%\n",
      "Epoch: 389\tTrain Loss: 0.4603800 \tVal Loss:0.2269480 \tTrain Acc: 85.47059% \tVal Acc: 92.7647048%\n",
      "Epoch: 390\tTrain Loss: 0.4058229 \tVal Loss:0.3057173 \tTrain Acc: 87.58823% \tVal Acc: 90.5882335%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 391\tTrain Loss: 0.3396125 \tVal Loss:0.1047067 \tTrain Acc: 89.85294% \tVal Acc: 97.2352934%\n",
      "Epoch: 392\tTrain Loss: 0.2509111 \tVal Loss:0.0879145 \tTrain Acc: 92.57353% \tVal Acc: 97.9999983%\n",
      "Epoch: 393\tTrain Loss: 0.1831838 \tVal Loss:0.1043574 \tTrain Acc: 94.61765% \tVal Acc: 97.5294107%\n",
      "Epoch: 394\tTrain Loss: 0.1699041 \tVal Loss:0.0499751 \tTrain Acc: 95.41176% \tVal Acc: 98.9411753%\n",
      "Epoch: 395\tTrain Loss: 0.1322054 \tVal Loss:0.0244614 \tTrain Acc: 96.30882% \tVal Acc: 99.5882338%\n",
      "Epoch: 396\tTrain Loss: 0.0982814 \tVal Loss:0.0176283 \tTrain Acc: 97.5147% \tVal Acc: 99.6470577%\n",
      "Epoch: 397\tTrain Loss: 0.0836439 \tVal Loss:0.0165747 \tTrain Acc: 97.97059% \tVal Acc: 99.6470582%\n",
      "Epoch: 398\tTrain Loss: 0.0807445 \tVal Loss:0.0168477 \tTrain Acc: 98.07353% \tVal Acc: 99.4705874%\n",
      "Epoch: 399\tTrain Loss: 0.0757648 \tVal Loss:0.0174470 \tTrain Acc: 98.17647% \tVal Acc: 99.5294106%\n",
      "Epoch: 400\tTrain Loss: 0.0764846 \tVal Loss:0.0132334 \tTrain Acc: 98.22059% \tVal Acc: 99.6470577%\n",
      "Epoch: 401\tTrain Loss: 0.0671085 \tVal Loss:0.0127443 \tTrain Acc: 98.48529% \tVal Acc: 99.6470582%\n",
      "Epoch: 402\tTrain Loss: 0.0709616 \tVal Loss:0.0122014 \tTrain Acc: 98.2647% \tVal Acc: 99.5882338%\n",
      "Epoch: 403\tTrain Loss: 0.0669568 \tVal Loss:0.0137280 \tTrain Acc: 98.48529% \tVal Acc: 99.5882344%\n",
      "Epoch: 404\tTrain Loss: 0.0669842 \tVal Loss:0.0129498 \tTrain Acc: 98.44118% \tVal Acc: 99.6470582%\n",
      "Epoch: 405\tTrain Loss: 0.0660539 \tVal Loss:0.0118890 \tTrain Acc: 98.5% \tVal Acc: 99.7058815%\n",
      "Validation Loss decreased from 0.012117 to 0.011889, saving the model weights\n",
      "Epoch: 406\tTrain Loss: 0.0595608 \tVal Loss:0.0143988 \tTrain Acc: 98.88235% \tVal Acc: 99.6470577%\n",
      "Epoch: 407\tTrain Loss: 0.0614267 \tVal Loss:0.0134184 \tTrain Acc: 98.69118% \tVal Acc: 99.5882344%\n",
      "Epoch: 408\tTrain Loss: 0.0559515 \tVal Loss:0.0130216 \tTrain Acc: 98.94118% \tVal Acc: 99.5882344%\n",
      "Epoch: 409\tTrain Loss: 0.0614488 \tVal Loss:0.0135769 \tTrain Acc: 98.55882% \tVal Acc: 99.6470577%\n",
      "Epoch: 410\tTrain Loss: 0.0636765 \tVal Loss:0.0144627 \tTrain Acc: 98.41176% \tVal Acc: 99.6470577%\n",
      "Epoch: 411\tTrain Loss: 0.0600646 \tVal Loss:0.0160725 \tTrain Acc: 98.63235% \tVal Acc: 99.6470577%\n",
      "Epoch: 412\tTrain Loss: 0.0610599 \tVal Loss:0.0198423 \tTrain Acc: 98.64706% \tVal Acc: 99.4117635%\n",
      "Epoch: 413\tTrain Loss: 0.0621655 \tVal Loss:0.0216061 \tTrain Acc: 98.5147% \tVal Acc: 99.1764700%\n",
      "Epoch: 414\tTrain Loss: 0.0629508 \tVal Loss:0.0174481 \tTrain Acc: 98.52941% \tVal Acc: 99.2941171%\n",
      "Epoch: 415\tTrain Loss: 0.0623886 \tVal Loss:0.0133145 \tTrain Acc: 98.5147% \tVal Acc: 99.5294112%\n",
      "Epoch: 416\tTrain Loss: 0.0676787 \tVal Loss:0.0187384 \tTrain Acc: 98.16176% \tVal Acc: 99.3529403%\n",
      "Epoch: 417\tTrain Loss: 0.0644446 \tVal Loss:0.0155195 \tTrain Acc: 98.33823% \tVal Acc: 99.5294106%\n",
      "Epoch: 418\tTrain Loss: 0.0632917 \tVal Loss:0.0237520 \tTrain Acc: 98.69117% \tVal Acc: 99.4705874%\n",
      "Epoch: 419\tTrain Loss: 0.0685399 \tVal Loss:0.0171321 \tTrain Acc: 98.23529% \tVal Acc: 99.4705868%\n",
      "Epoch: 420\tTrain Loss: 0.0797450 \tVal Loss:0.0152282 \tTrain Acc: 97.86765% \tVal Acc: 99.5294112%\n",
      "Epoch: 421\tTrain Loss: 0.0843153 \tVal Loss:0.0228363 \tTrain Acc: 97.7647% \tVal Acc: 99.3529409%\n",
      "Epoch: 422\tTrain Loss: 0.1120528 \tVal Loss:0.0589549 \tTrain Acc: 96.75% \tVal Acc: 98.5882342%\n",
      "Epoch: 423\tTrain Loss: 0.2387866 \tVal Loss:0.3118934 \tTrain Acc: 93.08823% \tVal Acc: 91.5882337%\n",
      "Epoch: 424\tTrain Loss: 0.4144833 \tVal Loss:0.2701092 \tTrain Acc: 87.83823% \tVal Acc: 91.8235284%\n",
      "Epoch: 425\tTrain Loss: 0.4762091 \tVal Loss:0.3028221 \tTrain Acc: 85.76471% \tVal Acc: 91.0588223%\n",
      "Epoch: 426\tTrain Loss: 0.4286722 \tVal Loss:0.2353597 \tTrain Acc: 86.58823% \tVal Acc: 93.0588222%\n",
      "Epoch: 427\tTrain Loss: 0.3245389 \tVal Loss:0.1109799 \tTrain Acc: 89.86765% \tVal Acc: 97.1176457%\n",
      "Epoch: 428\tTrain Loss: 0.2055525 \tVal Loss:0.0600490 \tTrain Acc: 93.86765% \tVal Acc: 98.5294110%\n",
      "Epoch: 429\tTrain Loss: 0.1649923 \tVal Loss:0.0377366 \tTrain Acc: 95.42647% \tVal Acc: 98.9999992%\n",
      "Epoch: 430\tTrain Loss: 0.1114730 \tVal Loss:0.0188935 \tTrain Acc: 97.32353% \tVal Acc: 99.6470577%\n",
      "Epoch: 431\tTrain Loss: 0.0979569 \tVal Loss:0.0183254 \tTrain Acc: 97.38235% \tVal Acc: 99.5882344%\n",
      "Epoch: 432\tTrain Loss: 0.0916781 \tVal Loss:0.0134708 \tTrain Acc: 97.83823% \tVal Acc: 99.7058815%\n",
      "Epoch: 433\tTrain Loss: 0.0872507 \tVal Loss:0.0141677 \tTrain Acc: 97.64706% \tVal Acc: 99.7058815%\n",
      "Epoch: 434\tTrain Loss: 0.0760903 \tVal Loss:0.0139215 \tTrain Acc: 97.92647% \tVal Acc: 99.7058815%\n",
      "Epoch: 435\tTrain Loss: 0.0859314 \tVal Loss:0.0159870 \tTrain Acc: 98.04412% \tVal Acc: 99.5294106%\n",
      "Epoch: 436\tTrain Loss: 0.0862087 \tVal Loss:0.0221416 \tTrain Acc: 97.67647% \tVal Acc: 99.1764700%\n",
      "Epoch: 437\tTrain Loss: 0.0817816 \tVal Loss:0.0421310 \tTrain Acc: 97.77941% \tVal Acc: 98.8823515%\n",
      "Epoch: 438\tTrain Loss: 0.0930228 \tVal Loss:0.0383134 \tTrain Acc: 97.75% \tVal Acc: 99.1176462%\n",
      "Epoch: 439\tTrain Loss: 0.1050642 \tVal Loss:0.0210322 \tTrain Acc: 97.39706% \tVal Acc: 99.2941165%\n",
      "Epoch: 440\tTrain Loss: 0.0909222 \tVal Loss:0.0176475 \tTrain Acc: 97.57353% \tVal Acc: 99.5294112%\n",
      "Epoch: 441\tTrain Loss: 0.0774119 \tVal Loss:0.0265818 \tTrain Acc: 97.91176% \tVal Acc: 99.3529403%\n",
      "Epoch: 442\tTrain Loss: 0.0891920 \tVal Loss:0.0192443 \tTrain Acc: 97.79412% \tVal Acc: 99.4705874%\n",
      "Epoch: 443\tTrain Loss: 0.0748221 \tVal Loss:0.0211186 \tTrain Acc: 98.14706% \tVal Acc: 99.4117635%\n",
      "Epoch: 444\tTrain Loss: 0.0819579 \tVal Loss:0.0153516 \tTrain Acc: 97.97059% \tVal Acc: 99.5882344%\n",
      "Epoch: 445\tTrain Loss: 0.0829391 \tVal Loss:0.0147911 \tTrain Acc: 97.77941% \tVal Acc: 99.5294112%\n",
      "Epoch: 446\tTrain Loss: 0.0630513 \tVal Loss:0.0165046 \tTrain Acc: 98.63235% \tVal Acc: 99.5294112%\n",
      "Epoch: 447\tTrain Loss: 0.0614845 \tVal Loss:0.0116807 \tTrain Acc: 98.69118% \tVal Acc: 99.4705874%\n",
      "Validation Loss decreased from 0.011889 to 0.011681, saving the model weights\n",
      "Epoch: 448\tTrain Loss: 0.0525218 \tVal Loss:0.0112214 \tTrain Acc: 98.72059% \tVal Acc: 99.5294106%\n",
      "Validation Loss decreased from 0.011681 to 0.011221, saving the model weights\n",
      "Epoch: 449\tTrain Loss: 0.0522362 \tVal Loss:0.0174859 \tTrain Acc: 98.73529% \tVal Acc: 99.4705874%\n",
      "Epoch: 450\tTrain Loss: 0.0531986 \tVal Loss:0.0100612 \tTrain Acc: 98.75% \tVal Acc: 99.5882344%\n",
      "Validation Loss decreased from 0.011221 to 0.010061, saving the model weights\n",
      "Epoch: 451\tTrain Loss: 0.0508916 \tVal Loss:0.0119793 \tTrain Acc: 98.64706% \tVal Acc: 99.6470577%\n",
      "Epoch: 452\tTrain Loss: 0.0455028 \tVal Loss:0.0116361 \tTrain Acc: 99.04412% \tVal Acc: 99.5882344%\n",
      "Epoch: 453\tTrain Loss: 0.0468112 \tVal Loss:0.0112433 \tTrain Acc: 98.98529% \tVal Acc: 99.5294106%\n",
      "Epoch: 454\tTrain Loss: 0.0470582 \tVal Loss:0.0135137 \tTrain Acc: 99.0147% \tVal Acc: 99.4117641%\n",
      "Epoch: 455\tTrain Loss: 0.0457639 \tVal Loss:0.0163509 \tTrain Acc: 99.0% \tVal Acc: 99.5294112%\n",
      "Epoch: 456\tTrain Loss: 0.0446007 \tVal Loss:0.0104251 \tTrain Acc: 98.94118% \tVal Acc: 99.6470577%\n",
      "Epoch: 457\tTrain Loss: 0.0470123 \tVal Loss:0.0079870 \tTrain Acc: 98.80882% \tVal Acc: 99.7058815%\n",
      "Validation Loss decreased from 0.010061 to 0.007987, saving the model weights\n",
      "Epoch: 458\tTrain Loss: 0.0435407 \tVal Loss:0.0085300 \tTrain Acc: 99.0% \tVal Acc: 99.7058815%\n",
      "Epoch: 459\tTrain Loss: 0.0435557 \tVal Loss:0.0114929 \tTrain Acc: 98.98529% \tVal Acc: 99.5882344%\n",
      "Epoch: 460\tTrain Loss: 0.0438547 \tVal Loss:0.0189655 \tTrain Acc: 98.95588% \tVal Acc: 99.4117641%\n",
      "Epoch: 461\tTrain Loss: 0.0404906 \tVal Loss:0.0110730 \tTrain Acc: 99.05882% \tVal Acc: 99.5882344%\n",
      "Epoch: 462\tTrain Loss: 0.0445304 \tVal Loss:0.0089307 \tTrain Acc: 99.11765% \tVal Acc: 99.7647047%\n",
      "Epoch: 463\tTrain Loss: 0.0414931 \tVal Loss:0.0074671 \tTrain Acc: 99.08823% \tVal Acc: 99.6470582%\n",
      "Validation Loss decreased from 0.007987 to 0.007467, saving the model weights\n",
      "Epoch: 464\tTrain Loss: 0.0423580 \tVal Loss:0.0092170 \tTrain Acc: 98.97059% \tVal Acc: 99.6470577%\n",
      "Epoch: 465\tTrain Loss: 0.0407284 \tVal Loss:0.0103729 \tTrain Acc: 99.08823% \tVal Acc: 99.6470577%\n",
      "Epoch: 466\tTrain Loss: 0.0451308 \tVal Loss:0.0104039 \tTrain Acc: 98.89706% \tVal Acc: 99.5294106%\n",
      "Epoch: 467\tTrain Loss: 0.0438509 \tVal Loss:0.0100934 \tTrain Acc: 99.05882% \tVal Acc: 99.6470582%\n",
      "Epoch: 468\tTrain Loss: 0.0417056 \tVal Loss:0.0085371 \tTrain Acc: 99.05882% \tVal Acc: 99.7058815%\n",
      "Epoch: 469\tTrain Loss: 0.0416074 \tVal Loss:0.0098711 \tTrain Acc: 99.04412% \tVal Acc: 99.6470577%\n",
      "Epoch: 470\tTrain Loss: 0.0445212 \tVal Loss:0.0172884 \tTrain Acc: 98.88235% \tVal Acc: 99.4705868%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 471\tTrain Loss: 0.0529588 \tVal Loss:0.0190755 \tTrain Acc: 98.60294% \tVal Acc: 99.2941171%\n",
      "Epoch: 472\tTrain Loss: 0.0697792 \tVal Loss:0.0372363 \tTrain Acc: 98.30882% \tVal Acc: 98.9411753%\n",
      "Epoch: 473\tTrain Loss: 0.2886564 \tVal Loss:0.4102306 \tTrain Acc: 92.70588% \tVal Acc: 90.5882335%\n",
      "Epoch: 474\tTrain Loss: 0.8719819 \tVal Loss:0.7654380 \tTrain Acc: 76.5% \tVal Acc: 77.4705887%\n",
      "Epoch: 475\tTrain Loss: 0.8361420 \tVal Loss:0.5150582 \tTrain Acc: 75.70588% \tVal Acc: 84.4705880%\n",
      "Epoch: 476\tTrain Loss: 0.5598265 \tVal Loss:0.2504479 \tTrain Acc: 82.76471% \tVal Acc: 92.7647036%\n",
      "Epoch: 477\tTrain Loss: 0.3530407 \tVal Loss:0.1591262 \tTrain Acc: 89.23529% \tVal Acc: 95.8823520%\n",
      "Epoch: 478\tTrain Loss: 0.2120483 \tVal Loss:0.0606173 \tTrain Acc: 93.92647% \tVal Acc: 98.9411753%\n",
      "Epoch: 479\tTrain Loss: 0.1328970 \tVal Loss:0.0302759 \tTrain Acc: 96.11765% \tVal Acc: 99.4705874%\n",
      "Epoch: 480\tTrain Loss: 0.1059126 \tVal Loss:0.0182521 \tTrain Acc: 97.13235% \tVal Acc: 99.6470577%\n",
      "Epoch: 481\tTrain Loss: 0.0777354 \tVal Loss:0.0138405 \tTrain Acc: 98.07353% \tVal Acc: 99.6470582%\n",
      "Epoch: 482\tTrain Loss: 0.0689210 \tVal Loss:0.0126717 \tTrain Acc: 98.32353% \tVal Acc: 99.6470577%\n",
      "Epoch: 483\tTrain Loss: 0.0629866 \tVal Loss:0.0118739 \tTrain Acc: 98.75% \tVal Acc: 99.7058815%\n",
      "Epoch: 484\tTrain Loss: 0.0620807 \tVal Loss:0.0120768 \tTrain Acc: 98.58823% \tVal Acc: 99.7058815%\n",
      "Epoch: 485\tTrain Loss: 0.0545934 \tVal Loss:0.0103483 \tTrain Acc: 98.88235% \tVal Acc: 99.7058815%\n",
      "Epoch: 486\tTrain Loss: 0.0518928 \tVal Loss:0.0097949 \tTrain Acc: 98.88235% \tVal Acc: 99.7058815%\n",
      "Epoch: 487\tTrain Loss: 0.0523041 \tVal Loss:0.0106317 \tTrain Acc: 98.70588% \tVal Acc: 99.7058815%\n",
      "Epoch: 488\tTrain Loss: 0.0510621 \tVal Loss:0.0099649 \tTrain Acc: 98.73529% \tVal Acc: 99.7058815%\n",
      "Epoch: 489\tTrain Loss: 0.0473638 \tVal Loss:0.0104700 \tTrain Acc: 99.0147% \tVal Acc: 99.6470577%\n",
      "Epoch: 490\tTrain Loss: 0.0464062 \tVal Loss:0.0089518 \tTrain Acc: 99.02941% \tVal Acc: 99.7058815%\n",
      "Epoch: 491\tTrain Loss: 0.0449133 \tVal Loss:0.0082279 \tTrain Acc: 99.05882% \tVal Acc: 99.6470582%\n",
      "Epoch: 492\tTrain Loss: 0.0471413 \tVal Loss:0.0115017 \tTrain Acc: 98.94117% \tVal Acc: 99.6470582%\n",
      "Epoch: 493\tTrain Loss: 0.0453977 \tVal Loss:0.0088039 \tTrain Acc: 99.0147% \tVal Acc: 99.6470582%\n",
      "Epoch: 494\tTrain Loss: 0.0438478 \tVal Loss:0.0095498 \tTrain Acc: 99.10294% \tVal Acc: 99.7058815%\n",
      "Epoch: 495\tTrain Loss: 0.0420879 \tVal Loss:0.0103180 \tTrain Acc: 99.04412% \tVal Acc: 99.7058815%\n",
      "Epoch: 496\tTrain Loss: 0.0438130 \tVal Loss:0.0097410 \tTrain Acc: 99.0147% \tVal Acc: 99.6470582%\n",
      "Epoch: 497\tTrain Loss: 0.0396537 \tVal Loss:0.0091860 \tTrain Acc: 99.22059% \tVal Acc: 99.6470582%\n",
      "Epoch: 498\tTrain Loss: 0.0432846 \tVal Loss:0.0144168 \tTrain Acc: 99.08823% \tVal Acc: 99.5882344%\n",
      "Epoch: 499\tTrain Loss: 0.0462643 \tVal Loss:0.0101163 \tTrain Acc: 98.97059% \tVal Acc: 99.5882344%\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "min_val_loss = np.Inf\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    train_accuracy = 0\n",
    "    val_accuracy = 0\n",
    "    \n",
    "    \n",
    "    hidden1, hidden2 = model.hidden_init(train_batch_size)    \n",
    "    #print('hidden[0].shape:- ',hidden[0].shape)\n",
    "    \n",
    "    for inputs,labels in train_loader:\n",
    "        #print(inputs.shape)\n",
    "\n",
    "        '''\n",
    "        Creating new variables for the hidden state, otherwise\n",
    "        we'd backprop through the entire training history\n",
    "        '''\n",
    "        #h = tuple([each.data for each in hidden])\n",
    "        \n",
    "        h1 = tuple([each.data for each in hidden1])\n",
    "        h2 = tuple([each.data for each in hidden2])\n",
    "        \n",
    "        # zero accumulated gradients\n",
    "        model.zero_grad()\n",
    "       \n",
    "        # get the output from the model\n",
    "        output, _ = model.forward(inputs, h1, h2, train_batch_size)\n",
    "        #print('OUTPUT', output)\n",
    "        \n",
    "        \n",
    "        #print('Labels Shape :-', (torch.max(labels, 1)[1]).shape)\n",
    "    \n",
    "        # calculate the loss and perform backprop\n",
    "        #print('Labels Long :-', labels.long())\n",
    "        loss = criterion(output,labels.long())\n",
    "        #print('LOSS IS :-', loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #calculate training accuracy\n",
    "        output = F.softmax(output, dim = 1)\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "        logging.debug(' top probab {} top class {}'.format(top_p.view(-1, top_p.shape[0]), top_class.view(-1, top_p.shape[0])))\n",
    "\n",
    "        equals = top_class == labels.long().view(*top_class.shape)\n",
    "        train_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        \n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        #nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        #print(train_loss)\n",
    "              \n",
    "    model.eval()\n",
    "    for inputs, labels in val_loader:\n",
    "                \n",
    "        val_h1 = tuple([each.data for each in hidden1])\n",
    "        val_h2 = tuple([each.data for each in hidden2])\n",
    "        \n",
    "        output, _ = model.forward(inputs, val_h1, val_h2,val_batch_size)\n",
    "       \n",
    "        loss = criterion(output,labels.long())\n",
    "        \n",
    "        val_loss += loss.item()\n",
    "        \n",
    "        #calculate validation accuracy\n",
    "        output = F.softmax(output, dim = 1)\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "        \n",
    "        #logging.debug(output)\n",
    "        #logging.debug('VALIDATION top probab {} VALIDATION top class {}'.format(top_p.view(-1, top_p.shape[0]), top_class.view(-1, top_p.shape[0])))\n",
    "\n",
    "        #print('Top Class:- ',top_class)\n",
    "        equals = top_class == labels.long().view(*top_class.shape)\n",
    "        #print('Equals:- ', equals)\n",
    "        val_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    #Averaging losses\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    val_loss = val_loss/len(val_loader)\n",
    "    val_accuracy = val_accuracy/len(val_loader)\n",
    "    train_accuracy = train_accuracy/len(train_loader)\n",
    "    \n",
    "    print('Epoch: {}\\tTrain Loss: {:.7f} \\tVal Loss:{:.7f} \\tTrain Acc: {:.7}% \\tVal Acc: {:.7f}%'.format(e, train_loss, val_loss, train_accuracy*100,val_accuracy*100))\n",
    "    \n",
    "    #saving the model if validation loss is decreased\n",
    "    if val_loss <= min_val_loss:\n",
    "        print('Validation Loss decreased from {:6f} to {:6f}, saving the model weights'.format(min_val_loss, val_loss))\n",
    "        torch.save(model.state_dict(), 'lstm_state_256-38-removed_Ht_Ct.pt')\n",
    "        min_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUSIC GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stacked_LSTM(\n",
       "  (lstm1): LSTM(1, 256, batch_first=True)\n",
       "  (lstm2): LSTM(256, 38, batch_first=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=38, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights\n",
    "test_model = Stacked_LSTM(input_size,hidden_size,num_layer,output_size)\n",
    "test_model.load_state_dict(torch.load('lstm_state_256-38-removed_Ht_Ct.pt'))\n",
    "test_model.eval()\n",
    "test_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load population database\n",
    "#testing_data = np.ones(200)*1\n",
    "testing_data = list(range(50,90))\n",
    "testing_data.extend(testing_data[::-1])\n",
    "testing_data_rev = testing_data[::-1]\n",
    "testing_data_rev.extend(testing_data)\n",
    "testing_data_rev.extend(testing_data_rev)\n",
    "testing_data = testing_data_rev\n",
    "\n",
    "\n",
    "testing_data = np.asarray(testing_data)\n",
    "testing_data = testing_data.reshape(testing_data.shape[0],1)\n",
    "\n",
    "initial_seq = [network_input[0][1:].cpu().numpy().tolist()]\n",
    "\n",
    "testing_data_unnorm = testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "testing_data=testing_data.tolist()\n",
    "for i in range(len(testing_data)):\n",
    "    list1.extend(testing_data[i])\n",
    "\n",
    "#list1\n",
    "\n",
    "for i in range(len(list1)):\n",
    "    list1[i]=(list1[i]-50)/(89-50)\n",
    "\n",
    "list1 = np.asarray(list1)\n",
    "list1 = list1.reshape(list1.shape[0],1)\n",
    "testing_data = list1\n",
    "#list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting\n",
    "def prediction_with_influence(influence,int2note,initial_seq, max_note, test_batch_size = 1):\n",
    "\n",
    "    predicted_notes = []\n",
    "    initial_seq[0].extend([[0]]*len(testing_data))\n",
    "    test_seq = torch.Tensor(initial_seq).cuda()\n",
    "    \n",
    "    h1, h2 = test_model.hidden_init(test_batch_size)\n",
    "\n",
    "    \n",
    "    for i in range(len(influence)):\n",
    "        \n",
    "        test_seq[0][sequence_length - 1 + i][0] = float(influence[i])\n",
    "        \n",
    "        test_slice = test_seq[0][i : i + sequence_length]        \n",
    "        test_slice = test_slice.view(1, test_slice.shape[0], test_slice.shape[1])\n",
    "                \n",
    "        test_hidden1 = tuple([each.data for each in h1])\n",
    "        test_hidden2 = tuple([each.data for each in h2])\n",
    "        \n",
    "        test_output,_ = test_model.forward(test_slice, test_hidden1, test_hidden2, test_batch_size)\n",
    "    \n",
    "        test_output = F.softmax(test_output, dim = 1)\n",
    "        top_p, top_class = test_output.topk(1,dim =1)\n",
    "        test_seq[0][sequence_length - 1 + i][0] = int2note[top_class.item()]/max_note\n",
    "        \n",
    "        predicted_notes.append(int2note[top_class.item()])\n",
    "        \n",
    "    return predicted_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_notes_lst = prediction_with_influence(testing_data,int_to_note,initial_seq, max_midi_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_notes_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ea44d4feb8>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuIAAAHwCAYAAADjFQoyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOy9eZwsV133/zm9T89Mz517Z783uWty751LYiAhLGGTRRQQNKCAPxRFAVEBBUT8KY+PiCLyKKigPAIKghgDyqKyhRBIIIQlMeRm5q65+5197dl6P88fp7vr1OlT1VXd1T3V3d/36zWv6a6uqq6eOX3qU5/6LoxzDoIgCIIgCIIgmktguw+AIAiCIAiCIDoREuIEQRAEQRAEsQ2QECcIgiAIgiCIbYCEOEEQBEEQBEFsAyTECYIgCIIgCGIbICFOEARBEARBENsACXGCIAiCIAiC2AZIiBMEQRAEQRDENkBCnCAIgiAIgiC2ARLiBEEQBEEQBLENkBAnCIIgCIIgiG2AhDhBEARBEARBbAOh7T6ARsAYOw8gAeDCNh8KQRAEQRAE0d7sA5DknO93u2FbCnEAia6urp1Hjx7dud0HQhAEQRAEQbQvJ06cwNbWVk3btqsQv3D06NGdDz744HYfB0EQBEEQBNHG3HzzzXjooYcu1LItxYgTBEEQBEEQxDZAQpwgCIIgCIIgtgFPhDgTvIYx9gBjbI0xtskY+x/G2JsYY0GLbZ7KGPsSY2ypuP4jjLHftlqfIAiCIAiCINoJrxzxTwD4GID9AP4NwEcARAD8NYB/Y4wxeWXG2EsA3AvgGQA+B+BDxfXfD+AOj46JIAiCIAiCIHxL3cmajLGfAfCLAM4DuJVzvlBcHgZwJ4CXAng1gI8XlycghHoewLM45z8sLn8ngG8AeBlj7BWccxLkBEEQBEEQRNvihSN+e/H3X5ZEOABwzrMA3ll8+kZp/ZcBGARwR0mEF9dPAfjD4tM3eHBcBEEQBEEQBOFbvChfOFL8fU7zWmnZExhjOzjnKwCeXVz2Fc369wLYBPBUxliUc562e2PGmFV9wiNVjpkgCIIgCIIgthUvHPGSC67rJnRAelwSx4eLv0+rK3POcxAhLiFlW4IgCIIgCIJoK7xwxP8LwCsBvIUxdgfnfAkAGGMhAH8srddf/N1X/L1qsb/S8h3V3phzfrNuedEpf0K17QmCIAiCIAhiu/BCiN8B4FUAfgrAJGPsixDhJc8FcBDAGQDXQSRnOqFUYYV7cGwEQRAEQRAE4UvqDk3hnBcAvBjA2wDMQFRQeQ2AKwCeBmCxuOpc8XfJ8e6DnoSyHkEQBEEQBEG0HZ7UEeec5zjnf8k5v4lz3sU5T3DOfxLAJICbAGwBmCiufqr4+3p1P8Vwlv0ActAnfxIEQRAEQRBEW9DoFve/CCAG4M5iOUNA1AoHgJ/UrP8MAHEA91ermEIQBEEQBEEQrYxXLe4TmmVPBPDnANYBvEt66bMQlVZewRi7RVo/BuDdxad/78VxEQRBEARBEIRf8SJZEwDuYoxtAXgUwBqAYwBeACAN4HbOeTnMhHOeZIy9FkKQf5MxdgeAJYg488PF5f/m0XERBEEQBEEQhC/xSoh/FsArIKqndAGYAvBRAH/OOb+grsw5/zxj7JkA/gDASyHCV84CeAuAv+GcU8WUNodzjkLxvxwMMPuVOw3OAebwb6KuyznAC+JxIOj9sbUQhQIHhyjDFKAxRjSAfHESCzCAOf3OEoRD6DzZGXgixDnn7wPwPpfbfAfCNSc6jMmpJF73yR/iyvIWAOAZ1w/iY6++BeFgo1MWWoD7/gr47oeA294M3PYm+3UXzgJ3vBKI9gKv+g9g6iHgc28A1meAQAh4/C8CP/2B5hy3z/jofefwl187ja1sHvFIEG/7icN4zdN0PccIwj2ZXAG/+okf4L4zop/dnv4ufPTVt+DISEWUJkHUxPErq3j9J3+IqdUUAODZR4bwD794M0J0nmw76D9KNJ1/uPexsggHgHtPz+MbJ+dstugQCnng7j8GNheAu94p3G07vvhGYOE0cPVB4Kt/ANz/QSHCAaCQAx78J2DlcuOP22dk8wW876unsJUVrQs2M3m876unkMsXtvnIiHbh7hOzZREOAFeWt/AP91KhL8I7Pvytx8oiHAC+cXLONOaI9oGEONF0Hp1KViybuEpl45HPmJ9n1u3Xv3S/8fjUl4B1zcVMZqP+42oxzs6tI50zi+6tbB7nFzrvb0E0hkenKueriauV8xpB1IpujD1K58m2hIQ40VS2Mnmcm68UmJPTdBJDPmt+nnIx6WY2gNRK5XLeeS7wpOZCD6AxRniHboydnV9HKuu0gTRBWLOWyuLi4mbFcprD2hMS4kRTOTW7Vk4+kbESTx1FIWd+XlWIS8k7+bR+/U4U4hYnKxpjhFfoxli+wHFmtspdLIJwwMmZNe1yEuLtCQlxoqnIYugFN4wgEhJDcGo1heWNjNVmnYEqxLc0DrdMpMf8PK2bpDuvAJE8xm5//G5jOZ3ECA9YWE9jNin6zcXCATz/2HD5tclpCh0g6keew1504yhCxYopFxc3sZbKWm1GtCgkxImmIp+obtyzA0dGesvPT3S6UHIbmhLprr7PDnPEOecmwf2yW/aUH09OJUGVUYl6keepIyMJ3LhnR/k53XUhvEAeR4+/th+HhgzTxcotJ1oXEuJEU5mQJpjx0QTGRxPa1zqSAgnxerm6soXVLfF3TMRCePL+XeiNiiqtixuZspNJELVimsPGaA4jvGdCMqzGRxMYH5PGGCVsth0kxImmkS9wnJw2ruaPKhNMx4cO5F3GiDsS4p3lAE8qIikQYDg6Ko8xOokR9TGpmgnSHHZiOomCLgmGIBySzRdwesbINVANq44/T7YhJMSJpnFhcaNc23moN4rB3qh5gul0N8mtIx7ttX8d6DwhPi2LpD7xe4zGGOEdpjE2lsBQbxS7uiMAgI1MHpeWKqtdEIRTHptfR6bY82D3ji70xcNkWLU5XrW4J4iqqG4lABwZTYAxoRdL5b9i4Q5tze42RjzcVX2f7RaasrUCfOE3xeMX/y0Q32l6mZ/9Bv498lF8Jf9EHB77A+DBT+C3zn0M04Efx1cLtzo7ic2dBL78u8DA9cAL/g9Arctbjwc+DPzgI0BOkwC+6yDw038NhKLAF34LmD9VuU4wBDz+VcDT32paLJdfZQw4MtILxhjGxxLlZiuT00nsG3Bwt4ogNOjOk7JhdXpmHdl8gTpRtxEkxImmIYugY8UJpicawr5d3Ti/sFEu/3XDnr7tOsTtxW35Qkciu80c8bveCZz8L/G4fx/w/D81vfw7M78HBICbA2dwLvpq4LNvwgCA/xv5EfalPu3MEf/0zwMrF4Hz9wIHnw0ceaHnH4NoIFvLwNf+oPL7VGL1EvDdD4k7Smfvst7P3X8C3PDzwI5ryovk8qsHBroRj4hTqEmITyXxghtGPfkoROchz1Gl8+SOeAS7d3Th6soWMvkCHptfx5GRhNUuiBaDLqmIpmFO1OyTHsvJTh0cw1shxKuUL7QSGjLt5og/9M/G4x/+o+ml1U3zHYVrF+6t2PyCk/JfKxeNx+fvc32IxDazsVD9u7F8Hliq1pKem8cCzPPT+BjNYYT3qAUNyo9NCZsUntJOkBAnmobulpv6uKPj39yGphQcdPFrNyEuEzU7QurYCa2aRVQIQpy5Kv/VtaP6OoS/yEhNdQaPAm9+RPy84l+N5euzwPqc8fz2jxrrHXqeeT0JNVGzxDGawwgPUMuvms6TlLDZtpAQJ5rC3FoKC+uidFw8EsTenfHya5SwWcRtsqYjR7zNQlNklGTVipPT4mOmp10Q8cK2Y0z9e8VIiLccmQ3jcVc/0L9X/IzcYCxfnzOL7JHHGev17zOvJ2ElkvYP9CAWFqfT2WS6PNcRhBumVlOm8qu7dxh5QJR03r6QECeagjxxHB0VZeVKUPmvIm7LF3ZiaIqMIsRPXl0yvz5/0vQ0BiGObE9iajhQoEMTh1sZWYjLJT57hozH63PA2oz02rD+sSTW1fKrsoEQDDAcHjHPYwThFvWuMZMSxVVHnJqTtQ8kxImmYC4rZw4poPJfRdwma3aaEK9wq83j6Nz0gvn1rWXz6qzoiNuJJMUBRV5TdYPwN3JoiizEQ1HjDgfPA5miqA6EzXc+VMFeRC6/OlgsvypDd/aIepm0yKMCgD39XUjERHLw6lYWU6upph4b0ThIiBNNYUKTCV6iVP5Lt25HoQtNKdgIaasYcSZ/rdvINVEvTKTPmc7lcXVu0XbzUmjKqZk1ZPMWf1clJhg5CjFoOUyOeI/5NdntLi8bAgIB/TqSa243h6nLOnYOI+pCTvStep6kDpttAwlxoimcsEjU1C3r2O6HarImuOHa6bByxLv6pV20kSOuutVZwxE6M7uOELcXzdf0itu8pfJfWtYUIV7xPyF8j1VoCmB2u62WWTjiVoma5WWUsEnUiVUOQnmZ5JLTGGsfSIgTDWcjncP5RXFyDAYYrh+u7AhJt3WhF9Z24SlWQly+zd5WQlwRyVkjhGlyOll2vK04sstom2A5xtT3yJMj3nJYhaYAFo74sPVzaTxUE0miuY94fG5+HVsZB1WNCKLI6lYWV5a3AACRYAAHB3sq1qGEzfaEhDjRcE7OrJXDew8Odms7Z1L5L+jd11qEuMkRr++QfEWFEN8qP5ycSqIL9qL5UL8x3TkW4hSa0nrYOuIWoSky3YPG482FcghYNUc8Hglhf7GjZoGL5j8E4RQ5wfe64R5EQpXyjEoYtickxImGY5eoWYLKf6EyRhyoIsR1jhsDYlKST1s54kpoSk4S4tNJxKo44vv6jAtAy5MYJWu2PrYx4rrQFEWchyJA107xmBeAjYWK8qv7dulb2NOdPaJWql3oAcChoR6Eg+K2y5XlrXKpQ6K1ISFONJxJUwKKvn19MMBMLXs78iTmRWhKNGEuuddWQlzviBcKHCemkuhi9qJ5r3Rum5iyKP9Fjnjr49oRr7JsfdaUfKmWX5WR5zfqsEm4oVoyMABEQgFTaGdHnifbEBLiRMOx6qip0vHJTmodccC9EI/1tW/VlIpkTSHEryxvYS2dK9cJt6I/nK9e/osc8dbHNkbcgSOurrc+58itBGgOI2rHnIOgN6wACk9pR0iIEw0lly+YWooftTuJdfptXdehKQ6EeLs74pyXq+xUC01huVT1ZCdyxFsf1+ULqzvi1RI1y69Jc9jJ6TXkO7U5GeGKTK6As3PGefLIaGVBgxKUsNl+kBAnGsr5hQ2kc0IMjvbFsLPYuEdHx7tJrpM1NTHisT4A0m3zthLiilvN80A+Wz4ZVQtNQXbTXP5LPYnls8CmUoucHPHWo95kTQDoNQvxEw4dcbnRz1Y2jwuLG5brEkSJM3NryObFRdu1O+NIxMKW65Ij3n6QECcaipNEzRIdX/7LixjxWB/AZCHeRo7c+kzlsuxmeYxVq5qCbMq+Xv3GAipCecgRbz3k0JSo4ojHdwJMqdpUJVwluzptKr96eMTarQTozh7hHqehTwBwVJrDzs6tIZNrI7OlQyEhTjSUSQcJKCXikRAOdHL5Ly/KF7ZraEo+VxTKCrlUeYzFUKWCQHbTvkymGpYCkCPeitiFpgSC5vKEkd5K1xwwCfG1hatVy6/KUClWwi3yOKl2nkzEwrh2ZxwAkM1znJnrsPNkG0JCnGgoEw4TNY11OrjqQEMc8TYR4psatxrA6upqOemyO1gtNGULBwd7EAmKae/yklL+Sw19AUiItyJ2oSmA2QHXueHK8uyqcSemmlsJmOc5anVPOMH1eXKUxlg7QUKcaBiccyU0xToT3Fing2/ruknWLBT0Irtdq6bo3GoA52YMl3xMX9rZIJdCJBTAdcOGSyo30dCGvlBoSutRVYgP6x9brBPYMC7Q3IqkjpvDCNdwzs05CI4MKxpj7QQJcb+ycAa458+A6Ue83/f0j8S+Fx/zft8Ss8k0ljaEo9gbDWFPf1fVbTo6YVNXvvDCfeJ/taYIUW4RP9+1QwlNcSDEH7kTuP+DZgHjlMvfB+55D7B80f22KjPHxWddOCOen70b+K/fAb74JuAb79ZucnHGSK4c7aryWbObAGyEEoWmtC5L58TYufqgOUY8HK9c1yTErRxxY514VoyxJ7DT+Mm5fwSWL9geyt5d3YhHRPjKwnoac2uaMpkEUaRUfhUA+uNhjCRiVbehhM32IrTdB0BY8O+/KgTzw/8KvPlhc5OWesjngH99JZC8Cpz9OvDab3izXw1yMpxdEwwZXfmvoIPt2gKdIw4A33ovsHQeeOlHpHUt2ttHE3BVNeWxe4D/eK2x7m1vcny4SK8D//Iy4dpffgD4pS8431alUBDjcvWyuDD4lS8Bn3659d+kyJW5RQBCTA3GqiT3FuuOj48lgAfFItNJTBeaQo54a/C5N4gx+K33GsvCcf282evAEY/tAAJhoJBFN99EP5L4p8hfoO/RTSD5EPCaL1seimhO1ouHLq0AEBd7Q4eriyuiM1HDUhhzcJ6UDKsTxeZkTrYj/Ak54n6Ec2DmUfF49RKQ9vCKN7UiRDgAzE54t18NThv5yAz2RjHUqeW/dMmaJeZPmJ/rhDgLAvue5s4R/8rvG4/vemf1Y5RZOmeEzlz9H3fbqqSTQoQDwPJ54WxWEeEAML2wXH68M1rloqMoxOXuhyZHfGtZ3QLIkxBvCS4/ULlMF5YCAIeeq38sEwiY3PJbAqfRxzaN98ps2h6OaYyRY0nYYE7UrB6+CYhSwP1xUeJwLZ3DleWthhwb0RzIEfcj+aw59CC7BXT1e7PvrHQCyaWEExlozPWY2wQUed25U/PlfRwc7KmyRZsg1wV/7h8Lh/aBD4nnqqCWhXg0AbziX4DEbqB/r7uqKamV2o9XDuVIr4pxGq4efqRFrYkuXyRe8yTgx14pHg9cDzzwd8DJ/wIALK+KCwHGgERQ+pvc/hEg2iv+Fp/+ebGsKMTlZhlniuW/IqGAPh4/R6EpLYuVEN/7VOB13xLfod03W2/fM1Q2LcaZFHrFC8DcCWCP9baUsEk4ZVIqSuAkGRgAGGMYH0vgO2dF2NTE1Cqu2akJwyJaAnLE/UhOubrNeni1m1XiFXONi190U0NcpmOTnWQHuGcYuOkXjOcVQlwSrsEwsP8ZwK6D4rmbqik6F9gpaky1RUKlI9RY7JnjxuNrnwzc8iviZ99tJrEf5cKx3rerG6G89D2J7wIO/5Q59KD4vbIs/6UT4uSIty5q6UKZsZuAPbeYvysq0tgZDyg5EDP2uTvyHHaik+YwwjW13DkGOvg82YaQEPcjqvD2VIgrt1S93LfEWiqLi4vivUIBZqpUUY2OTdiUQ1OCYXtnW3bEA8qNLTdVU+QLMbXRSTUqhLgmxtopqhCXk5TVOF5JiMeK3TTHRxPmz1JK0pOT9aSxrj2JaYV49fAYwqdYOeJOkUJTjgUumF+TLxQ1HB7pRSm15fziBjbSFjkdREezvJEpl1+NhALlPhpO6NjzZBvimRBnjL2QMfY1xtgVxtgWY+wcY+wzjLGnKOvtY4xxm587vDqmlqWRYrlC5NvHOtbKyRmjycChoR5EQ85FXsde6cuOeCBUhxCvsY541w7n6wKVwrsuR1wRvKuXjMcVQtwQ110oCvGxhHksl8S6HCojC3HdSUwbmkKOuO+xyoOoU4hzadztYUozqSqOeCwcLIfUcW6eDwmihFw+9chIL0JB55JMLgfcUefJNsSTGHHG2HsBvB3AIoDPA1gAcAjASwC8lDH2S5zzTymb/ai4rsqjXhxTS1MRPuKhEFf31aDQlFpvtwEizCAeCWIzky+X/xrq7YCqA3L5QleOuHqRU6MQj7kV4l6GptgIXrXEXMgYC7FiW/vx0QTwqDS2qwlxp454IdvQPArCA6zGeJ1CPBnaBcvUudkJER5mU81qfCyBM3OilOLkdBI37/Uoz4doG2oN3wSAA4PdiIQCyOQKmFpNYXkjg/7uiNeHSDSBuoU4Y2wEwNsAzAK4kXM+J7324wC+AeBdAFQh/jDn/H/X+/5tSUNDU5rjiMtdMZ1mgpcIBBiOjibw4MXl4r46pPyXK0c8b15XxmnVFNXtjbpMiq1wxD0MTZGxccRLoSnHxhLmC9gqQvzYbrMjznNpsNJ3gQXF37D0/8hngEAHjL9WxaqUp12MuAMuprtxo9WL2U1RNWjgOsvtj40l8IWHpwCYE/IIooScyFuttb1KOBjAkZFePHJFjK3J6SRuOzTg6fERzcELm2dvcT/fk0U4AHDO7wGwBmDQg/fpHBqarNnAfUvUc6WvbtMxt93UcBO7EBOnMeJ2jvjGvLLPKnW4VTx1xG1isSuEuCGKu5DBQE8Eg71R80VlqMv8GxDfq+KFyUhCKv+VymFqRjr2WB8QikrHRuEpvsZSiNfniJ9ar1KFomrCJoUOEPbUc+cY6NDzZBvihRA/AyAD4FbGmOlyjDH2DAC9AL6u2W6MMfZ6xtj/X/xtaT50HE11xL0X4tl8AadnxC3ZG9ljuDH5LddJbx2ZiFIRmlKrEHcYmqIKZ7fx0M1wxINRIYxlZEccGRwdLTbByGkc8UBA7KNEcZ1S+a8Sj12eMtaJ9QFB6RYvlTD0Nw0S4o+sRO1XqJKweVQqk3lyZg25vIswMaLtSWXzODsvzpOMAYdHahDinXiebEPqDk3hnC8xxn4PwF8BmGSMfR4iVvwggBcDuAvA6zWbPq/4U4Yx9k0Ar+acX9KsXwFj7EGLl444O3qfUpGs6WH4SBOE+GPz68jkCzjApvC56B8h+IUCsPVu4KlvdLyPjiz/ZQpNCdtXP7GLEWcOr69V4eymnXtms7LRlJflC0v0DFeWmJPCTbpYRpyMONcna5Yel1xtqdb5+KhRh/fy9LSxfqzPLOrJEfc3Vndy6gxN+f58ldPjtL0jvqsnipFEDDPJFNK5As4vbOC64V7bbYjO4czsOvIFMa/v29WNnqh7OUaOeHvgSQYS5/wDAG6HEPavBfAOAD8H4DKAjyshK5sA/gTAzQD6iz/PBHAPgGcBuJsxVmfdqRankbW+VVHvZSJokdKE8HuhOxBE0QX62h+62sfhkd5ya/uOKf9lW77QTojXGJqiCmc3QnxD437X5Yhb3DFREzWBimTNitKFwYj54sRUwtAY/7KbNDurhKaYHHES4r6mAY74WiqLU0sFrHGlQZVc4rOKIw6QY0lYMzntvpGPypHRRNmnODu/jlTWZXgh4Qs8EeKMsbcD+CyAj0M44d0QQvscgH9hjP1FaV3O+Rzn/H9xzh/inK8Uf+4F8BMAvgdRbeXXnLwv5/xm3Q+Ak158rm2jkY64Kuob4IiXElB2stpPPKL8lziRivJfHXAS8ypZ02nVlLU6QlPUbQEh7O2SQ+2wc8RVlNCUY2N95nGsdveUYsrli1w5iXhpUbqIqIgRp1rivqYBQvzEtCg3OM+VsKjhcSBc3O/GnP57IHGMOmwSFtTaeVqmJxrCvl1iPOYLHKdnqUxmK1K3EGeMPQvAewF8kXP+Fs75Oc75Juf8IQA/C+AqgLcyxg7Y7YdzngPw0eLTZ9R7XC1Nizf0KTni3ajPSey42255NVnTRojnFdEu47RqSj2OuC4MJZ8BUivO9+HkvTWO+ErO+LzdgQz2D3QrQlxJsrNwxA8MiPJfAJDfko471meOK6fQFH/TgKoppSon81BKevaOAcPHjOdVXPGOm8MIx9SbqFnelsZYy+OFI/6i4u971Bc455sAvl98n8c72FepjENnh6ZUVE3xMjSlsY4457x8CzaO+o67427rFmqtI+5RaIobR9wqHrzW8BTL0JRKR/zCqvGZ+sN5EcIkj+OQUmpQdsilO0KhYvkvAEhAukCN9QEhStZsGRrgiJfmmwpHvGcIGLnBeF6tcooyh/Fa7xgRbUWhwE3NfI7VGJoCdOB5sg3xQoiXrCOrEoWl5U7OZk8u/j5X1xG1Oo2s9d1gR3xqNYXVLSGqegJ1CvFOK/+lhqbYhZjYJms6rZqiiOZS8xonWAnuWhM2XTjiZ5aNsJxEqPh3yNk44rIwV8Z/yU1KsA1jYWwHOeKthGWyphdCXHHEe4YVIW7viF/THy8n4S1tZDCbpLFEAJeWNrGREeO2XH61RsgRb328EOL3FX+/jjG2W36BMfZTAG4DkAJwf3HZkxhjFe2fGGPPBvA7xadq85/OooUb+sgTQQ/zzhHviPJftp011WRNu4Y+cpURF6EpgPPwFM8dcecx4qcWjb9TT6B48WIbIy6HppjHf2mM2TviJJ58jceOuFx+tUKI944Ao1Kl3SqOuGhOZlRKkRP0iM5Fdq7L5VdrRD5PnphOolCguy6thhdC/LMQdcKHAZxgjH2CMfZextgXAfw3hK33Ds75YnH99wK4yhj7DGPs/cWfuwHcDeGuv5Nzfr8Hx9W6qGLZ0xb3DazIAlmIc8R4fQJmZ3cEo33CzUznCji3sFFlixbHrnyh16EpnOtFs1P3V942IV1/r804277ifS1CU3pHKhZNzBmivdTi3rJ0ofpc+W6VkukSTBHictUUN7HzRPPxOEb87JwovwoA2S7lRm/PEDA0bnzHFh8D0uu2+5OTgieukmNJ1Nd5WmWoN4qBHjFfbWTyuLTUmG7ZROOoW4hzzgsAXgDhZk9CJGi+FSLM5EsAns85/2tpk09CVEd5IkSpw98AcB2AOwE8g3P+7nqPqeVparKmt1/a0gTTA80xu+3ciA677VZRvrDGhj5Oqqak1/QXeE7joWVHfPhx+uVucBiaspnJ4dSS8dnDpYs9XXt73XPlu3R4RJT/SkAOTaHyhS2Fx4646a7ewJj5xZ5hMZ4Gri8u4MDcpO3+THMYxfAS8C5RExDNyY6OUnWeVsarOuJZzvkHOOdP5pwnOOchzvkQ5/xFnPOvKet+rLh8H+e8h3Me5Zxfyzl/Oef8Pqv36ChauMV96UQzyDS3YDOKo805cOVB23CGjkpEUeO+HdcRt2noY5UcZvU3dxyaIm0vx8yWliengDmpiuj8KWD1qvX+rN632yzET82sYZMb8ZSsNH6dOuLJq8DlH5Rj4UvlvyoccVP5QjV/hBgAACAASURBVItjS68Dl7/vPK6eaAweN/SR55ldw9eaXyxdGNolbM5OAMsXyk87ag4jHCGPg1priMuYxxiFP7UanghxwmNatMX96lYWV5bF/kaDmhOOKsS/+0Hgo88G/uYJlsKwoxxxk7iuFppiFyPuRIhbONdOQlM4N29vEuKzwNI54AM3AH/3JODEfwKnvgx86FaxbOGsxftqQlNifeYa4BAnsDTCxoJcSghhOcQqpAhx+fk9fwp87LnAN99TXjQ+mqiMEQ9WEeL5HPDhpwEfex7w1d/XfyaiOTTQEd99zV7zi906IS4lbJ74T+Dvnwr8zeOBmUcBAIeGehAqNie7uLiJtRTVpe9kFtbT5aTdWDggyq/WSUedJ9sQEuJ+pJGVTRooxOVyTDf0aWLPVSF+/DPF5WvAma9Vro8OK/9l21nTTYy4g9AUq3rfTkJTsptGPHsoBuy4xnhtaxk4e7dxfKe/In4AgOeBs1/X71MndkdurFg0OZUERwAprohxp454iUc/W344PpZQqqY4SNZcOAUsnxePT3+18nWieeiEeM+I+A65RC6/CgCH9u0X+wKAnQeAaNFltxLipTmNF4DJzwMQzckODRnu/MkZarrSycjnySMjiXIH6Xo4RnddWhoS4n6kosV9awhxU9xbQrPfjJTUlM8CcyeM5xZlwK7pj6O3E8p/ca5J1qwxRlwW8FZVU6zCLZw44vK2wai5KkkuZR5T2S3luUVOgnwRcuBZwK2vB174VxWrlU4yKUhCWX0PJ0J86ZyIk0dRiLt1xFPS7V+KId9e5O9CqAu49XXAKz9d067k8quJWAh7dvUAP//PYp8v/ZixonyRODthVDyS5zHpsclQIMeyo5H//8fqjA8vsX+gB7GwmPdnk2ksrNOc1EqQEPcjjQxNUUW9hyJfThLZH9VUEpAd8YXTZoFjIcRF+S85EaVN49/kUBMWAAIBe0FtFyPuJFnTqkqJE0dcde5NyZCbGiG+aX6u3af0vodfALzgL4DB682rFDhOFluPb0ESyrkt58maMrMTAIBjg1F0MfH+OR5AIRSv7oibhLi3lYcIl8jfhb1PAV7wPmD3zTXtauKq8X8dHyuWlbv2ScV9PsFYsXtAdNkExP9/8ay4sFuSWmDIQrwT5jDCEV60tlcJBhiOjNDFXqtCQtyPVCRretnQp4GOuHRLbDSkuf0qC3FVeM8ct4xn7gg3SXXDARehKcoteCflCz1zxCPmGOzslnn8ZhWRbHXhZ9qnPqTg/MIGtrLigiXLJCGuin2nQrw4BgcjxmdOIo5Ly1vVHfEtKbSHHPHtxS5fwiXmJLoqZeXU8JTihV2Z5FVgQ1TtpYRNooTXiZrlfdEYa1lIiPuRCrHskePGecPKF2ZyBZydM8T3jsKyZiXJJVeFeDoJrFzU7rsjyn/pQk0amaxpJcSdiEpVNJsc8WqhKVZCXHbZK/p9AVD+93YuvJqsqXbaLFGsdsFSxn6TvFu8T7XyheSI+wfbUp7ucFVWTq2corurVxxj8hx2emYd2XZvTkZo2crkcW5enAcDDCYXu14oYbN1ISHuR1RxnE/XVIO7gny2UtB5JPLPzK0hmxei79qdcYQ3NVVQTI64piOdRXhKR1zpm4SoEyFuFyMuPXYbmuKkfKEqmitEsTR+czWEplgJcenkEozK3TJTSot7tWqKufJKmdJ4k0R1EnHxPnJoiu4ugSzEed7cFZVoLvJ4rAjTcocrt1J1xG3mtB3xCHbvEOMyky/gsXn7JkBEe3Jqdg2lxpf7B7rRFalvvMp0xHmyTSEh7kd04tiLEBKd++1RaIrJSRpN6MsRlhxxzoFpzUlLtwzAdcMdUP5LF2riWIjb1RF3GZri2hGPCFe8dDHA84DkMItQlZT5edV96kNT5JNLtEuqEa064qoDbuWIz04KESdVkEnyeNERl2PQqyRrAuSKbyceOeJy+dVwkJkqnWgxtbo/rp+/JHPhKDmWHY/5jkt9HTVVjoz0lvP7z82vYyvjgXlHNAUS4n6jULDoeOjBiV4ngjxK1pQTUB432g1szFeuVBLiq1f05fMsHPFoyFz+68R0G5b/UhMgAXPVFMAcZtKwqilOHHGNaJbF7taS8TibcuiI24emcM4xKSW5xeOyEFdjxBUH3CpGPJ8GFs6YRPUqukUyXahKi/sKIU5x4tuGRzHiski6frgXkVCV0+OOfUCkVzzeXACmH65cR3LJ5QoZ1P2wMzG3tvcuLAUA4pEQDhRrkhc4cHKGxlirUF9AHeE9VoLbi1hunegu5IQIqqHmLlYuibrR4W6TSPqxXXnhjKpkNoRb+vC/GMu6h4CNontuIcRRKODZOxcQnJ3GHN+ByalV3Lp/p/vj9TO6ZE0AIs6kKKZ5AWBF99tWfNRRNaWW0BRAiN10ceLflPIDsptmx95RsmalEJ9fS2NhXawTjwTR1S0J8YqqKaojrghxdcxJ360k78ZsMo21XBC9umMroV5IkiO+fXjkiLtOogsEgJHHAZe+a14eHwA2FwFwUR0quwWEuzoj6ZywZXJqFQfZVcSQxROj3cC0RyFKsR1A/16Mj/XhsXkRAjo5ncTjr+33Zv9EQyEh7jcshXiDHHFACJGgy9tk97wH+Nafl5++mj8N38dvAACO9Fq8z8XvAt87bL6oGH8J8NA/C3cyeQXYXALiksguFIB//Am8/coP8PYokOcMn518B3DbO9wdr9/JW4SasIBxUVOLI97wZM2iaJbjsGVHPJcyLh6AmkNTJiSRdHQ0ASaL7Wp1xKHcWbjh54AHPiQezzwCdA+WX0pC7PfqWh5Hyp+hSow4QEJ8O7Et5ekcV4maJUZuqBTie54ILJ4RJQ15AZibBHbfXJF0zjkX5RGJjiBf4Hjz3DvxrOhDYsFXPH6Dp78N46O/gP/80RQAuthrJSg0xW9YOd9eOOKWQrwGEfE/nzQ9fSH7Nrqxhf54GAPM4ir/8gOVn2PvU8z1oheVFujzJ4ErPyg/DTKOx81+wf3x+h1ZTMhC1Cre23GM+DaEpmwuGo/V5E0nDX00jnhFDoLcvjy9ZrjxABBWWkb3K23Kr3mi8XjxrOnCIcnFtpdWpTsO1ZI1AQpN2U62yxEHgD23apbdAgyNG88XxJy2p78LvTFxfKtbWUyt0sVbJ3H50nk8iz3UuDf4n09SwmaLQo6437ASxZ4ka9o44m5JVX7JB9kKdo/tAcsuajbQcOvrgfGfAR650whLWZ81r5OufJ+e7CKy+QLCwTa6jrQKTXEkxGtocZ9X3q/0/o4ccYvQlBKyO8wL5mOwGt9VQlNMImksAWwNGS+uz5qTg3uk1wDRfOVF7wdOfRl4+tvMf5/1WaDLuH07D3Fn6MKK9PelZE1/40GMuFp+9ahTR/zYzwJXvm+44kPjogvnPX9mrFOc0xhjGB9N4HvnxYXf5FSyXEmFaH/OXZnGvuLjLMIIjxyxW90ZnAOzj4rH6TXTBeTJ6TXkCxzBAN118TskxP2GlSj2IqnSUoi73Dfn5prgRQaximNjfUDmkrEw1lcpWgDgVf8BHHqOeNyjiCoZzfsMYAVn59ZNVQhaHl35QsBGiDutI+6gakq0R8T6q8stj1XniDsUFDWGplS0hZ6Vxkxy2pwcrApxALjlNeIHAJYvGMvX50xCfI7vAACcW5aOhxxxf+OBI3561lx+NRFzmDMTDImumyoWc9qxsb6yEJ+YWsXzxodrOl6i9bg4Y5gFS90HMPzr365/p4UC8K7i/JXdxGB3CEO9UcytpbGVzeP8wkb16j/EttNGlmKb4JVY1mEl5t2K/OwWdNU4BtmKuCKXxXOPxYlGXi4/VsseyrXHi3SzNE5dmnZxwC2AVafMmhxxl1VTIr3GYy8ccTtqCE1ZT+dwYVGMg2CA4frhXvOYmT9hxNHHdgChKGzplkXSHLA2U366CCHEL9o54oVC5Z0acsS3Dw+EuOfdDi3mNErY7Fym5hbKj0OxXps1XRAImEPxspsUntKCkBD3G1aiuKGhKS73rRHHADDIVsUkIL/uWoirjrj+va5cvuDgQFsIXflCwDrMxDZBzWVoSlRyTGppcQ9YN81RsRKsNqEpp2aS5VD3g4PdiIWDZsdx7oTx2Gq8yUTiQLR4sipkTXkJXf2jAIA0lwSd+jfJrFf+XckR3z48SNasKVHTDos5rSO6BBNa5haMXJSuHg/v5sr5MpkN6rDZgpAQ9xuNdMQtE0HdCnF9MuZIcFXUMTUJcU2YAAuaK6O4dMQBYGH6stOjbQ1MMeIWoSlwWjVFFuJOHHG5FKAHyZp2ZDf1x2TjiFckagLmMSMfj2686dBuzzC6+1oAQBphzetFdKFW5IhvH6YwrRrKsKIBjnivfk47NNSDcFB8P68sb2F1qw2bkxEVzK2lkE8ZOQhd3Q0U4uSItxwkxP2GV2JZuw+PEkEtxPGhrg2EgoHqoSndg2bnytYR14v+tcWr4FYisxWxEtaWjni9MeKSAJAnckeOeB2hKYDePbZxxCsSNQFTyUETThxxq/Xiu3BkTFwgZmQhrl6caIU4OeLbRp2hKZxznGiSIx4JBXDdkBGWcIKEUkcwOZVEnBnnXxbxMG5b3ldmnRzxFoSEuN+wFMtelC/0yhHXC/FrImuVr+scyl5FBPUoMbsO3qs7u4irK950BfUFeSflC2txxB0ma5aXO3DodKLZjRDXjUObZM0JU6Jmsd59KGpKsizjWIhrxmXPcLnbXQY2oSnkiPuLOoX45aUtrKXFPvrjYYz2OQyzsiO+y/jubi2ZLuaow2bnMTGVRDekOSLSbb2yWxRHfN+ubsQjwuhaWE9jbo3mJr9DQtxvWFZNaXBDHzdILnUqYIQkDLKiQJHFc7de8JifKxUGZMEp70u68h9kq+11te9p+cJGJ2tK24ZqEeKacWgRmpLLF3ByRiorJ4cN9IxU7ke9yLNCJ9h7hsr7z3A7R1zpqgmQI76d1BkjPjltXFiNjyW8abITCJrv2khVfShhs/OYnE4iDmmOaKAQDwSYaZ6kiz3/Q0LcbzS0xb3Fvt2KfEkcX8Zo+XFvbqnidcQSQEgRaaobGek2xGA+Y5TSA8yhKTsPlB8OYqW94t9cly902tDHwhHPWTnitYamOIwRB/TjTRaykhA/t7CBTE58htG+GHZ2S2ErFq62Iyy2HeyNYqg3So54K1GnI67NQfACixKGlLDZeZyYSqKbNcMRF+dLCk9pLUiI+w3ZLZSdSk9a3Eti3rRvt464IbRPZwfKj8NbC8XSboaDKUS2MulYuJFl5PAUWdTvOlh+2H6OuIflC9HMZE2XVVOAyvHGufmOgBSaYiuSqo0jO3TbFt308bEEsrIQpxhxf1NnQx9tDoIXWCShy82Czs6tlS80ifZkI53D+cUNxE2hKY2KERfnS0rYbC1IiPsNWaTE+/XLa963JPJN+669asoy78FKsS0443nR3lwNJ3EkxC0SNuV9SY74EFturwnGUljXm6zpQIjXVb7QZUMfoHK8qV0+pdAAW5FUlyNuPQbHRxNK1RRyxH2Np454nxdHJLCY0xKxMK7ZKb4v2TzHGamjJ9F+nJxZA+doWow4YDYtTrSTYdWmkBD3G7Lz3SWV+PO6jnh8V+37lsTxBmKYL3YjBCBOOCYh3l159a8VUA4ccTk0ha22V/kvR6EpTpM13VZNkWPEnTjidYamVAhxm4opakdNmWoXdHbYiPhjY31KaErG/LcnIe4v6ogRX97IYGpV/O8ioQAODnookGyS0I9Jgr+t7uwRFZTMhHgTQ1MOj/SWW9ufX9zARjqn25LwCSTE/YbJEZeEuNfJmvWIfEkcb/IY5rnkImmFeD2OuBQj3r+//HAAq2AotM9JrK5kTTVGvJ6qKTU29Am7CU2xE+LGZ+ecY2JKSqRT3Up1HLGgeVzbYRPWMj6WAEcAWS79XeVjpNAUf1GHIy7fcTky0ivKr3qFTVnWcaqc0jFMFuewblOyZmNDU2LhYPmiknPg5AyNMT9DQtxvWLrWHpcvrEfkq444ZEd8ziyeHYem6BObTKI+vguICTEWYgX0Y719wlMclS/0smqKRR3xRjf0ASq7x1pUTJlJprC8KV7rjYawp79K0m/PkGj57ITuAeXvhPK43LszjngkWOmKlyBH3F/UESPesERNQJnTZkwvUcJm51AaY81xxI3zJSVstg4kxP1GziPXWrtvaSKoR+RLQnsTtTjiutriUik6q9CUSLdJxA+ylfaZYCwd8UY19LFI1qy1aoqrZE1noSny//boaAKBgFJWzq4MZjXU8nLS9qXyX5ZNfUiI+wuPHHFPEzUBc3lNJTRFfq8TU8n2ak5GlJHLrzYnRtw4N1PCZutAQtxvmBzxBsaIexSassGj2IxIoj551RBzLCAEmnqSifaiAiehKRVCfLV9JhhTwqIUElFT1RQJR6EpCf1yK7ShKW5ixJULP4vQlMlq3Q57lTriurridsjCPRgFYsadnfHRhHUJQ20dcRLi20YdMeKNdcStQ1NG+2LYERdjfS2dw5XlNmpORpQ5v7CBdLEqTiJoYX7Ui6UjTnkIrQIJcb/R0GRNi9CUemLEEUNkh1FLHEvnjceRHuHoWrSpN6ELTeG8sgKLtN4gVtqn/JfscNfdWdNJ1RRJ+EfrKV9YS9UURbRahKaY3EqdSIrtMN89cOOIA2ah1DNsuvswPpZQmvrIQpxixH1FjY54KpvH2XkxNzEGHGloaMqc6bvIGDONaYoTb0/kOaw30KiGPpUx4oDZvDg5s4Zcvg3Ok20KCXG/4ZVY1u5bFvnelC/cQAw7BvcYry2dMx6XJhuLNvUmdO5RPmOcZANh0cVRCU3J5jlOz7ZB+S/XoSl1NvTxOjSlrvKF+tCUiWqOeCBgFjtOK6bo1ldE/LEx1RGn0BTfUmOM+OnZNeQLQhzv29WNnqj70oe2RHuNZmbZzQpD4pipw6ZmTBEtjzyHxXlzY8R3dkcw2idCBtO5As4tODgPE9sCCXG/YRWaoia41bRvC5F/9UHgLw7ofz71MmBzybwfU2hKDCO79xqvrVw0HrsR4vEBlGtmby4Cf3kE+O4HK/clO+JMnLwmp5PA4mPAx54PfOaXnbm6fsNJ+UI58dI2RrxK1RTOraumNMMRP3cP8OGnA196e/FYKpv5JFNZXFoS4zUUYLhu2OJWbl1C3Hrb64d7zU19PnQrcO/7RMOqlMa9zGwA//5a4KPPBeZOWL/nhW+Lz/7VP3B3rIQ1NTriDQ1LAcT3UB5j79kD3PNnxntSDG/bUxpjDAWEC3KzvsbHiAOUsNkqkBD3G1bJmk7EbNV9S1fkvWPG41IjHt3P2buA458x70epmnLtXqO+t+mkWJogrn2SsWzgev2xBUPmmN+1aeDud0n7KgoxKQ54kIlY3cmpJPCZVwOXHwAmPgc89An9e/iZusoX2lVN0b1XHmVRz4KGawc0p8X9xe8AM48A3/+/wPSPtI74yWnjLsehoR5EQxaxv4nd0uNR/TpW2GwbCweRDSu5DPf8GbB8HtpKNFcfBI7fCVz5gfkCUuWbfy4++3c/aC/YCefUKsQbmahZQh5jAPCt9wIrl8V7UgxvW8M5L4+xGDJgpXkjHHedy2CLnHOl6AS62GsNSIj7Ddnp7Oo3hE52E0g7iLW23G/BLMQHDwPHbne2rZJolJeOIx+KY++ePULQqZTE84//oWjG0zMC/JyNSL7tzRUNXYx9VTriQygK8ekkMHPcWPfs163fw680qnyhzhFXha/8N1eb12iPtc4W9zIrF7UOu3yr3lYk3fpaESs+ehNw6Hnu3vvY7cDOg0D3EPCEV1e8/NDwy7DOpc/FC8D8qer7TU7ZvHbVeLx80Xo9wjk1Jms23BEHgCe/oTIxb+USAODAYDciIfFdnVpNYXmjBe/kEZbMJtNYKv5Ph6Mag8or5P2lyRFvRTwOiiPqpqAIsp5hYFU4KNiYM4cRuEF22kNd4rbpz/0T8KL3m9+zxA8+BnyzeBtViektpNdQOt3tHhpEMBgUAnlt2ryPsngeBH7rQQDc/kT55DcAT/gl4G9vttmXuWoKUGzhK1e201Vl8TsmR9yqs6bDGHFUCU1RhXQgIN6ztM98BghFrY9VF5pSqxBfnwPC0omkKOyrJmqWOPAs4HfPiuNnzHo9Hd27gDc+KC5+g5VTYfrIz+Dmcwfwpcjv42CgOB7l0KtQlz5kTBdDrntNucAlaqSGGPFCgeNEMxzx8RcD1/0E8MmfAS59Vywr/t/DwQAOD/fi+NXiPDadxFMPDTTmOIimMzltfNdvGAwBC8UnjRTiVRxxzjmY23mSaDjkiPsN1em0aZPsCjlRU47n7dohmptU/Mh1xiWxwTkCUqz5gbHi8ekqVshOUCDgzK2KdAND4/rlgEmIDwWEI76mtu+NNuik2kisHO6664hr3G1NTDaCkvCuVgFEF5oSCJhDXJyyPqt12CdMre371K3MBMPuRXgJxrQivPS+aURwnkshU0U3E4B1lRYrIc65IsTr+D4TBjWEplxc2sRGRnyHBnoiGOq1ufCsl3DMPKdJ//dj1GGzbZm4Ks1hA9Kc7GXpQsBsZGTWTXP+Nf1x9BaTkJc2MphJUlK5HyEh7jcqhLh1LVpXyImaThLr5JhfWYjnMwhycYwZHsThPUXBrkuUq/XKX7uv4uQV31kOg+nDBiLIIoi8sq7HjkMz2M7QFEBUpNG9rj1WfZUTV23uS1QI8TAyuQLOzEqNKRoVNlCFo8X3TUIaTyYhbpEcaiXEs5vm/xs54t5QgxBXm0U13CW0mMcphrd9kf+f1++UhbjH56dgSLojyU3n61JzsvIx0cWeL/FMiDPGXsgY+xpj7ApjbIsxdo4x9hnG2FMs1n8qY+xLjLElxtgmY+wRxthvM6YLNu4gTE5n0DyBr9UjxCUx7USIy6EGsohXaoiXRVI1R9wN2n0VJy+lI+IAVrETyuSiC7XxO1bJmqYwE6d1xN2EptTiiOsb8LhK2CyxPlfhsD82v45Msebt7h1d6IuHLTZuLKXyX0kufS45NMXOEdfdiVAFOglxb6ghRlwOG2hYWIpMryzEDUecYnjbF1mIH5CHWCOMIqfhKTTGfIknQpwx9l4A/wXgCQC+AuCvATwE4CUAvsMYe5Wy/ksA3AvgGQA+B+BDACIA3g/gDi+OqWVplCOuxohXQxZVUpJnasP4Im8ihiMjJSHuoSOudkxU92UqYbiCIaYIHC9qrjcbXbgI4LChj1pHXHb3qoWm1OKI6xvw1BQnvjZT4bBX7ajZRMZHE0hCFuIOHPF8Rl9XnIR4Y6ghRrwpiZoyFvO43ETo7Pw6Ulnl7h7Rkqylsri4aJRf3d0t/V8bLsRtEjbprosvqVuIM8ZGALwNwCyAcc75r3HO38E5fxmA50NYeu+S1k8A+AiAPIBncc5/lXP+uwBuAvBdAC9jjL2i3uNqWWxjxJvoiMvrSNtemDbcnGywC12Rogj0NDRF4zTKCZhKwmapjKFxYC0oxF0nazqNEXcYmiI74tWEuOyYm0JTanXEzQ6740TNJjA+lkCSS+NYFtPxXfpqQep6VstIiHtDLaEp03IOQjOEuDyPzxiLoyHs2yW+N/kCN4VkEa3LyRlz+dWwbIR5HSOu7pNKGLYcXjjie4v7+R7n3JR9xDm/B8AagEFp8cuKz+/gnP9QWjcF4A+LT9/gwXG1JraOeD3Jmm5jxPVC/KIkxE1ffk9DU6qIeun10aBOiG+i5chbJWvWECPuqmpKqepJrcmacmhKDcmaG3MVwn5CKl3YFJFkw7ExxRGX6dphfRfAkRCfq14qkqiOSyG+sJ7GbFKMuVg4gP0DDRBGKjbzuJyMPEEdNtuCiavyHNZnFsdNDk25brgHoYA4J1xc3MRaKgvCX3ghxM8AyAC4lTFmqr3EGHsGgF4AcmHnZxd/f0Wzr3sBbAJ4KmOsgWnsPqVQMAsnFvAwWdOiaooVFkL8yux8+XEoJgvxRidr6kNTjvRuYRCKEG/FduNq2coSdSdrOgxNUWuJ2+FlsmYhZxrXPBj2WWhKn9kRl4n1WZd53FqpXKYKcU3bc6IGXMaIy+PryEgCwUATyrlJeS3YmDfd0SLHsv2oaBYlf8+bHJoSDQVxaMg4V5+QmqUR/qBuIc45XwLwewCGAUwyxv6BMfYextidAL4G4C4Ar5c2OVz8fVqzrxyA8xD1zQ+or6swxh7U/QA4Ut+n2iZUcaW2SG6qIy5XTTG2nVtcLD+OdUsiqdGhKRaO+IHYRrmeeJmOCE2pR4jrQlMkQe0qWdMmNEV2i+3ix1evlB+uZQNIpsRnS8RC2L2jBpfdQ/b0dyGndtgsEeurzxEHqIShF7iMEW9KR02VUFQ0aAPE93jTmEcpYbP9qAivMznizQ1NAdSETbrr4jc8SdbknH8AwO0QAvq1AN4B4OcAXAbwcSVkpXQfzmo0lJbv8OLYWgqduJJF6caccM1rwRQj7iCWVxYYRYc5X+BYWl4uL+7ulf5FdiUH3RJNVAoceV9SBYKxULL9QlNMjrgmzKRQgJGEyUQNb5laqqaYkjVthHghD3AL4aNe4HXt1D9WkYT4/KZxvONjTSgrV4VAgGHXgEV1FDtHXCvENS45xYnXj8vQlKYnapZwUMLwxHQShQKFK7Uy2XwBp2eU8qvbGJpSPoYidNfFf3hVNeXtAD4L4OMADgLoBnAzgHMA/oUx9hdudlf8XXU24pzfrPsBcNLVB/ALuhNKuAuI9hmvby1XbucEOVzDSXULU2iKELYXFjcQzhuCPhaXnMJoj7mxAFD7hKPeCVD3JZ3QdvFljSPeiqEpFuULZXe79JWwcs/ttpHRhqbIMeI2oSnqtrJQVqvxlBxAQIhWWIhqSYjPbkhCfLRKI58mMTaiqeIDVHHEHYSmACTEvcCtEN8ORxywTLwf6o1iV7f4Hm5k8ri01IJGAlFGW351G0NTAAp/kzqUKAAAIABJREFU8jteVE15FoD3Avgi5/wtnPNznPNNzvlDAH4WwFUAb2WMlUJNSmcjq7NsQlmvc7CKdTTVoDUy7l3hQbLm5FQScUgiV3W87cSzW1SH3UKIxzOLGFJjxFvSEbcKTdE54lWEh6uqKZpkTTtH3CosBTCPmWBUXJyViMStRevq5fLD6XXDbd/uRM0Se3eP6V9w64jr4sYpNKV+XAjxrUwe5+aFUAkw4OjIdjnixv+dMUZCqY2YnNJU5Gl4aIq9I35MMjVOz6wjm6/xzjrRELxwxF9U/H2P+gLnfBPA94vv8/ji4lPF39er6zPGQgD2A8hBuOmdhVWsoxcJm/WEpuQzQCGPiakkuk1CXBHaduLZLRX70ldoCWzMYTjQbsmaVWLEqwoPN6Epuhhxp4640mhHFuLhmBIj3mWuZW/CcO2vJPVJbNvJoWtG9S94EiNOjnjdqE3QbDg5k0Qp8mP/QLdRfrUZ2Mzj46ZW953nQbUTE7pk84aHptjHiPfFw+V8m0y+gLNzlCTuJ7wQ4iVLaNDi9dLy0tn9G8XfP6lZ9xkA4gDu55xXyRhrQ6wElhcJmyYh7iA0hbGKNveT00nEmZ0QVx3xOq787dz1SI9xbLmU2aUHWtMRN/3vq1RNqSY8aqmaEnJYR9ypIx6Om8ePw9KG81vieCPBAA4ONqGsnAOuG92Bda45/mjCZYy4Zlk93XIJgQtH3ByW0uTQJ5sShpSw2T5ocxC2OUYcoA6bfsYLIX5f8ffrGGO75RcYYz8F4DYAKQD3Fxd/FsACgFcwxm6R1o0BeHfx6d97cFyth6UQ3wZHHKhI2JzcVkdc2pcuhlymFaumuOms2YjQlKDDZE3HQryr8rkDshCf57rhHkRCnqSw1E00FMRmQBnL0YS4CCJHfPtxI8S3K1ETsJ3Hj1FoSlvAOdfnIGxzjDhACZt+xosz3Wch6oQPAzjBGPsEY+y9jLEvAvhviPvk7+CcLwIA5zwJUVklCOCbjLGPFpM5HwbwlOL+/s2D42o9rGLEPXHEJZfYaStySbAvrCxjYT2NOJNEWkWMuCKea+m0WN5XFXfdqr04UA6laSnclC+sKsSlx05DU0I1JmvKyMmaoRqFOBfjfrs7aqrkIsrxxIpuqtXdJRLizaNmR7zZQtx6Ht8/0INYWHzXZ5NpLKx33g3hdmBqNYXVLTFH9nUZ4SDbXb4QIEfcz3hRR7wA4AUAfgfAJESC5lsBPBnAlwA8n3P+18o2nwfwTIgGPi8F8EYAWQBvAfAKzju03VwjY8TluGmnAlkST+euikY+9o64dKIJd1eW1XNDNXfdzhEHWs8VtypfqIv3duOIO66a0mRHPLFHu/uSI+6XRM0SgS6lmmpJiFMd8e2Fc6WcpnXMd77AcVJqZrKtjviaOek+GGA4MmIuY0i0Huodl3L5VT+EpiiOeKfKLD9SvdaTAzjnWQAfKP443eY7EAKeKOEoRtyFEE9OAd//CHDNrUpoisMmKZLbd35mEUBAqZpiE5pS72Sj1p1WBY+dIw6Izxut0XnIpoDv/T0wO1nb9joGDwNPfaPhPK/PAQ/8HbB6VTzfXDDWtXPEH/w4cOl70rrVYsQlR/zCt4HTXzWX1tOFptg64pqwlhJqTLgaMy6zcz+wNlXh2GeKU1LT43erEOnph6k4T1mIW8WIKwnEnOuF+MYc8O+vNS/rHgSe9Hqgf6/FvpPAA38PLJ61OeBu4OZfBsZuMpZNfhGY/pHYd3wX8MN/BC5/X7y25xbgll81Jwo3i4v3A6e+DDzhl4CB69xtK5sXLGiuMqRwfmEDW1mx/lBvFIO9TW7erIsRP38vcOYu4OZfxvhYAg9fFuNmYiqJp19nlXZVA5yL//elB7zbZ6uy+wnAE1/rzVjPpoDvfRiYnQAA7JlJ4v1hcbF3KNUD/HtxnpDn90YL8asPVs4pI4/Dnltfj0QshGQqh9WtLK6ubGFPfx13rasxdxL4wUf1816jGbsJeMpvNv99a2QbZl3CEicx4m6Su+76I+D4nWJfA4eN5Y6FuPElvTq/BGAA3U6TNesW4v3m5+oJtpoQt6zQ4YCHPwV8/X/Xvr0VkR7gyb8uHn/j3cBDn9CvZ5WsefF+4LsfVNatVjWl6HpkNoGPv7ByVW2ypp0jbhOaUuGIS5O8eiHVvxdYOF1xYVlyxI+MWnSz3CZ6+nYBRrlzFKIJcTvRqSOe2TCc23Bc/O1SK+JC5Pidldsvnwde+a/6fX/vw8A3/6z6QZ+7B3jTw+K7M3cCuPMXxfLVK8CxnwW+9DZj3eN3Aokx4OhPV9+vl2S3xLjkBSHG3/hDd9u3SlgKIOa0QEgcc3oV2FgE7vj/gHQSmH4Y44eN77bnoQOPfQP477d4u89W5fidQO+I+A7Uy48+DXz9j8pPjwI4WvJGloo/Kmq/DS+QQ1M25irnlON3gsX6MD52GA+cEwc1OZVsrBD/3OvEhf92kNloKSHuj2woQmAVIx6TbotbJGJomT9h7HduwljuWIgb683Miy9vLySBG1VOZsOPA/quEY8PPdf5ceoYuB4YvkE81k2Y1z/ffvt6QlNmJ6qvUwsX7jMeW73HyA1A94DxXL4AUUU44CBZsyjEF05VrgcYYlqeyNM2Y8wuNGXvU4048UPPBQ4+23jt0HOAF/wf8TgUA378D4H+/RW7zyKEa3fGkYiFK17bTiLd5gvDNRRPpnZVU+Rbv7Iwj/UBh3/K/g0Xzli/NvWw/bYlli8YjvGD0kXfI3fox8P8NvRBWzxr3BVZtPnMVrRKoiYgQvXkO30zPxIiHABmJxtbS7xRc1qr4tXfw+1+9j/T3MXYK4YfV92cmp0wNUlraMIm5zTmXECOuJ+wihHXNNdxhNW6ToW4lHy3sia+tAkmxZ+pcbOhCPDr9wEzjwpRVg+BAPCaL4vbbNdq9jX6Y8BvPSheB3B3cgzDd/0WHhe4IF6vp4ShLJqe+GvAnltr39f6DHDX/xKPZx7Rv8fz3gX0jIhQoEPPNYtvWVTranE7rZoSsXCYS+ElMSkUxO5Wol1oSvcA8Kb/EQ169jxRfI7f/IE4hqEjwN7bgNGbhPOaGBUXHZfNt8qzCPkuUROA+e8DYD4bEx3JrBzxQk6MwdKdIVWIv/hvgWO3mzvlrs8Cd71TPOY2ycbyXYRnvgPYecD8+uffYGzP8wBCQGbNvI4umdkuJKlRBJULmUK+ai1w8/ot5IgD4n+/UQxLWb5oLE+t4shwDxgTGubc/Dq2Mnnv6pzL42/8JcBhzd2xdufcPcCPineZvAqXkPaTfvyv4Pe+J86ZoQDDn7/0BoTkPKloD3DwOd68r0o4BvzGA+LOh/zdvvyACEkqHuv43iYlbGY3je9mMCrmu2aSsGjC5lNIiPsJq5OK10JcbUVuhfS+MS5O0n1MErgxTRxvVz+w/+lOj9CeaC9w4FnWrw8cEj8A9s6tYeUuyWmop829PElf93zg+p+ofV+5DHD3n4iqKCuXRHfFrh3mGOIbXy5uleqQRXV8J5C8an5dF+eo68ZpFTtbcrUdC3Gb0BRACOyE1ABnUOrbxRhwzRON5yM3VGye4SHfNPIxoYz1qVQUhwBrRxwQf0crIR4MV46rpXOSELfpfCcL8R97eaUQ/883Abniybh0UlbvclSrptMs5DkPEA6xGpZmu73zZj7b7ogD5nG0csl4XMgizjLYP9CNc/MbKHDg1OwabrpmR+U+akEef3tvE+Om0+CFhgrx8/1PxecL4vt+bCSB0OM9Og86Jb4TuOFl5mXRXrMQb1YJQ/nv29XfmePNBRSa4ieshLgsnHNb+iYtOup1xKUY3xhLI4IsYqW+TIFQfeUJPWb/QA/SzBBFq2t1TLSqaKqHUAQYOmo8nzlembhn9x6qEFdxWjXFSti5FuI2oSluGb2xYlEWId9VTAFQcffnwkbx76464vLfXv47Ovl/M0lIFiz+X5ybhXi3pnqQvJ/S/z2tOOJ+EeJqPsLWin49Kxw64nPJVLkkYDwSxL5dDYjTdYKVEAeA1CqOSUnKnnbYlC/8653TWhWnc5wbpPF6NmmMP9/MYfJn3lrBoaEeRIJijrqyvIXVzazFhnWyRePNDSTE/YTVSSUQMN/CddrC3VKIOy1faIiMGDLoheKG21QoaDbBAEMoapxcr8zqsmQc4qUQB4ARSXDOHBf/v5LoCUbs67rLf2Pdek5DU6zqqnsZmuKWwaNm0YhiaIpfTmIyyjg4kwyK8l/q/yQh9TRzLcTl/5vF/yu1YvwPIj36ykC6/ahCXBuasg21q9VwGLcCyaEQn5Dcv6OjCQQC2zR3VRHiDeuw6fWc1oo0QohL+zmxZIwp34TXKZ85EgrgumFjzmiYK07jzRUkxP2E3UnFbXgK59aVQ5y0uFfeswsZJKqFpWwzXXFDiE8vLtusWQWvr+blEIyZ45WTlN0FjSyq1Nv4gIOqKQXzbxWvQ1PcEI6Jso4SXbEYRhIOx2czUcbBbCaKqdVUZWjKjmuNx26FeEDjZKvIdcetaukHNBdiapK3TujbVctpFOp7NkiI+yIsBTD/71cvm19LrTYuYZOEUcOF+COLxmLflF/VfOamhKfQeHMFCXE/YZWsCShC3EEiop1r7tgRl0JTkEECUqKmD79c8W4jIXGuHiHu9SQyqjjibvYvC/G8Tojr6ohryhdaOazbGZoCVMSJ7x3eYTTB8BPK/ymJbr1jKVcuqMcRt7qDIYelWFVJMO2nFJqiCHG/JGt66ohbx4j7IlETMP/v16bNrymO+MnpNeQLHjVdIWHUeCG+YPyvfFN+VSfEm9Fhk8abK0iI+wnHjriD0BQr15wFnYcUSLfdu1gG+3skN9SHX65EwphgllZrnGizKcOlC4Sdx9PbMXzMeDx/wuxquhHiTh1xXWiKpSNeHAtyKcp00jpG2cvQFMActgPgwLCLRL1mogpxHhcnMTWcQ44lNwlxB3dZdLHdKk4ccd1+1KopHeaIn/CjI66SWsWg1GhoK5vHhUV9l0TXkDCqiJeum1y6fNeZsyBW88KY8FX51UiPcT7IbgD5LDniPoSEuJ+wc3dkF9uJI15vfLiybgxpHN0hiQMffrn6JSG+vr6GrYxNCTgr3ISNOCXWB/TvE48LOeDy98yv2WES4prEGq0Q1zjiljHipRb3IanEITfqG6t4GZoCVDjih0Y1Cal+QOOIT0ytVt55MjlQK/rH9cSImxxxB5V2uEXVFN844o0X4hvpHM4XBW0wwHB4ZBvdyipCHBCJfk8LHMeLA/dj8sqi9fpuIGGkFaV1kTLmyEyoF6WQQN8kagIiTE02WVJJHJWO7+zcGjI5mwpNtULjzRUkxP2E3UlFTgpzkqxZb8UUoCJZ80CvdPL24ZcrHDNixGNI4+RMDVf7jZpAZMF54dvO30MW1bU44uWqKRa3uGUx7eTWreeOuFmIXz/mU0dcaV6V5HHhJqnOtZXr5iTvQBfbrWIS4lYx4hpHXL6IC4T142FbHPHGJ2uenEmWP+7BwW7Ewh7V5q4FWyEuxshzei7hU5H34G8iH0TkR5+s/z1zGcO8YQFz865OQiNK60IaqxsB49zjm0TNEoo5kIiFce1OYbJl8xynZ9csNqwDqtLjChLifsLLGHGrdZwmagImR7yLZXBt3N+hKfLFSgzZ2m67NUqID0hJibOPungPWYhrXExtjLguNKVK1RT1WFIWt249jhFf4j34YUHUGj/PR7BvbLTKFttEIFhu7HSa70EScVxZ3kLyyMuNcffk3wB6pUYSi48Zj5fOGY97LT6jLrZbxRSa4iRGXPN/j/box8N2OOKeCnG9wPZNoiZg7pKsUvzsN7MT5UWJuR/U/57y3S2fVbtqOk7mOKdIY3W5YJwrfVf1aTsSNskRdwU19PETtjHicmiKg6opVq65i9AUHoqVZWAX0hiJSo6ZH79cSihNTYkojZpA5IY9G/PO36NZVVPUY7F0xL0NTTkxncRvZ96M5wYfwuzQ0/GPIR9PSS//JHDqy/jT+/qAWfE3nlwN48m/9nWRhDv+EnO3xJnj4nc2BcyXWsozc86AjJMY8bUZ47GlEFf2o4r6SI9eoG9HHfG6Q1NszIsivknUBCq7EcsUP/tY0Dje8Na81drOIVFk4GXCpiTk5zOGCbTtY0zFImHzKxNiLmlIwiaNOVeQI+4nbIW45GQ7EeKWjrjz0JTlrHEM3YEcEqY64h51fPMSpdxibY54g26pWYURuKqa4jRGXHbEHcaIq8fSpNCUyakk5tGPf80/B0N7Dta9v4bSOwLc8ium45ycSorwmpt+QXTRHLjOqPmfvAJsLgFzk4YDvfOA6Hanw1GMuNvyhfnKRE2r/bdpaIrZEd9mUeAgRrwvb1R82pFfxtxaHV2CAQoTkPFUiBvbLxXEuac/HvZf+VVyxH0PCXE/4ThZ04kQr7O9PYALq4aTtjOSA0v7/MslCfEYy9RW/svUmtfDiw0r97LaBU1NyZo1VE0BrCt+yHgcmiKfBHyV5GTDMbtaz8FwZSfVkjMOVMTEm3BUR7yG8oXq/5IXOiZZM5cv4OSMcSGy7W6lAyHONoz/8SBbqd+xNIkiHxoozcTJHOcUaftVXmxtP9bnv/Krms98bLfxPTgxlRTNybykUefRNoWEuJ9wmqxZV9UU50L8zJJxsu4L5/1/lWtyxNPYyuZxfsFl+a9GfUYvHHErV7tiG11oileOuLehKXIb720XSQ4ZN7Uh14gkUwOnR5wLcVOLe51jnQU2S1U0GNA9UH0/XCPEC/n2dMSDlUL83MIG0sWqEKN9Mezs9qDSTz1EbcZ46bNLdz362CZOXqkzPMXv83YzaZAjnoQwynw5h8UqhfhIIob+uDBh1tI5XF5yYO65gS7+XEFC3E/YJmtKjniTqqacWjREV3cg4/8vl+yIQ5zgXd92a9RJq9tKiLtwxHWhKbp6uLqqKdVa3ANND01JZfN4bF5cKDEGHB7x4UlMg9ysQ1v+a/THjMeqIy6/pqK7kyGzsYDy/zO+y/rvr4a4VDjieX0yaEs64vYx4r5K1AREiGHIInSh9F2W73oAuHrlomZlF5AQN9CI0pqRhXjREffFGFPRzOuMMaWLq0cNjpT3qXh/QgsJcT/hZYt7y/b2zoX4xIJxPF1QhbgPv1whc2gKUEMiSqM+Y7RHXzas3mTNTU2dYW1oilflC71zxE/PGqFD+3Z1oyfq40RNCbX815k5JQZbdr2nf2SukmMbmqJcQKn/MydhKUBliIvWEdcI8VZ3xHVC3E+JmiWsvvOpVXFhsmXuCrw4c7m+9/P7vN1MOtIR139mU5y4lwmbnJv/tnZ3gQgAJMT9hW2MuNtkzfqE+Foqi8eWjZN1mKf9P6EroSlAvY64x66/LjzFTR1xXTiBTojLeB6a4l2MuO/cShfYnsRMnVRPApliM53uQXsBDdi74nKiZq/NftRwJp0j7pfyhaojnlkD8poLTiuqCXE/jjE7IS7/j4vkkjPYSLv4m+j2W35vH97JbCaNEuI8jmgogAMD3TYbbBNWQtwu16UeMhvG/BKOA6FtDgdrAUiI+4l6yhfOHAdmHrVfB3CcrHlyZg0pGLe+WXarxYS4zxxxQC/C3DjiOjYX7LcpmapOkjVNzWiWgQvfAZbOi+e5NHD2biA5pd+2BnzpVjrENmEz2iuqo6iM3FC9hrNdnLhTR1wV8xWOuEWyph8cccC6q6sOG/OCc64kA/tkzrL6zvO8ud58kQGsmhJOXeOkmVSn0KDyhUl048hIL0JBH0oqi9rpcgUhTx1xqtLjGh+Omg6m1oY+574FfPhpwIdvA87fV1ynPkd84uoqUpCuZDPrRmx6IOyuQ2ezkIU4EyEUC+tpzCVdlP9qqBCv0xHXoTuZ6FxVt+ULT38F+PgLgA89CVi+APz3W4FP3Q5c/LZ+2xqQEx1bTYjLx1s1YdNumYqtIy7XELfIOajYh84RL1g44mnrEKZGoRPibgSSzZw5k0xhaUPsvzcawp5+n8xZdt/5hdMVi4bYMian6hCNfjdQmkkDHXHfzmEWn/ngYDciITFXTK2msLzh0R0xGm+uISHuJ2yrpkgnETVZ8+53GY8/dbv4bSnEnTX0mZxOIocQMlzTrc6v3dmkz9YTMCaVCTe33ZrpiAej1TudVnPEX/xBzTYeNPQpkU8Dp74MTHzefluXFAocJ2S30i9hAw6RT7ra8l/7n1G5kW6Ziim+WxHLi5JbmtjjcB+8MqGX5y0uzLjzyjxeoYamAO46HtrMmbLLd3Q0gUDAJ3OWrRA/U7FoEKv1hQ6QMDJoWIx4t39Cn1QsPnMoGMCRESPx3LPwFBpvrmmN7KhOwTZG3MYRL8WgAobDVGeL+9KXMoUIIlBEvV+/XHKLe2YI8cmpJH78sI2DKNNMR9zJ/q2E+OBR4PGvAm78+SrbFAWi2xb3Mif+U98Upo7QlItLm9jMiGMa6IlgsDda8762g1L5r+XNLNbSOVxZ3sI1O6WL3Ce8GkivA3PFduV7nwIcfE71HduVq5x5RDqAxznfh9NkTUBceGnKADaMuh1xZ0LcV26lS0e87lriJIwMyBE3vTQ+msAjV8SyyakkbjtkURLVDTTeXENC3E84jhFXHPGB60RSWHk/+bpa3GfzBZyeEeI+hSgSrSLEpYuVcCENIUKZuyv9Zjri9QjxJ/86cPMvV9+mmiMuu+dWx3PxO/rldTjiqlvpuyYYVSiV//rOWZEsOzGVNAvxYBh42m/XsGOLpj65tPk7LieEVtuHNlnTYjzk0qJDaLPQOuK1CnGzeWHKQfCTW+nWEWciRjyXL9QWg0zCyMBDIc5TqyjNWmss7t/yq3ZCvBEJmzTeXEOhKX7CNkbcpmpKVBnsS+fqanH/2Pw6Mnlxos4GNE6lX79cwbCIXwcQQAERiJP0CaduUjZlJKwFI9b1fmvFSyFuG7KiCU3R1Y1WcVtmqh4hLtWt9a2TVIWGtInWhRUBQoSXRGf/Pvux4yRG3CoERedQNxJdgqhXjrhfk4Ht/nfJKxWLBtkK0rmC++ZkJUgYGXglxLMpsKLZleVBDO/c6d/yq5EeY07IbpqqIzWkhCGNN9eQEPcTjh1xRWSr7vfMI5WueQkH4nLiqvSF1FVZ8fOXS7rQiAdEwub5xQ1n5b/UCcRrl7aW0BRYHAPTxO6XX5OFWCk0xYEQDwTdifE6QlPkBEffVLNwiXzcdSXTyVi1uXfanVPdhy40BQAKmuZQgN6hbiS6kokeJGsmU1lcXBTzZCjAcN2wpob/dqF+77sHbVcfxCoArk8KdgIJIwOTKN3QN0lzglTZJ4k4xnf7+O/KmPn/Lh37kdFE+TR3dn4dqawHOSI03lxDQtxP2MWIywJaFd4VQvx4XcmaspMUjGrW9/OXSxLiR3aJvyHnwMkZByexRk8gzXLEtaEpDidYN5/bo9AUX4UNuMB0W9crN8kqRtwkxG+ssg/FVdcJW6ta3W3iiJ+cNnIaDg31IBqyuXBtNup3bMe1tqtHWRYJbNZ21yWXNpq7sWBzw478iCpKU/Vf3CR53P9zmMWdgJ5oCPt2iTGRL3Ccnq2jTKZm/77WCj6ChLifcNxZU3XElZPZzPG6kjVlURGJaSZuP3+5pAuWxw0ajq0jodTo+qeq81WPEFcv1EzbuKiaouLmc4dqS7CcX0tjbk2M2Vg4gP1+bILhgAMDDSj/ZRUj7kqIK5VXtELc4lib7YjrHEkPYsTlOxS+CksBnAtxab6oOWFTFpp+rXbVbCzqartCrZjitzGmYvOZPQ9PoTririEh7idsY8RtGvqojvj/Y+/do2TJ6nrP785XvbNO1annOaf7vM+pB92ATQPdQtOAIIKOouCgF0dHbVFcXhV1XRcqowvWLLzjFdeo14vCODM6XhBQ7lUadHhIX0FgbrMa6arzfvY59T5Vp7Iyq/K954+IzNwRGZEZEbnj/fusVavyERkZVblzxy9++/v7/lb/1XGxpr4JxuCQg7bsfiL8fecnhEDcSjbJ7Sv5ZBoYPGzvPXrNiDdcU6za0tVtdPBzKE0RbQvnZrJIBsVWziZ6+68LMnTien03oOj7e5GmGDXIMQvEvW7qI7VYszVnBrZQE2jvbmkUiKcHgfHTzbuTTLEwbLPJ7AZlJ9uRoBOv7wvNfPhg8O1XvSzYpDFnm4BWF8SUjhlxsVhTL03RncwKG1pLQ81+OhdrruwWsXugZKlGB9LoGzQIxAcC3CZZ+Ptewq7iEdXGsH7rLnBbt0owNAkcVk925X3g8j+0nnOrFfTwTKstvZX/o1kGq2MgrnsN59alKfdvmz83MgvsrbbuO5SmBLaIzgEa+6/VHB7v1f5LrxGvHADL/7UVTA+MA9kjnfchjo2D+2i1VxUw08a63eb+/m1g5EjLIrGTNKWUV+axkRnlfmFLufgTT+4myYtAjzErgfjwNDDSkrI9yi6isp/E9oU+HB628b3bvNS6HeR520vE//8LX3ckx9q99jWMqbeLqZHg26+Kf/OdZzUJq8dSO3iEKeOkdnMFuG0SO1hlVyg4dus8GjEoEA8Ssoo1jbZp0KXFvV67ywyLNQP85RIC8bNf/w18qjE/7gL4Pwy2f/3/ong+/9EjSlv3Bm5dyQ9PARtL1t/DkWsKoBR5CoWaVqUp4rhhSaVde2Op8cXvAP75Q63nE84y4tpCzYAFSTZZ7NZh0y7iRdT+PeBPn2xduAFKNrybvECUpohjWkQMPlL9rTnETY34f/t94Au/A0w/BLzrGSCRMC/W3FsH/uhRxb/+Hf9Z+a78X9+rjLmf+0rrAtpgzhTtVwFgcTZgWTn9937UJBAXakp+Jf1J/Ao+Cfy1xPeNK+L/4XO/7mgXY8Lt1OBY8O1Xxb/5Sx8AvtS6+x1A6zy5A+PzpIz3JUwhaUqQ6FSsmcy0gq96RVts1U3XefiMuo++zq2xASzptZVjJ9o3Gj/Z+f38xOh4O/HlrFcQAAAgAElEQVT8p4Crn28PWMZPSTskDZNz9t7DiUZc/zrOje0LxWNp8OR7W7ff+AHgwVe27i++tXU7mVGCdAdo9LtBX9LtgvSCTTGIvvoFbRAOAA+8wsI+hM/eSJYCaF1TxEJwNwPxL/yO8nv928Dlz6nvZzB37d8DLn0GKO0qF5Df/mvg259Q5sfqAbAsdHk1mDOvbrTsV48eGsDooHN3H1cYOAQMqKHc6INKHwg9k+eAyfNy39etOS1sHD7dfRs7hOH/KvtvtkIiDYw+4P37hhDKiAeJThlxxpRsdkX1kq0eAEk1EDLTgzf4H/4Q+PqHgbnv7bo82eZmcf5nFDnC1mXlBH/2jcDRR6z+Rd7zxK8pwYQqsbiykW9KbU5ODOHwUEb5f61+S9m+st++evCynwQe+XF3ju87f1HJ+I0eA06+pvv2ptIUC4F4Q46iz4gnM8D89yn/Kz0vf0rxMu7LAi//GeDsG5TVmGMvA2ZfDPzEZ5Sx9PAPAyn70pT9chXXVT/kBFM04mHm/Ixi/8V5y/6rP92DQ4d4gaX/Xr/0x4DHft7CPoRA3FQLLsw16cHWqodXxZr5dfX9DI4vv6FkxBvsrWuPK7/Rum0wZwa2o2aDZBr4gT8Bnvsr4NGfVhIbb/49YOlvlb/n0IPKd3NwAti8hK0r38BN1YpxbDCN05MOrBjHTgCveo/cvyOsvPLdQH4TuNfePMkqVzb2sHtQxcX6Axh/+MckHpxLPPITwM4tYGPZ8OnL63vIFZXv0qmJIYwPOXfEAqCcY17yo8BwZ2tOQoEC8SDRqVgTUGQXjUC8ctDKSHY6ebIE8OBjwPHHLR1Cm7ZyOAt8/x9Zem0gGD8J/NBHmnf/6z9ewh9+8SoA4GfOnMJ73zyvBOl/oBa8VcvaYOXRp4C3/J57x5edBd76J9a3dypN0TuniBrxl/0U8D0fNH7d4Lhy4dZg4izw9j9v3T/xKuXHIZfW9prW5icnhjCQCZCtnAMa9l83tgqo1TmurOfx0LEelmOZSRD94h+x/j3U7MNECy7uW6w/8apYszFnGWrE7wO7L7Tu59e12+WFIN1gzgx0oWaD89+j/DR4+VPKj543/29Yu7uLt/3hPwMAjo8M4ss/9VqPDjKiDE8BP/DHPe3inf/r57FeVsbk548fk3FU7jIwBnzfH5g+/anPXsCHv3wdAPDz50/j177bYLWUcA2SpgSJThlxwNw5pVNGPDVg2bJq96CCOzvKfjPJBM5MBagJhkMMrZmSQmFNraS9kHFoyecaMqQp4NqMeLfXuoj2Qi8a+kFth80eG/uIKx1i1rrbCojpPqwE4sK84naxZvN9DhS5lDjnjcy2bq/9a+t2fkMbfIc9I26Ts9PDSKnOQrfu7WOv6LAJDSGFrXwJ6znlnDGQTobWflXElQ6bhGUoEA8SnTTigHmb+04ZcQst7RuI9mvnZoaRToZ/eGi6Hzbsv0RJRU2XEe+hSY0rmGbEuxXs6Zr6iJlDHwuLliNUqNlAqk7cLCOesPFd1DQFMgvEhcfFOcLLjLj+eyc2vNq42Lpd2gVygluPJiOuDcT19qtRGGN9qaQmKXJxTULTFcIxGvvV2ZHQ2q+K6M+ThLf0HGkxxn6CMca7/NSE7U902fZjvR5TaOmaETdo6sN554y4hU6aDZYi0O1Qz7GxAYz0Kf/L7UIZa7miNiOul6aEJSPeNUOql6YIGXE72VXJRHGMLch0TkmYBNF2PjPxIt5MI143CcS9yohXDrRBf7JPG4jrLyDE+6YZ8STu3j9o1oRk+1M4esh6IiLIaMbY3R5XXYieiOIcdnJiCP1pZe5Zz5Wwlfe4n0DMkaERfw7A75g892oArwPwWYPnvgXg0waPPy/hmMJJN424aCXYtBurwNAnuIGFTpoNotB2XE8iwTA/m8U3bm4DUP7G2fOC17NemhKajHg3jbjONUXUiHe1PnSHWp3j4lprjM1HZIyJzTwurOZQr3MknGbJzPTdduREtjXiwsW6ZxnxojboT2W6Ojo1KeUU3//MYFvyQi9LCbytnEUWZrP4G9wFQBlLv4ma9AkAkgmGuZksnntBKdpeXsnhiXNUaOkVPQfinPPnoATjbTDG/kW9+acGTz/HOf/tXt8/UjjJiIvZ8MywUpEvWvHZkKZEUb8LKJOlGIi/fn5adRWpt5qmNAhaRtwMW/aFdUDsyOeTRvzGVgHFipKZnxrpC34TDItMjvRhYjiDrXwZhXINt7f3ccKpbtRM3y1bIy6iyYh7FIh3y4h3o7ABZE60JS+0hZrRmsMaUCDuL6EoBnbAwhEhEF+lQNxLXEuNMcZeBOCVAO4C+Ixb7xMpbBVrqgG4vtBQfzLr0sCnQblax9WNlvZwbtaZR3QQ0RbTGRRslgTNZWQy4sLtNo24PxnxQHc77AHGmCa731OgZKoRtxOICx++FV9wcY5w00dcpKovks7YC8Qb8pQuGfGoIM5hl9fyqNQsNugipHJQruH6ptIsKgr2qyJUsOkfbp6R36X+/ijnhv21jzDG3sUYe6/6+2G7b8AYe9boB0A4vXecFGuKGfHUQPvyrsWM+JWNPVRqStb0wfFBZPsD1gSjBwyzSWLBptj0JDSBuB3XFARCIx7FQs0GmmKnXk5i4vdenA/sXDyZ7cOMtEcNfUSqB7pize7NxjQ0CjZ1c2bUCjUbHBrMNPXu5Vod1zZ7bENOOOLS+h7q6uLiqcnh0NuvitCqi3+44iPOGBsA8E4AdQAfMdnsDeqP+Lp/AvDjnPPbbhxX4LHiI96gKU3pkhG3WKwZpbbjehr2X9U6x617+8gVK8iaZcSDJk2RohGvB0IjrunaGiHZAKAv2OyhmE5KRtxCsaaIH/aFlWJvGfG9NeW3EIgXKkxjv+qo8U2AWTiSxd37yt+3dDcXqWxsWFiKUFdgPfMzWSQYUOfA9c08Dsq1SF1oBBm3zsg/DOAQgM9yzl/QPbcP4P0AHgEwpv68BsCXADwJ4AuMMUsCS875I0Y/AC52fXEQsSNNaWTCNRnxfoNA3FqxZhQLNRu02X+t7mkD7jBKU7ra2elcUzQXed4H4pzzyMoGABP5kxPMgmhbGnELxZoivtgXFnvMiDekKa1x/cJua39np4eRSYXfflVE2hgjHBPlOWwg0/JEr3NoCusJd3FrpvoZ9feH9U9wzjc45+/jnH+Tc35f/XkGwBsBfB3AGQA/7dJxBRvRosvQNUWUpphlxJ1JU6Kq322g9Xre1Qbckc+I6xr6+JAR39wr4V5BCZQGM0kcH7duqxkGpNl/afTdXaRqZiRCUKypD8SNVvM6YSBNuX2/dexRSyYAkv3qCUdEtVCzwQL5ifuC9DMyY2wBwOMA7gB42urrOOdVtGQsT8g+rlDQVSNuVKzZLSPePeDhnONChK/0AYNskmlGPCyBuF3XFH814kvCpD4/m3Vu7xdQGvZfDS44PYmZeYA7zYibNfQR0dgXuiRN4TqL1cpBu21o3zCQtug2Y1CseXO7dexxmMO4/n9KuEqtzpXVVJWo2K+KUMGmP7iRGutWpNmJTfV3+HvGOsGRRlwMxA0y4qnu0pQ7OwfYKykntLHBNGay1r3Hw0JbIYppRjxo0hSTgLWrfWGHhj4+2BdGWfrUQErG0iyIduwjbkUj7kFGvK47FVT2jTvaWpWnGGTEb2y35sIojrFjYwPI9ivnhd2DClZ2OzRyI6Rz814BBxVlHEfJflWECjb9QWogzhjrB/BjUIo0P+pgF69Uf1+XdlBhwpaPeMM1RZSmOMuIiwUoi0dGI9MEQ2RRKA68vJZHPSm4wlQKrduhyYjbkKaA+25fGGXHlAaLMjpsmvqIO2xxb0Wa4oV9oT4nUy60F2sCwMiMtf0ZaMRv7bT2Nx/BMcYYow6bPhJlQ4MG4gXsxdU91Oq06uIFss/Ib4dSfPm0QZEmAIAx9grGWFvakTH2OgC/rN79S8nHFQ7sBOJVI/vCPmB4xvw1JkS5AKXB6GBaY/91UDcxDEoGzLYxItKUqNcgAJKK6cz03a5qxIUVMNcy4jobxXKhvVgTMKhxGTK+nV9X5C7Cfkt1ZcxHzX5VRHQbooylt8ThPDk50ocpNdN/UKnhxlahyysIGcgOxBtFmkadNBv8LoC7jLFPMMY+pP58AcAXAPQB+C3O+VclH1c46KYRT1nIiA+MaV9jIbsd9QKUBuLkuVcxGfqBK9Y0+fy6Zkj10hQxI+7tike+VMXNe8qEnkwwnJuOTrMokTnV/gto2X/ZxkxW4tg1xaZ9oVsZcb00pZxvLzQH2lf0phdatw89CPSp3+F6RekgLMyZNSj/o7jMYaTh9Zaodm3VQ/IU75EWiDPG5gG8Ct2LNP8CijvKowCeAvBuAGcB/DWAJzjnH5B1TKHDlkbcJCOut6YT9c8mxOFKH9CeoHfNAvGwSFO6WRBqNOLcV434pbVcs1bv9OQQ+tPR9KbV239dWu/+3WtDoxF36JoiBu2WGvp4IE3RHwevA0VBWmGkER88DGSPtu4PT2mfz29o9ltVT2dxmcMoSPKWOJ4n6WLPG6Q19OGcX4C2sbbZdh+FM/14NMhvAh9/p3L7h/9vYETIANmRplx6GviPjwGzL2k9ZlSY2SUQ3ymUm0U/fakETk1Et05WnDx3zOqcAlesKamhj48a8TgUajZYODKKa5tK9n95JYeXPHDI3g78yIiLK20vfB3441cAMw8Bb/1TeZ7z3KAl+8G2cAwGGfHhGe39kRlljrx3Vbn/4Sc0f18cMuJnpoaRTjJUahx3dg6we1DB6EA0ZThBYmOv2LQkHYqg/aoIZcS9J1odD8LA078KvPA15eeL79c+1y0Q18tONpaBb/1V676RrGJyruPhiDZrczMjSCWjOyTEAptNs0A8LBnxrhpxfUZcKLrxWCOuLXKK7pIuoC/YdFBM57lGnLXPG5sXgW9/Arj1Fevv2Q2jzPzBTut2IyMuZsBHjyo/DbJHtc/XSgBa4zoPJRGxeDS6gXgmldBIuyhj6Q3iHBZF+1URcY6m8eUN0Y26gsryp1u3n/+b1m1d4ZFhIH7kpcD5t5jvu5ER/4nPAENTwPFXAS99Z8fDWYrJchsAHD3Usv8qVE0Cm6BlxM0Wmey6pvjY4j4OhZoNepYOmDme2HJNEZsCdQnEE0nzuoj7t62/Zzf0GnEA2DfIiJ98DXDqSWBoEnjlu4GH3wFMnAfGTgLf8WPAK94FjMxqdsPB8Knaq/ECn46s/aoIyVO8Jy6yFAA4Pj6IQbW1/Va+hI0c2WS6jTRpCuGAPqFoTbN0y4yXhBkDfuSvgJtfAf7PN7c/3ziZnXgV8CuXLC0rx6VQE2jZf33t+jbKMFnODUtGvKuPeAfXFA814tVaHRfXot0EQ2TewP4raSd7ptF3O/URN9mH4bYJrae+SMOrWwaGGXEhEG9875Ip4H/6L0C93pq/fv7r6rEyYPwU8MtLmtqY//fCJn7lPy8BUIKkKNqviiwcyQLPKrcpY+kNcTpPJhIM87NZPHtLWbFaWs1hKuIXt35DGXE/EQPxbtlwETOvXVEjblHbGacrfaBV7V42uwYNnGuKQ4243jXFJ4349a0CylXlImB2tB/jQ0FbcZCL3v6r4RZjGRkacbPunIbv1yEj3vDqloFRb7d9UZqiuzAW5y/GtFn+RBLIDDV/nl+Pdmt7PZQR956od57WQwWb3kKBuJ/0C19oMRDv5mXdb6KztRlEFis1XN3MA1DOc2KL7qjSmEQrRoE4S/jSdbIjUnzE/ZOmxKlQs0FPFnPi+HO6iqFfDen2fp5kxA2OY/9e63YPF8Bxkj4B2mZFVzf2mhe6hDsUSlXciIH9qggVbHoLBeJewnVdqpxmxE0DcXvLR1fW883OWScPD2GoL/pKpUYxnaE0JWiyFKBDIN5l+b1Ti3sPA3Ft19boB0lAjx02TX3jHUpTrGxrGohLzIh3laY4XymJUzEwAGT703hQde2o1DguO7HJJCxzUbBfPTM5HFn7VRFxDrtAGXHXoUDcS4r3dQ8IJ12Nh3iXL3oyre0y18BmIC4GSVFsCW3E6clhZJIJlLjBRUfgCjVhHpjZ1YjbGV8SiVu2Euix+6FZEO00I96NRKKDNGXN+n66YSRN0fdAcMB2oYxV1X41E3H7VRGSp3hH3OSbAHBueqRZ23LjXgGFkoV+BIRjKBD3En2GSTwR2cmIA8ZZcZsnszgVoDTIpBI4Oz0cgYy4DftC+GNfyDnXSVOin60EepSmOK4JELBb2JlIwdCdx+2MuIjD716c7FdFqMOmd8TxPNmfTuL0pHJRy7myKkC4RzxmraCg11xW9lu3pQTi9jLicbzSB5TJ1LBYM2iFmoBLLe69+dqv5YrY2VdcO0b6Ujg2NtDlFdGgzf5rz4b9l1kQbSu4tuPSklC2Nxr7pRxQ3m9/3AlG9oUiDlej4liDAFBG3EvifJ5sQBd77kKBuJfoM0yNNvWA5xnxep1rskmLcTqJHcmaZMSDKE0Jr33hcoyaYIg07L8a2DqJOV0BcbptYyyYZaQLkrLi3QJxhxnxOEqfAO3femElB66vPyKkoLdfjdXFHhVsegYF4l7SlhE3k6ZYOJH2mBG/vb2PQlk5OU4MZzA5EsBssEssHhlF2VAjHsD/gZQW9/DFvjCumSRAW+xk6yTmtUa88X5mGWlZ8hQjjbiIhIx4XIqBAcUKdGxQSSbslaq4s3PQ5RWEE25sFVBSXWmOjPZjLOL2qyKaWhfKiLsKBeJe0lGaIhbTuZ8R13bUHI18EwyRudmR8GfEbbW498c1JU5dW/WImTNbzilmAbdTH/Gu26pjwSwjLcvC0AWNuN5+9XwM7FcbNJqTNRAL7wl5xHoOE/7ei2t7qNbIJtMtKBD3kj19IC5bmmI9I7682pq447TcBij2X6PDBu4KoQrEu9kX6qUpPmTEY1jk1EAvHbCMqUuOnSy3zIy4rEC8mzTF/nfv8vpe0371xOEhDMfAflWENLzuE+c5bHwog9lRJaYoVeu4vmWzORlhGQrEvUR/UqsetNwsPNaIx1k2AACz4wZ/c1ikKY0CO8uv07mmeKARzxUruL2trPikEgxnp4ddf88g4dj+yyzz7bpG3GVpSreMuANpSlwLNRuQhtd94n6epIs9b6BA3Ev0JzVeb7Wg9lgjHucrfQA4MnGo/cEgZsSNbOUsZTz9bXF/cbVV4HRmahh9qeg3wRBpt/+y2HTFaXGulX0Yje/GtmaBsqyMeLcOnw6kKXEt1GxAGl534ZzrzpPxsF8VoYs9b6BA3EuMTmoNeYqHGvGtfAnruRIAYCCdxMmYNMEQeWDSIBAPTUbcQlDW1uJe1Ii7HxQvC5rVOAZJgEOLOSkacTuBuLrfA32zMRVpGXH5xZpxz4ifmhxCJqV81iu7RewUyj4fUbRYz5Wwrf5P42S/KkIZcW+gQNwrahVg/177481A3DuNuPiFmpttLaHHiZMzY+0PBjEjbiRBsZLR9lkjHre240aIf/ey1WI6KRlxk22TBgXKjf22df1V2ZPUXVNysWab/WoML/bSyQTmZkaa9yljKRd95+m42K+KiHPY0sou2WS6BAXiXlHYguIjp6PhnOKhRjzushQAODw60v5gWDLiVoIyvWuKxy3uaYw57H4oRSNuFswbBOJdpSle2Rfa++7dirH9qghlLN0j7isuAHBsbAAjahH0zn4FazkbzckIy1Ag7hVmWstGm/teNeKJtOUAK+4FKADAjFYPApkRNynW7Po6fYv7uslz8ilX67iynm/ej+tJTGzqY9n+yzSIltDi3mh8G23bJ3xe+XVtoa9TumbE7X339M2i4mS/KkIaXveIew0C0GNzMsIy8fJ7cpPcCvD1DwNr31aC5Lf/OfDtTwLL/0UJggpbxq+TJU2hQk17GJ34w5IR71ma4m5G/NpmHmU16Dx6aACjgwaZ2BjQsP9a3S2iVK3jxlYBZ6cNVmJEzAJuGRlxI2mK0X5HZpXgu7wH1CvAwQ6wfR34xp8B5TzQfwh47N3A9CLwrY8BF/9e2f7waeA7f0n5Hn3lfwfWn1f2d+pJ4xU8EZvfPY39akyDJIAy4m5C50mFhSNZfOPmNgBljL1+ftrnI4oeFIjLolYBvvIHyu2BMWDrKvA3T3V3C2hKU+wWa+qKDS2eyA7KNVxXm2AkGDAXoyYYGowC8bBkxC2tfOgb+nhnX0grLi0WZrNY3VVWvZZXc90DcVc14h1cU0QmziqJgW3V6SW/AXzqp4Cdm61tti4Bb/0w8Lfv0r421Q8MTQJf/mDrsYt/D7zsJzsfcw8Z8TgHSXOzWTCmfL2vbuZRrNTQn46XQ5Eb7BUruHUvvvarIo6KzglbkDRFFoceBPrUrM/BDvD8p7oH4UCrzb3tjLju5GPxRHZpfQ9qDwycmhzGQCamk7bRhUsgA3EZxZrw1L5wKaZtx41Y1HQ/tHASc1Mj3kma8kMfVbfpA970QSAjOClVCtogHADuXVOy5HruXVN+9GxeNj/ec2+yLZeiYmCF4b4UThxWPqtanePyukWbTKIjFwT71bPTI7GzXxUh+ZP7UEZcFowBMw8Bt/5Zuf/c/9N67uF3APPfq9yeOAd88f3Ahb9T7hsWa1r40uuXmbtpMFXESvA4Z5KMgpKDegqBM6iSYl+ob3HvckY8xl1b9dgu2JSRETe1L+wgTXnobYrUZPAwMDylTQZUS+2vq1eVVcC2xyvKj56qUOT1kn8DvPhHFKeWzDBw4tXmf4sBm3slbOwpx9SfTsTSflVkYTaLG2rXw+WVHB4+ZmDNSthimc6TTc5ODyOVYKjWOW7d20euWEG2P55yQ7egjLhMZh5q3b5/q3V78QeA+e9TfibPA+nB1nNONeJ6jE6WBpBsQMUgI75xEEBrJhnFmh7aF3LOaYwJaJqurOa623/J8BG3oxEXg/apeSUIB3SBuIFTQs0k4K6ZBOjiPpJp4OSrlfnw9GuBpL35TrQtnJvJxtJ+VYQylvKhQs0Wfakkzky1pDliszZCDhSIy0QMxDWPP6y9LxZWVh029NFjdLI0gApQVBIp6LtWruYtSIm8xrF9ob7FvfC3uagRv3v/ALmiclGZ7U/h6KHArTF4imj/tV0oNxtpmSLDNcWWRtxk264Z8UqHjLjB6pw4PzmZ3wQoSNJCBZvyofOkFu3KnsWeCIRlKBCXiVEgPjAOZI9oH3MjI17rnhGv1bnmajbWJzHG2rLid/eCGIgbacQtZAD10hSNRty9DKI+Gx5XW7kGbfZfq11OYmaBuGsZcbNAXHjc6CK/XjUOuGtmgbgwP/UojaJCTS3iPH5hNYd6PYAreyGiUqvj8hrZr4pQwaa7UCAuk8m59qYZMw+1Bz5pIUvoVCMOGDfo6MDNewUcVJSAbDrbh4nhANr1eYmum9/tnDWdvac41Yh3ck1xUSNORXTtiIHS0t0uJzErgXE37PiIO82IA60kgoiZdlzctscVGbHOJe7FwAAwNdKHiWHlsy2Ua7i1ve/zEYWbqxst+9VjY/G1XxXRdAmmQFw6FIjLJJUBpua0jxllyTWBuEPXFMCWdzigDZLoKh/K5yVwd6+OYqVLB0CvkaIR555pxGlJtx1bGl6vM+KmUpguGnGzx+tVk2JNIZjvIRDfL1dxXS1MjLX9qgBj1HRFJrTi0o74f7i8lkfFSnMywjIUiMtGrweffXH7NppAvAeNuN0mGFREp0WXISzVkwG0/zKQdtjViOtdU1zUiNMYa8fWsq5phtolH3HTDLzDjHitohRs6hGD9h5WZC6t7TUXd05ODMXXflWH9mKPNLy9QDUI7YwOppv1PuVaHVc38l1eQdiBAnHZ6DPgXTPiRtIUdzLi2mwlyQb0gUkZ6eBlk2S5pnjgI767X8Hd+0pwlkkmcHoyvk0wRBr2XwBw694+9ooGGeMGMjLiZoWdRlI2K3aJZhlxQ2mKiZuK+FgPxZraIInmsAZUsCkPyogbY9uKlbAMBeKyEQPvZB9w+Gz7NikhEK/2IE0ZGLN1aJSt1KFbUSghFTz9mwwfceilKe5kEcX/3dnpYWRSNL0ABvZfax1WXUwz1HZcU2QUa1rJiBtokWsmRZxW3tMCFCQZs0gWhlLgnFNG3AQq2HQPOlPK5shLgeFp5fa5Nxp75Moq1vz+P2zd/oH/1HHTjb0itvLKCXUok8Tx8cGO28eCSGfERWmKzr7QpYy4ODlTEZ0WTbFTpzEmRSMuu1jTZkbcSJpitm+b0Bgz5uTEMPrTythZz5Wacz1hj5XdInYPlNWb0YF07O1XRSgj7h7UWVM2mSHgJ/8BeOEbwPk3GW8jq1jzyEuBn/q80qHu9Os7bioWas7PZpGIeRMMAG0Z8TJPNe2/AvP/MfQRtxJI66UpokbcnUCcuraas3Aki099U7m91MmHV0ZnTSct7tse70EjbiRNsXJ8XdDbr87TGGuSTDDMzWTx3Av3ASiB0hPnJn0+qvCxdFc7h8XdflVEvPBdWtkF55z+P5KgjLgbjJ8EXvw/Av0mGkbDjLjDhj4PPAqcfUPX4IpkKQbo7AvLSAfP/ktKi3t9RtwlacoK6XfNsLysK0UjbpYRl+2aYpQRrxnbF5rt2wY3tlr2q1MjfZgcibn9qg7qsNk7JEsx5+ihAWT7le9urlht1gMRvUOBuB+40dCnC2QrZ0CqXZoCBGzZzbChj11pivst7kvVmqaSfm52RPp7hBnL9l8yfMTtZMStuLSYSlOM7AstZMQdasQpSOoMFWz2DtUgmMMYI3mKS/R8RmaM/QRjjHf5aTNnZow9zhh7mjG2zRjbZ4z9K2PslxhzsdtIUNC0uDeSpsj/F1ygjHg7bRlx5QIoUPZfRoG4JftCfUMfd+0Lr6znUVU7+j04PohsPzXBENHbf13bNLH/8ryzppWMuJ1izYp2dc/w+BwG4hQkdYQy4r1DF3udEd3WaIzJQ0bq9TkAv2Py3KsBvA7AZ396hIUAACAASURBVMUHGWPfD+BTAIoAPg5gG8D3AfgQgO8E8HYJxxVcNBnxHuwLLVIoVXHjntIEI5lgODdN2UoAbYFJMxAP0pW+jGJNcNftC6mIrjuLR7LN5dzllZxxMxrTDLVLrimuFGu6I03RjjGSPumZn8kiwYA6B65v5nFQrpHPug12Dyq4s9OyXxWdjggFyoi7Q88RH+f8OSjBeBuMsX9Rb/6p8FgWwJ8BqAF4knP+39XHfwvAFwG8jTH2Ds75x3o9tsAiq6GPRS6u5ZpNMM5MDqM/TZMzAINiTSVQWQrSBONYI94hI+7CohNlK7uzcCSLf1xeB6CMsR/8DoONDItzbc4HdlrcSy/WNOmsqdm3/QtBzjmWxWJguthrYyCTxMmJIVzbLKDOlXn/pQ/as7iNM+Icdm5mGOkkKXf1aAs2A3SeDDmujTTG2IsAvBLAXQCfEZ56G4BJAB9rBOEAwDkvAvhN9e7PuXVcgcAwEHcvI06FmibopCmJtBKobOyVsLkXEPsvw0DcSqW6PhB3OSNOY6wrljS8RoGx3QsnzzTiBtIUl+wLN/dK2MqXAQCDZL9qilgkTdIBe1AdVXdOTw4jo16g3L1/gN39LhfdhCXcvOR7l/r7o5yLUQBep/7+nMFrngGwD+Bxxlh0S+K7BuJyM5Y0wZigK9Y8MT3evH0hKCcxwwypgxb3mtfL/drX69QEwwp6DS9vLFOJOK0J0OxDtmuKyUWpUYBet5ARd7AisySML7JfNYcKNp1Dq3rdyaQSODvdkuzQxZ4cXAnEGWMDAN4JoA7gI7qnz6u/L+tfxzmvArgBRTJzysL7PGv0A2Cupz/AbcRizVpJkaVQRtx7dBnxM0cON28HZoKRoREXM5QuZMPv7BwgX1LeY2wwjZlsf5dXxBPR/mv3oIKVXYNA1ihIdTMjbkmaYkMjzutArdz5+BzMbxQkWYMKNp2jTSZQDYIZ1GFTPm5lxH8YwCEAn+Wcv6B7rjHCzawpGo8fcuPAAgFj7W3uXdKIV2t1TUttOokJaDLiDHOzLT1lcLJJRvaFNjXi4kWeG/rwVa12l5o8GGPJ/ssoMLa7gmEaXEvOiBsF4oCxraFm3/bHIK24WEOc3y+u7qFWN1h1IdooV+u4uiE2iyJDAzOoYFM+bgXiP6P+/rCD1zbO4l1nEM75I0Y/AC46eF9v0ctTXMqI39gqoFRVpAlHRvsxNmSQFYsrYkY81YfFo60sSMfuh14iIyNedzcjLhbtkJtFZ8T/j+EYc1qc220fgIl9YQ8acaOGPp0e7/aeHVheIVceK0yO9GFKbXR0UKnhxlbB5yMKB5fX91CpKSHH8cODGCH7VVMWqQ5BOtLPyoyxBQCPA7gD4GmDTRpnH7Mzdla3XTTRd9d0KRBfIlmKOWJGPNmHOdX+CwCubxWwX+5SdOYFMjTiombXBQ9xkg1Yp6uG1yjotq0Rl1GsaSEj7hSbFxb5UhU3yX7VMiRPsQ/VUVlHbNZ2ZX0PpWqXvgFEV9zIiJsVaTa4pP4+p3+CMZYCcBJAFcB1F44tOGgC8aJrxZo0wXRAkxHPNO2/AKUr/CVB0uMbTjtripIWDz3E6WKvM12DJBkZcen2hV2kJnaxOb9dEuxXT08Okf1qF6hg0z6UTLBOtj+NB1XXomqd48q6SXMywjJSz8qMsX4APwalSPOjJpt9Uf39JoPnngAwCOCrnPOA+Me5hD4jXnMnI06Fmh0QAxP1duDsvxhDm068J2mK3CBmu1DGqlp0mEklcEq9kCGMEe2/7uwcYPdA5zBiqBF3UZrSi0bcKTbnNwqS7EEZcftQMsEeVLApF9npsbcDGAPwtEGRZoNPAtgC8A7G2MsaD6pB/AfUu38i+biCR8p9jTjnOlu5WdLvakgZBOJBzCbpgyXb0hRxbMn9yos2j3MzI0hRE4yO6O2/2mwyDVdAZNkXOvQRNyvKdIrNv4eCJHsEcg4LMJxzXKCElS2oYFMuss+ajSLNPzXbgHOeA/AUgCSAf2KMfYQx9u+hdOd8DEqg/nHJxxU8xIx41Z1AfD1XwnZBsRIb6UvhgfGBLq+IGbpiTSCgncP0gbiljLiZa4rcr7xYcEhFdNboOMYMNeI2PzNbxZoWMuLd6+btYTPDT8XA9jhxeAiDamv7rXwJGznJ0qKI8cL2AfZU+9XxoQzZr1pgkVZdpCLtrMwYmwfwKpgXaTbhnH8awGugNPD5IQC/AKAC4D0A3sENO11EjI6uKXLkA2KQNE+2cu2ILe7VbOG8aP+1lguG/Zf+c7NtXyhqxCU3iyLZgG06Zixd1YgbSVMsaMRlY2N+09uvztMY60oiwTT/pyUKlDqisV+dpfOkFcSM+IWVHOpBOE+GGGmBOOf8Aueccc4fMCnS1G//Fc75mznnY5zzAc75Q5zzD1l5bSQQA/G7zwL791r3JZ0EKUjqgrhUrwblov1XsVIPhv2Xo4y42NCnYvy4BEg2YJ+OdQiuasRtFGsaBe2ysDG/Xd8qoKzar86O9mOc7FctQfIU61AdlX1msv0YG1TmiL1SFXd2JMvXYgYJOv0iPdi6/d/+A7D+fOu+rECcgqTOaDLirduBK3ZyohGHiTRFoiNPsVLDtU3lQoUx4PwMjTEriPZfVzf2moEmAEk+4gYFvoBJQx9JGXGjIN/osU7vaQAlE5wRuDkswJCzmH3ampOtRttt2m0oEPeL8ZMmTzBg9JiUt6AJpgtjJwxvBy6b1JYRt7B06kFDn8vrrc59Jw4PYbjPRTlDhBDtvyo1jitCRz8pPuKAwefMjPdj6ppi8z1TBvUnRo8BtoJ8SiY4Q5zDLgRhDgswlBF3RuDOkyGGzpx+8ehPA4V7wOaF1mMsCbzoB4FDD/a8+71iBbfu7QMAUgmmcWogVCbPA2/5fWD1W8ATv9p8OHCdw9oCcbuuKe74iNMJzDmLR7K4va18P5dXcq0x57STqp5EEqjVtPftyF7sZsTTA0Bpt/tjgK3iU+qo6YzzMyNIJhhqdY4b9woolKoYogvlNnYKZayo9qt9ZL9qC1p1kQd9M/1iYAz4ng+6tvsLq60s29npEfSlqAmGIY/+VNtDWmumXXDO/S3gaSvWDIZryhLJBhyzMJvFZ59fA6D8H9/eeMIoSJWREWdJ4ws4Kz7iIql+4wY/aQOnCaPHGsdiAc65puCc7Fet059O4vTkEC6v58G5Unj+yPFxvw8rcCyT/apjxIRVYBzGQgqNuoiyvKKtBCesc3x8ULD/KmNzz+feUlJ9xF3q2krZSluYZpNkaMSNXpNIGu/bbkY8ZRJcizUvzW17k6as5YrY2VcKjUf6Ujg2RvardiDpQHdoVc85pyaGkEkpc8rqbrFplUzYhwLxiEJBknOCZ//Va2dN+a4p9TrXNKNZpIs9W+jtv5qOrbI04vrXMBNpipWGPiJpk2DY6PFUxl7wr0MMkuZns0gkyFbODiQd6A7VUTknlUxgbqZVeN7WnIywDAXiEYUmmN4IVDbJiUYc7vqI39rex35Z2e/EcAaTI31dXkGImNp/2QmWO6GXMyUS9oJ8GRnxRNrYqcViRpyylb0hSnl8n8MCCo2x3gjUeTLEUCAeQSq1Oi6v5Zv3KRC3T6A6h/XqI+6CRlx7AhulJhg2YYwZayx7yCBr38BqRtymRtwsI24UoCfTJk2ErI1BWtXrDfF/dnFtD9VavcPW8aNYqeHqpnKeZAyYI/tV29CqixwoEI8gVzfyKKuT7rGxAYwOuticI6JoCzYDFohbcZ0QA2OxoY/ddukmLFENQs/oi4IB2Cuo7IRRXYEd/blpRtxk5cMoQE+kTJxarGXEqRi4N8aHMpgdVS6QStU6rgehOVmAEO1XTx4eIlcZB4gJK/GcQNiDAvEIQk0weufctGL/BQA37xWQL1W7vMJFHNkXmrmmyJGmULaydzTLuquSM+JWNeJmF2Zm72lWgGmWETeUpnT/e3LFStPekexXnUPSAXM0NQg0hzni/Ey2eaq5tllAsRKPxuiyoUA8glCQ1DsN+y8A4By4tObjSaxnaYp8H3G62Osdw1UXo8DYkUbcpYy4kSVhImUsQen0eBcuCvarZ6aGyX7VISQdMIfqqHpnuC+FE4eV82StznF5fa/LKwgjKBCPIBQkySEw2aSA2Rdu7pWwoVo69qcTOElNMBwh2n+t7BaxUyi7qxGXUqxpJEFJG29vVqxp4cJCY79KyQTHBGYOCyBUqCkHGmO9Q4F4xOCcU0ZcEoHJJunrIC1ltd1r6HNB0wQj25TwEPYwtP8y1IjLyIgnbNoX2siImxVlJlPKT9u+LQTilK2Ugn4Oa9pkxhyyX5VHYM6TIYYC8YixslvE7oFSnDc6kMbRQ9QEwymB6RzWc4t7uRrxJWo7Lg1tsVPOJCPupMW9xc6aMuwLE0kTLbhZprz7GNSOMeqo6ZQHxgYxohYhbhfKWMsZdEWNIbe291Fo2q/2YSprYstJdCVQxgYhhQLxiLF0V+tmQbZyzhGb+vhq/xUw+0JacZFHW8GmNB9xAzmTof7cbrGmUSCeNs58mxVrdvl7ytU6rqyT/aoM9M3JKFBSIFmKPMTVhAurOdTrtOpiFwrEIwYFSfIQ7b/Kftp/9WpfqNGISwjEybpQGm3ZJDc14oaPS/ARN3VHMZOmdC7WvLbZsl89eojsV3uFMpbtLK/SHCaLyZE+TAxnAACFcg23VLcjwjoUiEcMKtSUSyAKUQKUEd8vV5sXJAlqgtEzov3X1c08ikbuX7Iy4p0e12NLmpIykaCkHNkXUrZSLoY2mTGHxpg8GKNVl16hQDxiUEZcLoEoRAmQRvzS2h4a9V4nJ4YwkCFbuV7Q239dWTdYdZHiI54wedzNYk2zzppdAnEq1JRKIOawgEFjTC7aMUaNfexCgXiE2D2o4M7OAQAgk0zgzBQ1weiVYHQO0+n87Wa1JfqIUxGdfMST2NKqgTzFUUZc95qEiTTFNCNuo6FPR/tC/eOsqzxK/J5RMXDvnJ0eRkp1Nrp1bx+5YqXLK6LNVr6E9ZxivzqQTpL9qgTEcwFlxO1DgXiEEL8A52aGkU7Sx9srC7PaCcYX+69efcQ1Le57y2DTiot82qQDTmoC9OiLtBsBeK8ZcaMW92aNe5IGkpUu+nDOOckGJNOXSmqSMmKzpDgijq+52RGyX5WAOIf56jAWUihSixC03CafY2MDTfuvnf2KP/ZfAdKIUw2CfNoLNi0Gy53QB9xmGnEpxZpmWnADaUqXC8G79w+QKyrjNdufIvtVSWjHWLylA3SelM/JiSH0p5W5ZGOvhE214RthDQrEIwQFSfIJhP1XW3azB9eUHgLxWp3j4lrr75+nMSYFvf0Xd7ICosdM3tIWoNsMxM3sC42O0ahYs0tGXJ8NJ/tVOVDBZgtacZFPMsE0hfsXYj7G7EKBeITQygZIvysL3+2/em5xL2jEe5Cm3NgqoFhRbOWmRvowOWIgUyBso7f/agvEpWrELe7b7HEz+0KrnTVtFWrSHCYLKthsQRlxd6Ax5hwKxCNCuVrH1Y2W9m9+dqTD1oQdfJ9gepamVIwft4n4t1MRnTwYY5oL55p+WpaSEVfvWy7WTBiPFVP7QrPOmvqMeOfxt0xdW11hUbioubyWR8Wv5mQ+c1Cu4fqm0iyK7FflEgir35BCgXhEuLy+h0pNKSQ8fngQI/3UBEMWvheiOMqQmklTnGfERTcLWtKVizjGqvUeXXIAc4241WJNwFhGYhaIm9kX2izWXCLZgCuMDqabevtyrY6rG/kur4gmF9dyaDR+PDU5TParEgmGw1g4oUA8ItBym3uI9l+3t32w/3KkEZdfrKmtQSDZgEzEoLPKdZ+3TI241Yw4YBw0m/mIm9kX2pCm7O5XcPd+y3719CTZr8rEd4ldAKDzpHvMzWTRMKC5vlXAfrna+QVEEwrEIwIVarqH7/ZfvWrE7b7WALKVcxfxO1vRqwZkdtbUS0M6XZgZZsSNfMQ72RdaL9YUg6Sz08PIpOj0JBMq2KRCTTcZyLQ82TlXmr8R1qCZLiKQv7O7+Gr/5UgjbuI24TAjvrlXwr1CGQAwlEni+Pigo/0QxpycGMJAWgmWK65mxO0E4gbvaysjbhCgd9CIU7bSXSgjTmPMbcRal7he7DmBAvEIwDnHBbrSd5VFPyeYXos17b7WgCXhb56fzSJBTTCkkkwwzKkF1nX9tCzFR9xmsSZgQyNuUJRp9ninjDgVarrKoq7o3JfmZD5Sq3PNaiadJ+VDBZvOoEA8ArywfYC9kqLHGh/KYCZrcLIkesLXgs0AZMRpSdd9GmPMHdcUScWayYyB7MXAphBQM+XW309bDEw1CLI5emgA2X7lc9o9aOnx48KNrQIOKoqV63S2DxPDZL8qG23BJgXiVqFAPAIsrwonsFlqguEGYiB+ZT2PctVD+y/952kpMDMZAw414lSD4D6NCxyul6Y4uXgy9RHvMSOeSLZnuU07axpJU4wz4qVqTePkMUf2q9JRbDLjm7EkWYr7iE3eLq7lUKvHa9XFKRSIRwDKVrqP3v7r2qaH9l8BkKZQDYL7eJMRtyF7MeuW2RZcmzX0MZKmGL/flfU8qupJ+8HxQWTJftUVRLejuGl46TzpPpMjfZhSG70VK3Xc2Cr4fEThgALxCEBX+t7gXzZJnyHtwTXFgd44X6ri5j1lQk0mGM5NU7bSDRr2X3Unn7cefcBtlhG365qSSLU/bsu+0Pj9aA7zBsqIK5D9qnv43gAvhFAgHgHoSt8bfLP/8lkjfmkth0Zd1+nJIfSnqQmGGzTsv9qKNR1lxC22uLctTTGRm1iVsZhIU2gO84Y4WxjSGPMGKti0DwXiIWenUMbKbhEA0JdK4JTq40nIx7fOYT77iC9p3Cwok+Qmi0dG5WTELRdr2syIMyONeAdpSlvQbvy3kGOKN5yZGkYmqXzmd3YOsLvvcXMyn9jIFbGVLwEg+1W3Ec8R1GHTGhSIhxwxqzE3M4JUkj5St9Av63pm/+WzRpwKNb1j4UhWjkbcrMW9rWJNg6A9kTBuW29qX9i9xX29zqkGwSMyqQTOTreak8UlK072q97h23kyxEiN2hhjr2aMfYoxtsoYK6m//5Ex9mZhmxOMMd7h52Myjynq0HKbd4j2X7li1Tv7LyeBuJlripNAnIIkz1iYzYK3+Yg7cU1xwb6wcV+v+zbSggPG2nGD97uzc4C8ar86Npgm+1WXiaM8hc6T3nF8fBCDGeV7fq9QxuZeyecjCj7m3RVswhj7TQDvB7AF4O8BrAKYAPBSAE8CeFr3km8B+LTBrp6XdUxxgIqcvKNh//W169sAlMn92JgHS5w+SlOqtTouCq2K52mMucr8bBZr+ouooGjEG/d7si9sfz+N/eoRsl91m4UjWeBZ5XZcNLx0nvSORIJhfjaLZ2/tAFBWI6bo4rojUgJxxtjboQThnwfwg5zzPd3zRl5Uz3HOf1vG+8cZutL3loXZ0VYgvprDGxdn3H9TfWDioTTl+lah6Zk+O9qP8aGMrdcT9pgc6cNGMgWIq7lB0Yg3M+IG9oWmDisWAnGSPnlKHDPi1HnaWxaEQHx5JYfXnp/y+YiCTc/SFMZYAsDvAtgH8KP6IBwAOOfxqAjxmGKlhquqnzVjiv0Z4S6+dA5rC8StZMTNHrcX1InFNlRE5w39aX0ALMO+sNHivgcf8cZ9I/tCy8Wa7QE7FQN7y7zwPb6yvodStebj0bhPoVTFDbJf9ZRFsjC0hYyM+OMATgL4JIAdxthbALwIQBHANzjn/2LyuiOMsXcBOAzgHoB/4Zz/q4TjiQ2X1/eanatOHh7CUJ80pRFhgi8+vD4Wa1K20nv6+zJAWXhAZka8TbJiJyOeNnnczL4wZUmTTjUI3pLtT+PB8UHc3t5Htc5xZT2PFx2N7gXQRcF+9czkMNmvekCc/eqdICNye1T9vQ7gmwAeEp9kjD0D4G2c803d696g/ojb/hOAH+ec37byxoyxZ02emrPy+rAjDvB5OoF5wulJxf6rXKvj7n3F/mt00OUugFI14jYDcQqSPGcgY83yryNmGnFxX90CfMvSFAMteGO7LtKU7UIZq6r9aobsVz1jYTaL29v7AJTveJQDcZJves+56REkEwy1OsfNewXkS1UMU6LQFBmuKQ3xz88CGADwXQBGoGTF/wHAEwA+IWy/D0VP/giAMfXnNQC+BKWo8wuMMZqNLUAFKN7ji/1XW3bTSjFb764pnHNdRjy6J+sgMdCn0+HLdE0Rg+9uAb5psaZRZ00T+8IuxZoXyH7VF+KUsaTzpPf0p5M4PamEcZwrTeEIc2TMeo2ZlUHJfH+Bc57nnC8BeCuAOwBewxh7DAA45xuc8/dxzr/JOb+v/jwD4I0Avg7gDICftvLGnPNHjH4AXJTwdwUeutL3B8+Lnezoes1eY+e1Kmu5InbUhh8jfSkcGxuw/FrCOf0ZbaC7W6rb34mpvlsYF10z4ib7MCzWNNiXBftCkj75Q5wKNuk86Q/UYdM6MgLxHfX3dc75t8QnOOcHULLiAPDyTjvhnFcBfES9+4SE44o09TrXZJMW6STmGZ532PRJI750Vyt9oiYY3sB0Qe3t+w58eK1kxLuNBbP29Eb2hYwZZNCTXYs1qRjYHxaPtv7XF1ZyqNej2XRFb79KF3vesUAFm5aREYhfUn/fN3m+EahbSac1dOQkTenCre19FMpKtfvEcB/5dHrIguDs4M2VvgNfaTP5ig29MS3p+oQuQL69LSEQN3JNkSVNMQvQDTtr6jLiVIPgCzPZfoyptS17pSru7HjUnMxjrm8VUFLtV4+M9mOM7Fc9Q9vqngLxTsgIxJ8BUAVwljFmNMpfpP6+aWFfr1R/X5dwXJGGltv8Y262ZX91dSPvvv2XT9IUGmM+ofuMbu0U7e/DzK0kYScjbqOzJtCe/e5SrFms1HBtU7GVYww4T/arntFoTtZAbKoUJWgO8w+x+dvFtT1Uaw4kdjGh50Ccc74F4OMARgG8T3yOMfYGAN8NYBfA59THXmEUsDPGXgfgl9W7f9nrcUUdTTc6ylZ6SsP+C0DT/stVfJKmUEbcJ3Sf0c1tB4G4mdOOrWJNM525QcANGNsd6oN24f1F+9UTh4fIVcFj4qDhpTnMP8aHMpgdVVbqy9U6rm8VfD6i4CJr5nsPgFcA+A3G2BMAvgHgOJRizRqApzjnDenK7wJYVK0K76iPPQzgdert3+Kcf1XScUUWutL3F0/tv/QyE0vyEjNpirVAPFesNP++VIJpnGIIl9F9viu5Mgqlqr0+AfqVD8OMuET7Qv3jLKGMNTOdOahQ02/ioOGl86S/LMxmm/akyys5aqZkghSvKM75BpRA/EMAHgDwb6EE1p8B8GrOuWhf+BdQ3FEeBfAUgHcDOAvgrwE8wTn/gIxjijp0pe8vi17afzmxL+wxI35xtVXgdHZ6BH0paoLhGbrPqIaEpuDMyT5aGXEXNOLNjLgQdJvJVYT3JH24vyx6XuviLZxzzRijrq3eE4eLPRlIWwvknG9DyYy/p8t2HwXwUVnvG0e28iWs55QCroF0EiepCYbneOrD60gjbuYjbi2gFt0s6ELPY/SBOE9geWUXjxwfs76PNo14ov1xxxpxg6JM/b7NgnZh/C1RttJXTk0MIZNKoFytY2W3iJ1COVLFjGu5IrYLSotasl/1B88dxkIKdU8IIWLgNzerdLAivEV/pe+q/ZcjjXhvDX1oSddHDDLitrNJVjLiTn3ErQToSTOHFWUfZL/qP6lkAnMzLalA1DKW+s7TzFIjNEImYhO45ZUcOI+mTWavUCAeQkiW4j+i/VfebfsvJxpx0xb31jLiNMZ8RPcZ1ZGwv+piqbOmw4y4kY+4/vEu0pRb2/vYb9qvZjA50tf5WAhXiHLBJtUg+M+xsQGMqLUtO/sVrOUcFJ7HAArEQwhlK/3HU/svj11TytW6xgmGTmIeo8tUNzTituy/zDLiUoo1zewLhceNdOPCPjTZylnKVvpFlDW8VIPgP4kE09gYRu1iTxYUiIcQylYGA8+ySU404mauKRZee20zj7Ia9B09NIDRwXSXVxBSaZOmJFGq1nHDjv2XmY+4LftCqxnxTsWaxhpxjf0qBUm+EemMOJ0nA4Gn9VQhhQLxkHFQruH6ppKtTDBgjppg+IZnncOkZsS7Zx7Fv4XajvtAoj0jDtgcY6YZcTsacZOumGb2heL2Zp7j6jbaMUZuFn4xN5ttTglXN/MoVlxuTuYRuWIFt+4p9qvpJCPbPB9Z0BRsUiBuBAXiIePiWg6NusBTk8MYyJCtnF94tqxr1q6842uct7gn6ZPP6D67RiBua4y1+Ygn2h+33dAn1flxTbGmWZMf9W8h/W4gGO5L4cRhxXWrVue4vG7TJjOgiParZ6ZGkElRqOMXmlWXiMmfZEGjM2TQcltwaNh/AcDqbssqSzr6oNpljTh1bfUZpi/WVD5/W8u6llxTuqyO2JamiBlxs2LNFDb3StjYU+xX+9MJsl/1mSjKU5bJfjUwnJ0eRkp1dru9vY9cseLzEQUPCsRDBmUrg4Pe/uuCW1f7jnzEzQLxzq/lnNMY8xsD+0JAuQi3bP9lphF3pbOmQdCdFLPnQsDPkprvydxMluxXfSaKBZtUqBkc+lJJnJlqdWYWVysIBQrEQwZlxIOFN9kkmS3uO7/27v0D5IpVAMDoQBpHD1ETDM/RfUYDGaXJynah3Gzk1RXTjHgvxZomuu9O9oWANkBPJClIChiRzIjTeTJQaAs2qbGPHgrEQ0StzjVXk3QS8x9POod52NBnSafdJVs5H9B9RienHIwxs1UUWxlxMy24DftC8Xl1H1QMHCzEz+CC283JPKBSq+PymmC/SmPMd8SC7KisusiEAvEQcWOrgAO1qn0624eJYWqC4TeeLOt6KE0hWUoA0H1GZ6a13eksYdYVUxwX0u0LU+3bAtoAnSVIvxswJkf6ApcgpAAAIABJREFUMDGsrLoUyjXc2t73+Yh64+pGy3712NgARgfIftVvxO85Oae0Q4F4iKDltuBxfqZl/3Vts+CO/ZfUjHjnDDeNsQCg+3zPzDjIJpmNGRkacSsBuklQXuIJXFf90Ml+NRgwFq2mK+TIEzzEz+HKeh7lqo3mZDGAAvEQQdnK4OGJ/Zcj+0JnLe5pjAUA3ed71lEgbiEjbts1xcBHnCVb+zGyLwQ0AfraXgWNetOTE0NkvxoQPOsS7AFUgxA8Rgdb9UblWh3XNvNdXhEvKBAPEdpsJTXBCAquFztpgieLX1kH9oW7+xXcvX8AAMgkE5pKd8JDdJ/Rqals0/7r1r197Fmx/zKTM0nxETfTghvYF+q2ubvbsvhcoEY+gSFKBZuUEQ8m1GHTHArEQwRlK4OJ653DmNb+zeKLTB42f/2SkAk7NzOMdJKmB1/QfUZ96TTOTos2mRZWXcw04rLtC83cUZLG0pQ7QiBOhZrBwbMuwS7DOdcUNC8epYu9oECNfcyhM21I2MgVsZVXrMuGMkkcHx/0+YiIBq4XbGoCcfcy4pRJCggG1oPajKUF6UBbEygZ9oUGWvCkSRbcJEC/vSNkxGmMBYaTE0PoTyvjbmOvhM09izaZAUNvv3pktN/nIyIaeOIwFlIoEA8JS0KANz+bRYKaYASGxVmX7b/sOF0YvUakw+upUDMgGDTjsX2xZ6YRF/Xnjos1k8bbmD7euv3C/VaAN09jLDAkE0xTOOtaczKX0ScTyH41OOilKZabk8UACsRDAslSgoto/7Xvhv2XI424fR9x7RijJV3fMAiibS/rmrmmyGjo04M0paiaCk2N9GFyhOxXg0QUOmxSoWZwOXpoANl+ZS7IFavNeiSCAvHQQNnK4OK6/RezkcU0eo2Fx0vVGq5utCrZ52dHDLcjPMCg0FL8zl9ey6NS62L/ZcVHvKtrilmxpnNpSg3KPilICh5RKNgkeV1wYYxRwaYJFIiHhAuUEQ802s5hkvVvdoIno9dYePzKeh5VVVJz/PAgRvqpCYZv6O0pE0mMDqZxbMyG/ZeUzpq9FGsab1NTTzlUqBk8FiOWEV88SmMsaIhub2EdY25AgXgIKJSquHFPaYKRTDCcm6ZsZdBw1TnFiUbcDJPXUyYpQGiCaNa8+NJ0p7vbZYyZ+ojLKNZ0bl/YCMTJfjV4zM1k0Sg9ur6Zx0HZheZkLrK7X8GdnZb96ulJsl8NGotuO4yFFArEQ8DFtVyzCcaZyWH0p6kJRtBwd1nXgX2hzRb3JH0KECbBsi0Nrz6r3tjn4dOtx8ZPddmHiUZ89AEgmVH3IexP3PdhYd/C+9zi0wBoVS+IDGSSODmhNCerc+W8EybE7wTZrwYTkqYYk+q+CeE3VKgZfBr2X8VKvWn/Ja0YzYOGPjTGAoRJTYCtiz0DC0QAwLFHgTf/HrB7B3jluzvvw0wjPnQYeNufAze+DLziZ1vPn38L8F2/DVSKwIt/pPX4k7+OffThN76WxC0+g0GyXw0sC0dGcW1TWX1dXs3hpQ+O+XxE1qFkQvA5PTmMTDKBcq2Ou/cPsLtfweggySApEA8BNMEEn4b913Mv3Aeg2H9NjkzK2bkj+0ITLbnB6+t1Tm4DQSJhLSPOOTe3Z9OvfDRdUxjw8qcsHoeJNAUA5r9X+RFJpoBX/XL7frJH8PXzv4a//er/p7yU7FcDy8JsFn/3rRUA4ctYkrwu+GRSCZydHm7KUpZXc3js9GGfj8p/aO0mBFC2Mhy4VuzkckOfOzsHyJeUJhjjQxnMZKkJhq+YZMSPHhrA6ICSPdo9qGBlt2htH4Cz2oJOgbhNxDmMCjWDS5gLNrWFmlSDEFSow2Y7FIgHnGqtjotrrZbWdKUfXFwr2HRZmiJ2OaMmGAFAswLSus0Y0xVsdnDnMWgKZBszjbgDKFsZDkQb1oure6jJbk7mEqVqDVfWW+fJuRkyNAgq1GGzHQrEA871rQJKVcUz+MhoP8aGMj4fEWGG7TbkVnESiMN6Qx+SpQSMDr7xlgs2pWTETTTiDqAxFg4mR/owpda2HFRquLFV8PmIrEH2q+FBbBYXNvmTW1AgHnBIlhIeNPZfWwXsl6tyduxyi3vKVgYME404YKNgs00j7p80JV+q4ibZr4aGMHbYpDqq8DAnNIu7upFHqRoum0w3oEA84NAEEx5E+y/OgUuCpKgnXNaIU7YyYAQmIy4nEL8k2K+enhwi+9WAE8YOm5RMCA/Z/jQeVF2TqnWOK+tdmpPFAArEAw5lxMOFZtlNVjbJUYt7a24a24UyVtWiv75UAqfUCwnCRzo03Tkzpdh/AUqR7e5BxXgfbT7iDqZ6SYE4BUnhIvQZcTpPBh4q2NRCgXiA4VxrKye2USeCiSudw1ws1hSDpLmZEaSoCYb/dLjwSicTODfT6hhomrF0JSPuLJO9tEJzWJhY1Gh4d8F5sAs263WOCzTGQsUiNfbRQGfdALOWK2K7UAYAjPSlcGxswOcjIrrhyrKuiYtG59dY8xFfXhUcUyiTFAw0GvH2z9tSNkmKRlxOsSZlK8PF8fFBDGaUz34rX8bmXsnnI+rMnZ0D7An2q9NZSY3UCNegDptaKBAPMOIAnT9CtnJhQGP/tZaTY//lyDUFMHRO0Y0hkg0EkC5SJEsXewHRiOvtV+dpjAWeRIJpPqelgEsHNMkEsl8NBXr5Uz0kNpluQYF4gKEgKXyI9l/FSl2O/ZcTjbj+dSavp2xlAOnikmOpDsEVH3H7gfj1rQLKqv3q7Gg/xsl+NRSEqWCT6qjCx0y2H2Nqa/t8qYo7Owc+H5G/UCAeYChICifSi53EDI+dzKZRIC68vlip4dpmofkWczM0xgKB+BkbBNDzGvuvvWagq0H/Op804pRMCCdhKtgkZ7HwwRjTjbF4N/ahQDzA0AQTTuR3DnNgXwgY68SF119aa3XOO3l4CEN9zhu2EBLpkhEf6U/j+GHF/qtS47i8bmCTqfnsmXnNQCckaMTF8U+t7cNDmIrptMXANMbCQphWXdxGaiDOGHs1Y+xTjLFVxlhJ/f2PjLE3G2z7OGPsacbYNmNsnzH2r4yxX2LMyRpq9MgVK7h1bx8AkE5SE4wwsTAruXOYS9IU8UJvnk5gwUH8jE0uvLoWbHZoCmT9OJjOStF+IE6reuHk3PQIkmp3spv3CsiXJDUnk4zefvUk2a+GBtHdRprDWEiRFogzxn4TwDMAngDwOQD/AcDfARgD8KRu2+8Xtv1bAH8MIAPgQwA+JuuYwszF1VaW68zUCDIpWrwIC/qK8J7tv5wWaxoG4q3HSDYQUCx0Uu2aTXJ68aZHDL5tBuKcc90YI1u5sNCfTuL0pNicLJiB0gXhQo/sV8NFmORPbiNlLZox9nYA7wfweQA/yDnf0z2fFm5nAfwZgBqAJznn/119/LcAfBHA2xhj7+CcxzogX17RVoIT4aFh/7VfruFeQbH/msr2O9+hE/tC5YXtDyWMM+KUrQwQXTTigIWTWIemQPaOJQXUSo72s5YrYmdfaThE9qvhY2E2i8tq18PllRweOT7u8xG1Q4Wa4eXUxBAyqQTK1TpWdxWr5rgWc/d8+cgYSwD4XQD7AH5UH4QDAOdcbP/2NgCTAD7WCMLVbYoAflO9+3O9HlfYoSApvEi3/5KaEVeC83qda7JJi3SxFxwsFOeKc8IFo1UXWRnxpJCrSabNtzNAY786m0UiQbZyYSIMGUuqowovqWQCczMtye2FgI4xL5CxjvM4gJMAngawwxh7C2Ps3zHGfpEx9pjB9q9Tf3/O4LlnoAT0jzPGurryM8aeNfoBMOfwbwkMNMGEG6nFTrI04sJrb23vY79cAwBMDPf1lrEn5MK6Z8Rnsi0rwD0j+68uTYEs04M0hbKV4UbbYTOYQZJ2jJH0KWxQwaaCjED8UfX3OoBvAvh7AB8E8AcAvsoY+zJjbFLY/rz6+7J+R5zzKoAbUCQzpyQcWyip1Oq4vJZv3qeTWPiQOsH0jxrftvM63X3RzYLGV8AYOGR8W4Axphljbe486UEgoWaw+433YYnGa1kSyNgrhFuiQDzUaJuT7aFaM7DJ9JFipYarm8p5UrFfJUODsCHfYSycyAjEp9TfPwtgAMB3ARgB8CIA/wClIPMTwvaNaMDsv954vOvZg3P+iNEPgIs2/4ZAcXUjj7I66R0bG8DogL0lYcJ/pC7rPvAK4KG3A1MLwGM/b/11r30vMDILpAaAoSng9e9rHRMVagaX2ZcAL/k3wMR54PFfMN2sY5vovmHgyV8Hxk8Br/0N58fy2vcq+3jNv7N3EQha1Qs740MZzI4qK2Wlah3XZTQnk8jldbJfDTthkD95gYyR21gDZQDexjn/lnp/iTH2ViiZ79cwxh7jnP+Lhf01hISx7XlKQVL4adh/1eq8af817PREkUgAP/QR+697yY8oPwZQDUKAYQz4gf/YdbOuFoZP/Kry0wsPvU35sUmuWMHtbcV+NZVgODs93NtxEL6wMJtt2gMur+QCZaOrqUGgOSyUnJ/JgjHFmefaZgHFSg396fg5WMvIiO+ov68LQTgAgHN+ACUrDgAvV383Mt5m6ZWsbrvYQUFS+Am6/Rdd7IWfjhlxn9Harw6jLxW/k2sUCHLGklZcws9wXwonDivnyVrdpDlZDJARiF9Sf983eb4RqDe8qxrbn9NvyBhLQSn8rAK4LuHYQgkFSdEgqMVOm3slbOwplnQD6SQ1wQgppyaG0Kf2F1jZLWKnUPb5iFosazpqUhFdWAlyh81l6qgZCahgU04g/gyUwPksY8zIBPJF6u+b6u8vqr/fZLDtEwAGAXyVc16ScGyhg3OubQt9lE5iYUVbTBecCUbMJM3NtjroEeFCb/8VpIwlFWpGA7EJ09LKbu/NySSht1+lMRZeFo4E8zzpJT0H4pzzLQAfhyI1eZ/4HGPsDQC+G4rMpGFX+EkAWwDewRh7mbBtP4APqHf/pNfjCit37x8gV1TaCY8OpHFklGzlwkpQl3VpxSU6BFWeQrKBaHBsbAAjam3Lzn4Fa7miz0ekcGt7HwXRfnWEzpNhJajnSS+R1Q/2PQCuAvgNxtgzjLHfY4x9AsBnoXTQfIpzfh8AOOc5AE9BKfL8J8bYRxhj/x7AcwAegxKof1zScYUOfZDEGGUrw0pQ7b+oBiE6dC3Y9IFytY4r64L9KgXioUXfnCwoF3vkUR8dxGZyF1ZzqNeDseriJVICcc75BoBXAPgQgAcA/FsojXs+A+DVnPNP6Lb/NIDXQJG1/BCAXwBQgRLQv4MHZf3LByhIig6i/Vc5QPZfon6XgqRwE8SM+LXNlv3q0UMDGB0k+9UwE8QxtrxKc1hUmBzpw8SwomreL9dwS3VbihOyMuLgnG9zzt/DOT/JOc9wzg9zzr+fc/41k+2/wjl/M+d8jHM+wDl/iHP+Ic55TdYxhRGSDUSLoBWi7JerzQuCBAPmZmiMhZk51f4LAK5u5lGs+D99UrYyWgRx1YXGWHRgLJirLl4iLRAn5CBOdItHaYIJO0HrHHZxbQ+N9aZTk8MYyJCtXJgZ6kvhZMDsv5bIzSJSBLGYjsZYtNA4jK36f570GgrEA8TufgV3dg4AAJlkAqcnqQlG2AlaIQqtuESP+YBJB0g2EC3OTg8jpTor3d7eR65Y8fV49ParDR9qIrwE8WLPSygQDxBioHZuZhjpJH08YUe0/1peyflu/0U1CNEjSNIBzjnJBiJGXyqJM1OtpJDYrMkPLpD9auQImoTTayjSCxBk+RU9gmb/RRnx6BGkYjrRfjXbn8LRQwNdXkGEAe0Y81c6QOfJ6HFyYgj9aSUc3dgrYXMvXm1kKBAPEBQkRY8g2X/V6hwX1yhbGTWCZP+lz4aT/Wo0CNKqC624RI9kgmmMAy4EQMbpJRSIBwitbIA6akaFoOjfbmzlUawotnLT2T5MDPf5diyEPKay/c3PsuCz/Ze2iI7msKggfpZ+a3g1nadpjEWGoNVTeQkF4gGhVK3hiuB4MD870mFrIkwERTqwRCsukSUoY4xkA9FE/CyvrOdRrvrTnExvv3p+ms6TUWExIAkrP6BAPCBcWc+jqi4pHz88iJF+aoIRFYKyrEuFmtFFO8b80/CSbCCajA6mm3r/cq2Oa5v5Lq9wh0tkvxpZtAWb8bIwpEA8IFAmKboExf5LW4NAS7pRIggZ8d39Cu7eJ/vVqBKEMUbnyegyN5NFwwDn+lYB++WqvwfkIRSIBwQq1IwuQbD/Ilu5aBOEVRfxfc9ODyOTotNLlAjEGKM5LLIMZJI4OaF4wnOurH7EBZopAwLJBqKNpnOYD8tum3sl3CuUAQBDmSSOjw96fgyEe5ycGMJAWlmmX8+VsJX33v5L0xWY5rDIsRiwjDiNseixoOmwGR+dOAXiAaBe57hAbgORxm/nFPE952ezSFATjEiRTDDMCQXefgRKopsFrepFD+0ctut5c7JanWtWE+dpjEWOuBZsUiAeAO7sHGCvpOihxocymM6SrVzU8HtZl1Zcoo/vY0wjG6BkQtQ4emgA2X6lOVmuWG3WA3jFja0CDio1AGS/GlXi2mGTAvEAILocLMxSE4wo4rf9F9UgRB8/i+lK1RqubrScNObIfjVyMMZ8HWNUqBl9xFWOi2s51HxsTuYlFIgHACpAiT5+239RRjz6+JkRF+1XHxwfRJbsVyOJ6Lbk9Rij82T0mRzpw9SIstJRrNRxQ/WMjzoUiAcAutKPB34VO+VLVdy8p0xoyQTDOWqCEUk09l+beRyUa569NxXRxQM/Cza1Y4ykT1Eljh02KRAPANq20HQSiyp+FWxeXM01m2CcmRxGf5qaYESRgUwSp1Tv7jpXlna9gqRP8cCvOUyxX6Vi4DiwqCsKjgMUiPvMdqGM1d0iAKAvlWj6aBLRw6/uhyRLiQ9+yVNINhAPTk8OI5NUwoa79w+wu+9Nc7LNvRK28i371QfJfjWyaORPMSnYpEDcZy4IJ8u5mRGkkvSRRBV9oZNX9l+UrYwPfhTT1eucLvZiQiaVwNnpVnMyry72loT3IfvVaOPXedJPKOrzGcokxQe/7L8oSIoPfmTE7+wcIK/ar44NpjGT7ffkfQl/8GOM0XkyPhwfH8RgRpFP3iuUsbnnfXMyr6FA3GeoUDM++GH/Va3VcVFoFUxjLNqI4+vi6p4n9l8a+9UjZL8adfxYdaHzZHxIJJjGxnApBgWbFIj7DDXBiBditb8XxU7XNgtNz/Ijo/0YG8q4/p6Ef0wM9zUbgh1Uap7Yfy1RV+BYoZ3DvKl1WaYxFiv8dOfxAwrEfaRYqeGq6ifNmKIRJ6KN18u6+mwlEX08H2NUgxArxGZNVzfyKFXdtcnU26+KGnUimsStwyYF4j5yeb21dHzy8BCG+lI+HxHhNl4v61KQFD88H2NUgxArsv3ppmtJtc5xZd3d5mSX1sh+NW7EzUucAnEfEU+S83QCiwVe239RkBQ/vOx+KNqvZlIJnCL71Vjg5aoLFWrGj3PTI0iqzjg37xWaxeBRhQJxH6EClPjhpf2X0gRDHGOkrYwDXmbEyX41nng5xug8GT/600mcnlQu6jlXVkWiDM2aPkJX+vHEq85hq7tF7KgZ95G+FB4YH3DtvYjgcHx8EEOq/ddWvoSNXNG19xLHL3UFjg9eFtNR5+l4EiedOAXiPlGvc002iSaY+ODVsq5e+kS2cvHAS/svqkGIJ3oNb90lm0y9/eo8jbHY4LXDmJ9QIO4Tt7b3USgr1eYTw32YGqEmGHFBtKl080qflnTji1fSAapBiCcz2X6MDaYBKK4md3bcaU52fYvsV+NKnAo2KRD3CZKlxBev7L9ojMUXL1ZdipUarm0qtnKMAednaIzFhbbmZKvuSOxoDosv4urHxbU9VGt1H4/GXSgQ9wmNvzNlK2OFV/ZflBGPL2LQcsGljLhov3ri8BCGyX41Vnih4aU5LL6MD2UwO6ooBcrVOq570JzMLygQ9wm60o83bhc75YoV3N7eBwCkkwznpqlZVJwQ7b9u3Cug4IL91xLNYbHGCw2vWAxMnafjR1wKNikQ9wmqBI83bksHxCzomakRZFL0VY8T/ekkzkwqNpmcAxddsP+iQs1447aGV2+/SufJ+OGVw5jf0NnZBzb3StjYKwEABtJJnDhMTTDihtvFdLSkS3g6xihIih2nJoaaF/iru0VsF8pS97+W09qvHhsj+9W4EZeCTQrEfUDTBGO2tYRMxAe37b9I+kS4uerSZr9KF3uxI5VMYG6mJXm7IHmMkf0qoekSvJID5+7YZPqNlECcMXaTMcZNftZ0257osC1njH1MxjEFGcpWEm7bf9EYI9zMiN/a3sd+0341g8mRPqn7J8KBmxpekj4Rx8YGMKIWge/sV7DmYnMyP5FZ5r4L4A8MHjezhPgWgE8bPP68tCMKKJStJBhjWDwyin++ugVAcdF58PCglH2Xq3WNEwuNsXiyYGD/JasFvXYOG6VsZUxZdFE6sEwN72JPoznZN25uA1DmndnR6EmUZAbi9znnv21j++dsbh8ZtG2hqRI8riwcyTYD8aWVHN70olkp+726kUdZ9Vw9NjaA0YG0lP0S4WJsKIMjo/1Y2S2ipNp/yXLP0bhZULYytiy4WExHrjwEoHz2jUB8aSWH189P+3xE8iGNuMfsl6tNP8wEA86TrVxscWtZl2QpRAO35ClUqEkAShOnxmLItc0CihU5zcn09qtnp+g8GVe86hLsJzID8T7G2DsZY+9ljP0iY+y1jLFkh+2PMMbepW7/LsbYwxKPJbBcWttDo97g1OQwBjKd/kVElHGrIpykT0QDtwo2Sb9LAMBwX6rp+lWrc1xe35Oy34urrf2Q/Wq88aJLsN/IlKbMAPgL3WM3GGP/M+f8ywbbv0H9acIY+ycAP845v23lDRljz5o8NWfl9X5A2UqiQcP+q1ytN+2/xocyPe+XurYSDdzIJon2q/3pBE5OkP1qnFmYzeKGusq7vJLDw8cO9bzPZZI+ESpnp4eRSjBU6xy3t/eRK1aQ7Y+W3FLWZeafA3g9lGB8CMBDAD4M4ASAzzLGXixsuw/g/QAeATCm/rwGwJcAPAngC4yxyM7slK0kGrhh/6VvgkFjLN5o7L9W5dh/aexXZ7Jkvxpz3FjZI+kT0aAvlcSZqeHmfXG1JCpICcQ557/DOf8i53ydc77POX+ec/6zAH4fwACA3xa23eCcv49z/k3O+X315xkAbwTwdQBnAPy0xfd9xOgHwEUZf5cbUCU4ISK7c9idnQPkiko789GBNI4eil6FOWGdB8Zb9l/bhbIU+y/qCkyIaAs25QTiNMYIEdHUYjmCHTbdFl79J/X3E9025JxXAXzE6vZhpFbnmqu5eVpyiz2yCzb10ieylYs3jDHMS5anULaSEBGbOV2Q0JxMb79K50nCjYu9IOF2IL6h/rYqNdm0uX2ouLFVwIFaVT6d7cPEMDXBiDuyl3VJlkLokX6xR/pdQmBypA8Tw0pty365hluq24lTrm2S/SqhJeoFm24H4o+pv69b3P6VNrcPFVSoSeiRbf9FY4zQI/NiT2+/OjdDYyzuMMY0WeteL/bIkYfQI46DK+t5lKt1H49GPj0H4oyxRcbYuMHjxwH8kXr3L4XHX8EYa7OGYIy9DsAv67ePEpStJPTItv+iMUbokZlNEu1XT04Mkf0qAUB/sdebhpekT4Se0cFWvVO5Vse1TbOG7eFEhn3h2wH8OmPsSwBuANgDcBrAWwD0A3gawO8J2/8ugEXVqvCO+tjDAF6n3v4tzvlXJRxX4NBmK6mjJqGwcKRl/7XUg/3X/f0y7t4/AABkkglNpTkRX85NjyCdZKjUOG7d683+S1tER3MYoSCOhV41vNR5mjBi4Ui2eX5bXslFqnZAhjTlSwD+FsBJAD8K4D1Q7Aj/GcCPA/heznlZ2P4voLijPArgKQDvBnAWwF8DeIJz/gEJxxQ4FFs5cYKJziAiekOWhle80Ds3M4x0kppgEEAmlcAZoTNhL/ZflK0kjJA1h5H9KmHGYoQLNnvOiKvNeowa9pht/1EAH+31fcPG5l4JW3nlemQok8SD44M+HxERFGRpeElbSZixMJtt+n8vr+zi5Sfb1ISWoDFGGHFy4v9v786D5DjLO47/nr1Xe1nHaleygi5LWkkYV7ArwXLwWRAImNNO/IeJi0AKUwnggKtCEQimAilSgeCAE6CSClQgFZMygVQSG5L45ChIMBDHOmzJ1trY1urWag/t/eaP7tntGc3R3dO9PTP6fqqmprane/bdd97tefrt933eLnW0NmlqdkHHxqZ1fGxa/T3RkxG8eCY//er6vo6ki4o6lT/ErrFSGNJltkz2BgKsnet61cQiGPAllf6LiZooJYmLvfkFpwMj+ecxQJKamyxv4m7cxckKL/RIv4qcwlWCk1icrFYQiC8TbrehlKTSf+W3McZWYkkSEzYPn5jQ1KyXrWBtT3usHk80riQu9hj6hFIuvqhTvR3eII6zU3OL48UbAYH4MqG3EqWYWV7gHGeFzem5eR06FlwEo6fM3rjQBIOap0fGNTsfPf3XXua4oIwkxvCyoiZK8b4nk10ToVYQiC+TfWQbQBnVTnY6eHRcc/6Qlo2rV6gnZlYMNKa+zlZtWLmU/it40RYWvZUoJ/8cFm8ML3eOUU6S2XlqCYH4MhifntPwSS89XXOTadsAaeWQr9rbukyiQyXVXuzltzE6E5BvaLBXualPz56Y0OTMXKTjRydn89Kvbu3nexL5GnWFTQLxZfDUyNnFRTAu6e9WRyuLYCBf1UESQ59QQTUXe6SVQyWdbc3avMZbnMw5b/GnKEi/ikoYmoLY+AJDJZvXdKnTv0DLpf+KgjaGSqq52Ds+Nq2TE0vpVzeSfhVFBOe6RL3YozMBlWzt71abf4H24plzGp2czbhEySAQXwacYFBJc5NpKDDBMkr6r4UFl9enBxqmAAAUtUlEQVTGmIOAYnZfnB8kRUn/RfpVhLG7ih5L5lGhkraWpryhvY0yPIVAfBkwExxhBC/SokxE+cXpSY1Pe+MxV3W1aaCXtHI43/q+DvV1epN4R8/NRkr/xR0XhBH3HObtvzTBkzaGUvKz8zTGwj4E4imbm1/QgcBYORbBQClxx/CyCAbCMLPYw1OYDIwwgt9vB0bOaj7k4mSF6VeHBkm/iuIaccImgXjKnj0xoZk5L2fv+r4Orexqy7hEqFVx03+RVg5hxb7Yo40hhP6edq31F3qaml3Q4RMToY4j/SrCypuH0CATNgnEU8YtXYQVN/0XvZUIK06PeGH61e0D9FaitDgXe8yjQljBuVSHjo1rem4+w9Ikg0A8ZZxgEFbc9F/0ViKsOEFSMP3q1v4u0q+irDgXe3QmIKzejla9zM/aNLfgdPBo9MXJag2BeMrye8SZCY7yoq4cdmpiRkdGpyRJ7S1N2uIH8kAxl6xdSv/1wulw6b/2ks0CEeSfw8INscvLmHIxgTjK213lAni1hkA8Rc65vBMRGVNQSdQey+AX2NBgj1pYBANltDY3aftgtPRf9FYiisJFVyqlySxMv8qqraik2gXwag3f2ikaOTul036PU097izas7My4RKh1UU8w+46Q8gvRRM06wNAnRLFx1QqtaPOGL52cmKm4ONkLp8+RfhWRNNoKmwTiKQo2kJ3rSSuHyqKm/6K3ElFFudgj/SqiamqyvHayt8LFXl5nAulXEULhneOFkGkyaxWBeIoIkhBV1PRf9FYiqijLkAfTr67r69Aq0q8ihCgXe2QWQ1SDvR1aucJLcTk+PacXTodfnKwWEYiniCAJcYRdOWxqdl7PHPcCdTMv/SFQyc5A+q+DR8fKpv9ijgviiLLUPStPIyozK+gVr+8VNgnEU8QJBnGEnbD51MjY4tCVzau71NXeknrZUP96Olq1cXW49F/c1UMcUSadk+IXcUTNMFbLCMRTcnZqVs+fmpQktTabtq1lEQyEE8waUK43KfgFtpMLPUQQdsImd/UQx/aBHjX7q5MNn5xYnIxZqDD96mbSryKkRsqcQiCekgNHliY4XbK2R20tVDXCCZv+i95KxBXmS8w5V9DGSCuHcDpam7W1P7g4WfE2tj9woUf6VUQRZ3GyWkWrT8m+l/JnggNhbVy1Ql0h0n/RW4m4wnyJkX4V1QhzscdETcS1ZU3XYgfnkdEpnZqYybhE8RGIp4QgCXGdl/6ryJfY/ILL601iDgKiCI6v3P9S8fRfe1/MH/rU1ERaOYQXZgxvcDIwK08jipbmJg0NLg353V/HveIE4ilhoiaqUanH8rmTE5qc8bJdrOlu19qejmUrG+rfQG/7YirCsRLpv5hEh2qEuetCG0M1wmYYq3UE4imYmVvIy0TAIhiIqtJtXe64oBpmVjBh8/wvMYYNoBr5i5ONaW5+Ie/189OvktAA0TTKhE0C8RQ8c3xcM/5JZ8PKTvV1tmZcItSbSr1JTNREtSotE01vJaqxqqtN6/q8O3Uzcwt6tmBxsqePkn4V1WmUCZsE4ikgSEK1KqX/okcc1SqXwjCYfrWlybRtoHtZy4bGUK7HMvgz6VcRx47BXpk/deWZ4xOami29OFktIxBPAUESqtXR2qxL+r3gp1j6r33MQUCVyq1+GEy/um2gR+0tzctWLjSO3WV6LPcx2RxV6m5v0abVXprM+QWnp4+OVTiiNhGIpyB/WWhmgiOeXeuLZ045PjatY35Kw87W5sUTERDF5jVdavfTf700OqXTgfRfe0m/igTsKjOZbi93jpGAUt+T9YRAPGHnLYLBlT5iKnVbN9iTNLRuaQgLEEVh+q9gu+IchiQUrhKcW5xsoSD9Km0McTXChE0C8YS9eOaczk5543n7Olu1vo+0coin1EQU5iAgKaUmbDJRE0nYsLJTPf4kzNOTsxo56y1n/9ypSdKvIhGNMGGTQDxhhUGSGb2ViGdXifRfzEFAUopN2CxMv0ogjrgKFyfLfT9yxwVJ2R1oX/uPFF+crNYRiCeMIAlJWdnVtnhHJZj+ax9zEJCQ4GqGueDovPSrK0i/iviK3XUJ5q1noiaq0d/TrjXd3uJkkzPzes7P9lRPCMQTRjYLJKlwstPkzNxiQN5k0o4BFsFAfEODPYvpvw4dH9fU7DyT6JCoYpPpaGNIipkV7VCoJwTiCdvLLTckqHAiyoGRMfnznbSlv1udbaSVQ3xd7S3aXJD+i2EDSFKx4U+0MSQp2Mbqcan7RAJxMxs2M1fiMVLimD1mdr+ZnTKzSTN7wszuMLO6jSxGJ2f14plzkqS25iZt7WcRDFSncCIKEzWRtJ0FQweCwwZoY6jWtoFutfiZnZ4/NanDJyZIv4pE1fuEzSTXlB2VdHeR7eOFG8zszZK+KWlK0jcknZJ0o6TPSbpK0s0JlmvZBBvA9sFutTZzwwHVKUz/9bJVS19a9CQhCbvW9erfnzgiybujR28lktTe0qxL1nbrwIi32Mo///SFxddIv4ok1HsKwyQD8TPOubsq7WRmvZL+RtK8pGudcz/xt39M0kOSbjKzW5xz9yZYtmVByi8kLZf+a2x6TqcnZ/XwgWOLr9HGkIRgsP1f+4/mpV+9+KLOrIqFBrJrfe9iIH7f40uBOOcwJGHzmi51tjbr3Oy8jo1N6/jYtPp72rMuVmhZdNneJKlf0r25IFySnHNTkj7q//jeDMpVtfyJmmSzQPWamixv6EAuD69EbyWSEZxUfmQ00L5Iv4qEBL8Pg22M70kkobnJNLRuKXHB/jobnpJkIN5uZrea2UfM7ANmdl2J8d7X+8/fKfLaY5ImJe0xs/q5nPHlLQtNkISEFOs1Guht15ruuvsXQQ1a29NRtC1xDkNSSvV808aQlPwJm/UViCc5NGVQ0tcKth02s3c65x4NbNvhPz9d+AbOuTkzOyxpt6QtkvaX+4Vm9niJl4bCFTk503PzOnRsaTh8cOlooBrFvqy4pYsk7Vrfq8eePp6/jTaGhBRrS6RfRZLqecJmUj3iX5F0g7xgvEvSpZK+LGmTpAfM7LLAvrl7UaVyzOS2X5RQ2ZbFwaPjmvNXdNq4eoV6OlgEA8m4bsdadbfnXzPfeNn6jEqDRvSmgvbU096ia3b0Z1QaNJq+Fa26Znt+e3rNrgHSryIx+RM26yuFYSI94s65TxRselLS7WY2LulDku6S9NaQb5cblFhxnVLn3OVF38DrKX9lyN+XiB2DPXrgA6/WvpfOat7V3xKrqF39Pe166M5r9PjwaS0470KPxaKQpLe/8mLtGOjR86cm1WTSFZtWMfQJifryOy7Xj549qYnpeXV3tOjKLauzLhIayNBgrz74mu3ata637oY8JTk0pZgvyQvErw5sy12qlJql0VuwX11obW7SznW92sntXKRgbU+HXn/puqyLgQZlZrp0Q58u3cDkOaSjo7VZ1+5Ym3Ux0KA625r1/hu2ZV2MWNLOmpLLtRbM2P+U/7y9cGcza5G0WdKcpGfTLRoAAACQnbQD8Sv952BQ/ZD//Loi+18taYWkHzrnptMsGAAAAJClqgNxM9ttZquKbN8o6R7/x68HXrpP0glJt5jZFYH9OyR90v/xi9WWCwAAAKhlSYwRv1nSh83sYUmHJY1J2irpDZI6JN0v6TO5nZ1zZ83sd+UF5I+Y2b3ylrh/k7zUhvfJW/YeAAAAaFhJBOIPywugf1neUJQuSWckfV9eXvGvOZefRsQ5920zu0bSH0l6u7yA/ZCkD0r6fOH+AAAAQKOpOhD3F+t5tOKO5x/3A0m/Ue3vBwAAAOpR2pM1AQAAABRBIA4AAABkgEAcAAAAyACBOAAAAJABAnEAAAAgAwTiAAAAQAYIxAEAAIAMEIgDAAAAGSAQBwAAADJAIA4AAABkwJxzWZchcWZ2srOzc9XOnTuzLgoAAAAa2P79+3Xu3LlTzrnVUY9t1ED8sKReScPL/KuH/OcDy/x74aH+s0PdZ4v6zw51ny3qPzvU/ZJNks465zZHPbAhA/GsmNnjkuScuzzrslyIqP/sUPfZov6zQ91ni/rPDnWfDMaIAwAAABkgEAcAAAAyQCAOAAAAZIBAHAAAAMgAgTgAAACQAbKmAAAAABmgRxwAAADIAIE4AAAAkAECcQAAACADBOIAAABABgjEAQAAgAwQiAMAAAAZIBAHAAAAMkAgngAz22Bmf2dmL5nZtJkNm9ndZrYy67I1Cr9OXYnHSIlj9pjZ/WZ2yswmzewJM7vDzJqXu/y1zsxuMrMvmNn3zOysX69fr3BM5Po1szea2SNmNmpm42b2YzO7Lfm/qL5EqX8z21Tmf8GZ2b1lfs9tZvbfft2P+p/FG9P7y2qbma02s3eb2bfM7JCZnfPr5ftm9i4zK/odSdtPRtT6p+0ny8z+zMweNLNf+HV/ysx+ZmYfN7PVJY6h7SeMBX2qZGZbJf1Q0lpJ/yLpgKRfkXSdpKckXeWcO5ldCRuDmQ1LukjS3UVeHnfOfaZg/zdL+qakKUnfkHRK0o2Sdki6zzl3c6oFrjNm9nNJl0kal/SCpCFJ/+Ccu7XE/pHr18x+X9IXJJ30j5mRdJOkDZI+65y7M+E/q25EqX8z2yTpsKT/lfTtIm/3pHPuviLHfUbSh/z3v09Sm6RbJK2S9D7n3D1J/C31xMxul/RFSUckPSzpeUkDkt4mqU9eG7/ZBb4oafvJiVr/tP1kmdmMpJ9K2ifpmKQuSa+SdIWklyS9yjn3i8D+tP00OOd4VPGQ9F1JTt4/c3D7X/jbv5R1GRvhIWlY0nDIfXvlnVSmJV0R2N4h76LJSbol67+plh7yLhy3STJJ1/p19PWk6lfSJnkn75OSNgW2r5R0yD/myqzroU7qf5P/+lcjvP8e/5hDklYWvNdJ/7PZVM3fUI8PSdfLCySaCrYPygsKnaS3B7bT9rOtf9p+svXfUWL7p/w6++vANtp+Sg+GplTBzLZIeq28IPGvCl7+uKQJSe8ws65lLtqF7iZJ/ZLudc79JLfROTcl6aP+j+/NomC1yjn3sHPuoPPPkhXEqd/fkdQu6R7n3HDgmNOS/tT/8faYxa97Ees/jlzdfsqv89zvHZZ37mqX9M6UfnfNcs495Jz7V+fcQsH2EUlf8n+8NvASbT9BMeo/Dtp+CX67Leaf/OdtgW20/ZQQiFfnev/5P4qcSMYk/UDSCnm3elC9djO71cw+YmYfMLPrSoxLy30u3yny2mOSJiXtMbP21Era2OLUb7ljHijYB+GsN7P3+P8P7zGzV5TZl/qPbtZ/ngtso+0vn2L1n0PbT9eN/vMTgW20/ZS0ZF2AOrfDf366xOsH5fWYb5f04LKUqLENSvpawbbDZvZO59yjgW0lPxfn3JyZHZa0W9IWSftTKWlji1O/5Y45YmYTkjaY2Qrn3GQKZW5Er/Efi8zsEUm3OeeeD2zrknSxvLkUR4q8z0H/eXtK5aw7ZtYi6bf9H4NBBG1/GZSp/xzafoLM7E5J3fLG5V8h6dfkBeGfDuxG208JPeLV6fOfR0u8ntt+0TKUpdF9RdIN8oLxLkmXSvqyvDFoD5jZZYF9+VzSFad+wx7TV+J1LJmU9CeSLpc31nKlpGvkTXa7VtKDBcPh+H+I7tOSXi7pfufcdwPbafvLo1T90/bTcae84bR3yAvCvyPptc6544F9aPspIRBPl/nPpKapknPuE/54wqPOuUnn3JPOudvlTYrtlHRXhLfjc0lXnPrlMwnJOXfMOffHzrmfOufO+I/H5N19+7GkSyS9O85bJ1rQOmVm75eXYeOApHdEPdx/pu3HVK7+afvpcM4NOudMXkfX2+T1av/MzF4Z4W1o+zERiFen0tVcb8F+SF5uQs/VgW18LumKU79hjzlbRbkuaM65OUl/6/8Y5f+hUq/VBcPMfk/SX8pL53adc+5UwS60/RSFqP+iaPvJ8Du6viXvwma1pL8PvEzbTwmBeHWe8p9LjS/LzTguNYYc1TvmPwdvR5b8XPyxh5vlTQB6Nt2iNaw49VvumHXyPr8XLuRxggnJ3Upe/H9wzk1IelFSt1/XhThPSTKzOyTdI+lJeUFgsYXCaPspCVn/5dD2E+Kce07exdBuM1vjb6btp4RAvDoP+8+vLbICWI+kqySdk/Sj5S7YBeRK/zn4z/+Q//y6IvtfLS+TzQ+dc9NpFqyBxanfcse8vmAfxJfL0FR4kUn9l2Fmfyjpc5J+Li8IPFZiV9p+CiLUfzm0/WSt95/n/WfaflqySF7eSA+xoM9y1PFuSauKbN8ob9a7k/SRwPZeeb0jLOgTr76vVeUFfSLVr7zeEhZ2SKb+f1VSW5Ht1/t17CTtKXiNRU1K1/fH/Lr5SbHzTMG+tP1s65+2n1y9D0kaLLK9SUsL+vwgsJ22n9KDJe6rVGSJ+/3yThbXybvdtcexxH1VzOwuSR+WdwfisKQxSVslvUHeSeB+SW91zs0EjnmLvKWMpyTdK28p3jfJX4pX0m86Gv8iv77e4v84KOnX5fUsfc/fdsIFliKOU79m9j5JnxdLHZ8nSv37adp2S3pE3pLdkvQKLeXj/Zhz7pNFfsdnJX1Q+ct8/5a8saAX5DLfZnabpK/K6/X7goqPFR52zn01cAxtPyFR65+2nxx/KNCfy8sB/oy8tjkgLwvNFkkjkm5wzu0LHEPbT0PWVwKN8JD0S/LS6x2R18iekzfhpOzVPY/Q9XuNpH+UN4v+jLyFHo5L+k95uWatxHFXyQvST8sbIvR/kv5AUnPWf1OtPeRlnXFlHsNJ1K+8hSIelXcxNSHpf+Tl/s28Duql/iW9S9K/yVvRd1xeD9Xz8r7kXl3h99zm1/mE/xk8KumNWf/9NVzvTtIjRY6j7WdQ/7T9ROv+5fJWFv25pBPyxneP+nV0l0rEL7T95B/0iAMAAAAZYLImAAAAkAECcQAAACADBOIAAABABgjEAQAAgAwQiAMAAAAZIBAHAAAAMkAgDgAAAGSAQBwAAADIAIE4AAAAkAECcQAAACADBOIAAABABgjEAQAAgAwQiAMAAAAZIBAHAAAAMkAgDgAAAGSAQBwAAADIAIE4AAAAkIH/B6qUG0LQo+qeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 369
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(list(np.ones(200)*89))\n",
    "\n",
    "#plt.plot(list(np.ones(200)*50))\n",
    "#plt.plot(list(np.ones(20)*50))\n",
    "plt.plot(testing_data_unnorm)\n",
    "plt.plot(predicted_notes_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({72: 14,\n",
       "         71: 2,\n",
       "         74: 10,\n",
       "         69: 4,\n",
       "         81: 24,\n",
       "         86: 17,\n",
       "         79: 104,\n",
       "         77: 7,\n",
       "         76: 62,\n",
       "         83: 28,\n",
       "         85: 2,\n",
       "         84: 13,\n",
       "         78: 7,\n",
       "         89: 4,\n",
       "         60: 6,\n",
       "         88: 12,\n",
       "         62: 4})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter(predicted_notes_lst)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
