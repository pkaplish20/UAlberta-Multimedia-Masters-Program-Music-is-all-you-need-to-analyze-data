{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.tensorboard as tb\n",
    "from Preprocessing.preprocessing_sorted import PreprocessingTrainingData\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as  plt\n",
    "import os\n",
    "import logging\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#static parameters\n",
    "train_batch_size = 115\n",
    "val_batch_size = 115\n",
    "sequence_length=50\n",
    "test_batch_size = 1\n",
    "input_size = 1\n",
    "hidden_size = 256\n",
    "num_layer = 2\n",
    "output_size = 38\n",
    "clip = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from preprocessing.py\n",
    "dataset_path = os.path.join(os.path.abspath('..'),'Dataset\\\\Clementi dataset\\\\Clementi dataset' )\n",
    "network_input,network_output,max_midi_number,min_midi_number,int_to_note = PreprocessingTrainingData().preprocess_notes(dataset_path)\n",
    "network_input, network_output = network_input.cuda(), network_output.cuda()\n",
    "\n",
    "# print(network_input)\n",
    "#print(network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(37, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(network_output.max())\n",
    "print(network_output.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2361])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "89\n",
      "50\n",
      "{0: 50, 1: 52, 2: 53, 3: 54, 4: 55, 5: 56, 6: 57, 7: 58, 8: 59, 9: 60, 10: 61, 11: 62, 12: 63, 13: 64, 14: 65, 15: 66, 16: 67, 17: 68, 18: 69, 19: 70, 20: 71, 21: 72, 22: 73, 23: 74, 24: 75, 25: 76, 26: 77, 27: 78, 28: 79, 29: 80, 30: 81, 31: 82, 32: 83, 33: 84, 34: 85, 35: 86, 36: 88, 37: 89}\n"
     ]
    }
   ],
   "source": [
    "print(network_input.max())\n",
    "print(network_input.min())\n",
    "print(max_midi_number)\n",
    "print(min_midi_number)\n",
    "print(int_to_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2361, 50, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata is highly unbalanced\\n# '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data is highly unbalanced\n",
    "# '''\n",
    "# sns.distplot(torch.tensor(network_output).cpu())\n",
    "# xx = pd.DataFrame(torch.tensor(network_output).cpu())\n",
    "# xx.groupby(0).size().to_frame(name='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2300, 50, 1])\n",
      "torch.Size([2300])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "to make batch of equal sizes\n",
    "Quick Fix\n",
    "'''\n",
    "network_input = network_input[: -61]\n",
    "network_output = network_output[: -61]\n",
    "\n",
    "print(network_input.shape)\n",
    "print(network_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create Stacked LSTM model\n",
    "'''\n",
    "class Stacked_LSTM(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, batch_first = True, dropout = 0.5)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hidden,batch_size):\n",
    "        \n",
    "        output, hidden = self.lstm(x, hidden)        \n",
    "        #print(output.shape)\n",
    "        \n",
    "        # stack up lstm outputs\n",
    "        output = output.contiguous().view(-1, self.hidden_size)\n",
    "        #print(output.shape)\n",
    "        \n",
    "        output = self.dropout(output)\n",
    "        output = self.linear(output)\n",
    "        #print('Linear Output :-',output.shape)\n",
    "        \n",
    "        #output = F.softmax(output, dim = 1)\n",
    "        #print('SOFTMAX OUTPUT :--', output)\n",
    "        \n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        output = output.view(batch_size, -1)\n",
    "        #print('Reshape to batch size first :-',output.shape)\n",
    "        \n",
    "        output = output[:, -self.output_size:] # get last batch of labels\n",
    "        #print('Final Output :-',output)\n",
    "        #print('RESHAPE SIZE :-', output.shape)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def hidden_init(self,batch_size):\n",
    "        \n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden = (weight.new(self.num_layers, batch_size, self.hidden_size).zero_(),\n",
    "          weight.new(self.num_layers, batch_size, self.hidden_size).zero_())\n",
    "        return hidden\n",
    "\n",
    "#initialize the weights of LSTM using Xavier initialization    \n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Divide the dataset into train/val \n",
    "'''\n",
    "train_size = 0.8\n",
    "indices = list(range(len(network_input)))\n",
    "split = int(np.floor(train_size*len(network_input)))\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "train_sampler = SequentialSampler(train_idx)\n",
    "val_sampler = SequentialSampler(val_idx)\n",
    "\n",
    "dataset = TensorDataset(network_input,network_output)\n",
    "train_loader = DataLoader(dataset, batch_size= train_batch_size, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset, batch_size= val_batch_size,sampler= val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stacked_LSTM(\n",
       "  (lstm): LSTM(1, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=256, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optimizer\n",
    "\n",
    "model = Stacked_LSTM(input_size,hidden_size,num_layer,output_size)\n",
    "model.apply(init_weights)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optimizer.AdamW(model.parameters())\n",
    "#optimizer = optimizer.RMSprop(model.parameters(), lr = 0.001, weight_decay = 0.01)\n",
    "\n",
    "\n",
    "#make sure to transfer model to GPU after initializing optimizer\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTrain Loss: 3.5800878 \tVal Loss:3.4100335 \tTrain Acc: 4.565217% \tVal Acc: 1.9565217%\n",
      "Validation Loss decreased from    inf to 3.410033, saving the model weights\n",
      "Epoch: 1\tTrain Loss: 3.4475122 \tVal Loss:3.3310713 \tTrain Acc: 6.032609% \tVal Acc: 1.3043478%\n",
      "Validation Loss decreased from 3.410033 to 3.331071, saving the model weights\n",
      "Epoch: 2\tTrain Loss: 3.3626674 \tVal Loss:3.1608108 \tTrain Acc: 3.423913% \tVal Acc: 8.4782608%\n",
      "Validation Loss decreased from 3.331071 to 3.160811, saving the model weights\n",
      "Epoch: 3\tTrain Loss: 3.3091430 \tVal Loss:3.1385721 \tTrain Acc: 4.565217% \tVal Acc: 8.4782608%\n",
      "Validation Loss decreased from 3.160811 to 3.138572, saving the model weights\n",
      "Epoch: 4\tTrain Loss: 3.2835425 \tVal Loss:3.1272240 \tTrain Acc: 5.163043% \tVal Acc: 8.4782608%\n",
      "Validation Loss decreased from 3.138572 to 3.127224, saving the model weights\n",
      "Epoch: 5\tTrain Loss: 3.2710857 \tVal Loss:3.0958062 \tTrain Acc: 5.815217% \tVal Acc: 10.4347827%\n",
      "Validation Loss decreased from 3.127224 to 3.095806, saving the model weights\n",
      "Epoch: 6\tTrain Loss: 3.2399686 \tVal Loss:3.1482610 \tTrain Acc: 6.630435% \tVal Acc: 8.0434782%\n",
      "Epoch: 7\tTrain Loss: 3.2674060 \tVal Loss:3.0832863 \tTrain Acc: 5.706522% \tVal Acc: 9.9999999%\n",
      "Validation Loss decreased from 3.095806 to 3.083286, saving the model weights\n",
      "Epoch: 8\tTrain Loss: 3.2237088 \tVal Loss:3.0558132 \tTrain Acc: 6.684783% \tVal Acc: 9.7826086%\n",
      "Validation Loss decreased from 3.083286 to 3.055813, saving the model weights\n",
      "Epoch: 9\tTrain Loss: 3.1839467 \tVal Loss:2.9981640 \tTrain Acc: 6.413043% \tVal Acc: 10.4347823%\n",
      "Validation Loss decreased from 3.055813 to 2.998164, saving the model weights\n",
      "Epoch: 10\tTrain Loss: 3.1335584 \tVal Loss:3.1371008 \tTrain Acc: 7.771739% \tVal Acc: 6.0869564%\n",
      "Epoch: 11\tTrain Loss: 3.1312660 \tVal Loss:3.0690069 \tTrain Acc: 6.358696% \tVal Acc: 10.6521741%\n",
      "Epoch: 12\tTrain Loss: 3.1951895 \tVal Loss:3.0023285 \tTrain Acc: 5.815217% \tVal Acc: 11.0869562%\n",
      "Epoch: 13\tTrain Loss: 3.0977340 \tVal Loss:2.9458460 \tTrain Acc: 8.206522% \tVal Acc: 9.3478261%\n",
      "Validation Loss decreased from 2.998164 to 2.945846, saving the model weights\n",
      "Epoch: 14\tTrain Loss: 3.0977343 \tVal Loss:2.8908172 \tTrain Acc: 6.521739% \tVal Acc: 13.4782607%\n",
      "Validation Loss decreased from 2.945846 to 2.890817, saving the model weights\n",
      "Epoch: 15\tTrain Loss: 2.9998643 \tVal Loss:2.8189214 \tTrain Acc: 9.510869% \tVal Acc: 14.5652171%\n",
      "Validation Loss decreased from 2.890817 to 2.818921, saving the model weights\n",
      "Epoch: 16\tTrain Loss: 2.9599500 \tVal Loss:2.8119665 \tTrain Acc: 10.21739% \tVal Acc: 13.0434781%\n",
      "Validation Loss decreased from 2.818921 to 2.811967, saving the model weights\n",
      "Epoch: 17\tTrain Loss: 2.9396012 \tVal Loss:2.7865022 \tTrain Acc: 9.293478% \tVal Acc: 15.2173912%\n",
      "Validation Loss decreased from 2.811967 to 2.786502, saving the model weights\n",
      "Epoch: 18\tTrain Loss: 2.9209246 \tVal Loss:2.7611825 \tTrain Acc: 11.46739% \tVal Acc: 15.6521739%\n",
      "Validation Loss decreased from 2.786502 to 2.761182, saving the model weights\n",
      "Epoch: 19\tTrain Loss: 2.8834800 \tVal Loss:2.7230638 \tTrain Acc: 10.70652% \tVal Acc: 13.6956517%\n",
      "Validation Loss decreased from 2.761182 to 2.723064, saving the model weights\n",
      "Epoch: 20\tTrain Loss: 2.8671777 \tVal Loss:2.7755120 \tTrain Acc: 12.01087% \tVal Acc: 12.1739130%\n",
      "Epoch: 21\tTrain Loss: 2.8644593 \tVal Loss:2.7855809 \tTrain Acc: 10.65217% \tVal Acc: 12.6086952%\n",
      "Epoch: 22\tTrain Loss: 2.8566443 \tVal Loss:2.8837699 \tTrain Acc: 12.06522% \tVal Acc: 8.9130434%\n",
      "Epoch: 23\tTrain Loss: 2.9148957 \tVal Loss:2.9766017 \tTrain Acc: 10.27174% \tVal Acc: 8.6956521%\n",
      "Epoch: 24\tTrain Loss: 2.9331425 \tVal Loss:2.8538701 \tTrain Acc: 10.27174% \tVal Acc: 8.9130433%\n",
      "Epoch: 25\tTrain Loss: 2.8996153 \tVal Loss:2.7002695 \tTrain Acc: 10.16304% \tVal Acc: 11.7391302%\n",
      "Validation Loss decreased from 2.723064 to 2.700269, saving the model weights\n",
      "Epoch: 26\tTrain Loss: 2.8481029 \tVal Loss:2.6931903 \tTrain Acc: 9.782609% \tVal Acc: 15.0000000%\n",
      "Validation Loss decreased from 2.700269 to 2.693190, saving the model weights\n",
      "Epoch: 27\tTrain Loss: 2.7809358 \tVal Loss:2.6748639 \tTrain Acc: 12.88043% \tVal Acc: 16.7391306%\n",
      "Validation Loss decreased from 2.693190 to 2.674864, saving the model weights\n",
      "Epoch: 28\tTrain Loss: 2.7715318 \tVal Loss:2.6338091 \tTrain Acc: 12.33696% \tVal Acc: 14.3478258%\n",
      "Validation Loss decreased from 2.674864 to 2.633809, saving the model weights\n",
      "Epoch: 29\tTrain Loss: 2.7574095 \tVal Loss:2.6168510 \tTrain Acc: 13.8587% \tVal Acc: 15.6521739%\n",
      "Validation Loss decreased from 2.633809 to 2.616851, saving the model weights\n",
      "Epoch: 30\tTrain Loss: 2.7165054 \tVal Loss:2.5839755 \tTrain Acc: 14.45652% \tVal Acc: 15.8695653%\n",
      "Validation Loss decreased from 2.616851 to 2.583975, saving the model weights\n",
      "Epoch: 31\tTrain Loss: 2.7191263 \tVal Loss:2.5978646 \tTrain Acc: 12.28261% \tVal Acc: 14.3478261%\n",
      "Epoch: 32\tTrain Loss: 2.7034238 \tVal Loss:2.6136498 \tTrain Acc: 14.29348% \tVal Acc: 12.6086954%\n",
      "Epoch: 33\tTrain Loss: 2.7082727 \tVal Loss:2.6534006 \tTrain Acc: 14.40217% \tVal Acc: 11.9565213%\n",
      "Epoch: 34\tTrain Loss: 2.6884905 \tVal Loss:2.6500986 \tTrain Acc: 14.13043% \tVal Acc: 10.4347825%\n",
      "Epoch: 35\tTrain Loss: 2.6863965 \tVal Loss:2.6620686 \tTrain Acc: 14.18478% \tVal Acc: 12.1739129%\n",
      "Epoch: 36\tTrain Loss: 2.6997025 \tVal Loss:2.6047893 \tTrain Acc: 14.02174% \tVal Acc: 13.6956519%\n",
      "Epoch: 37\tTrain Loss: 2.7236525 \tVal Loss:2.5853923 \tTrain Acc: 13.69565% \tVal Acc: 14.3478261%\n",
      "Epoch: 38\tTrain Loss: 2.6723248 \tVal Loss:2.5598141 \tTrain Acc: 14.83696% \tVal Acc: 16.5217390%\n",
      "Validation Loss decreased from 2.583975 to 2.559814, saving the model weights\n",
      "Epoch: 39\tTrain Loss: 2.6652859 \tVal Loss:2.4975913 \tTrain Acc: 14.83696% \tVal Acc: 17.3913043%\n",
      "Validation Loss decreased from 2.559814 to 2.497591, saving the model weights\n",
      "Epoch: 40\tTrain Loss: 2.6356826 \tVal Loss:2.4839797 \tTrain Acc: 15.32609% \tVal Acc: 18.4782606%\n",
      "Validation Loss decreased from 2.497591 to 2.483980, saving the model weights\n",
      "Epoch: 41\tTrain Loss: 2.6269964 \tVal Loss:2.5374430 \tTrain Acc: 16.52174% \tVal Acc: 18.2608694%\n",
      "Epoch: 42\tTrain Loss: 2.6717557 \tVal Loss:2.5589935 \tTrain Acc: 13.58696% \tVal Acc: 18.2608692%\n",
      "Epoch: 43\tTrain Loss: 2.6483434 \tVal Loss:2.5244942 \tTrain Acc: 15.27174% \tVal Acc: 19.3478253%\n",
      "Epoch: 44\tTrain Loss: 2.5977821 \tVal Loss:2.5227099 \tTrain Acc: 15.92391% \tVal Acc: 18.4782604%\n",
      "Epoch: 45\tTrain Loss: 2.5809954 \tVal Loss:2.4895145 \tTrain Acc: 17.3913% \tVal Acc: 19.9999999%\n",
      "Epoch: 46\tTrain Loss: 2.5804027 \tVal Loss:2.4412637 \tTrain Acc: 17.6087% \tVal Acc: 20.6521733%\n",
      "Validation Loss decreased from 2.483980 to 2.441264, saving the model weights\n",
      "Epoch: 47\tTrain Loss: 2.5599077 \tVal Loss:2.4190384 \tTrain Acc: 17.71739% \tVal Acc: 21.5217389%\n",
      "Validation Loss decreased from 2.441264 to 2.419038, saving the model weights\n",
      "Epoch: 48\tTrain Loss: 2.5210455 \tVal Loss:2.4055584 \tTrain Acc: 20.70652% \tVal Acc: 18.6956521%\n",
      "Validation Loss decreased from 2.419038 to 2.405558, saving the model weights\n",
      "Epoch: 49\tTrain Loss: 2.5223075 \tVal Loss:2.4105533 \tTrain Acc: 19.8913% \tVal Acc: 18.6956519%\n",
      "Epoch: 50\tTrain Loss: 2.5116749 \tVal Loss:2.4450161 \tTrain Acc: 19.8913% \tVal Acc: 21.0869558%\n",
      "Epoch: 51\tTrain Loss: 2.5108669 \tVal Loss:2.4628535 \tTrain Acc: 20.16304% \tVal Acc: 16.7391302%\n",
      "Epoch: 52\tTrain Loss: 2.4650896 \tVal Loss:2.4631180 \tTrain Acc: 22.3913% \tVal Acc: 20.2173911%\n",
      "Epoch: 53\tTrain Loss: 2.4588905 \tVal Loss:2.5117453 \tTrain Acc: 20.97826% \tVal Acc: 18.2608692%\n",
      "Epoch: 54\tTrain Loss: 2.4518867 \tVal Loss:2.4878185 \tTrain Acc: 22.01087% \tVal Acc: 19.7826084%\n",
      "Epoch: 55\tTrain Loss: 2.5322966 \tVal Loss:2.4532272 \tTrain Acc: 20.76087% \tVal Acc: 20.4347823%\n",
      "Epoch: 56\tTrain Loss: 2.5580958 \tVal Loss:2.5871325 \tTrain Acc: 19.45652% \tVal Acc: 15.0000000%\n",
      "Epoch: 57\tTrain Loss: 2.5052740 \tVal Loss:2.4363451 \tTrain Acc: 19.94565% \tVal Acc: 21.0869562%\n",
      "Epoch: 58\tTrain Loss: 2.5080703 \tVal Loss:2.3412635 \tTrain Acc: 19.8913% \tVal Acc: 19.7826084%\n",
      "Validation Loss decreased from 2.405558 to 2.341263, saving the model weights\n",
      "Epoch: 59\tTrain Loss: 2.5739737 \tVal Loss:2.3826804 \tTrain Acc: 19.02174% \tVal Acc: 21.7391305%\n",
      "Epoch: 60\tTrain Loss: 2.5365593 \tVal Loss:2.4258260 \tTrain Acc: 19.45652% \tVal Acc: 18.9130437%\n",
      "Epoch: 61\tTrain Loss: 2.5174061 \tVal Loss:2.4449641 \tTrain Acc: 19.18478% \tVal Acc: 21.7391305%\n",
      "Epoch: 62\tTrain Loss: 2.4389785 \tVal Loss:2.3003711 \tTrain Acc: 22.44565% \tVal Acc: 24.3478257%\n",
      "Validation Loss decreased from 2.341263 to 2.300371, saving the model weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63\tTrain Loss: 2.3476770 \tVal Loss:2.2510800 \tTrain Acc: 25.21739% \tVal Acc: 24.3478253%\n",
      "Validation Loss decreased from 2.300371 to 2.251080, saving the model weights\n",
      "Epoch: 64\tTrain Loss: 2.3454483 \tVal Loss:2.1930003 \tTrain Acc: 25.70652% \tVal Acc: 26.3043478%\n",
      "Validation Loss decreased from 2.251080 to 2.193000, saving the model weights\n",
      "Epoch: 65\tTrain Loss: 2.2857066 \tVal Loss:2.1675405 \tTrain Acc: 24.83696% \tVal Acc: 29.3478262%\n",
      "Validation Loss decreased from 2.193000 to 2.167540, saving the model weights\n",
      "Epoch: 66\tTrain Loss: 2.2297305 \tVal Loss:2.1673795 \tTrain Acc: 27.66304% \tVal Acc: 28.9130431%\n",
      "Validation Loss decreased from 2.167540 to 2.167379, saving the model weights\n",
      "Epoch: 67\tTrain Loss: 2.2146873 \tVal Loss:2.2100551 \tTrain Acc: 28.6413% \tVal Acc: 27.8260872%\n",
      "Epoch: 68\tTrain Loss: 2.2397944 \tVal Loss:2.1746354 \tTrain Acc: 27.55435% \tVal Acc: 29.3478262%\n",
      "Epoch: 69\tTrain Loss: 2.2216289 \tVal Loss:2.1892306 \tTrain Acc: 28.04348% \tVal Acc: 26.7391298%\n",
      "Epoch: 70\tTrain Loss: 2.2797858 \tVal Loss:2.2064317 \tTrain Acc: 27.17391% \tVal Acc: 30.2173909%\n",
      "Epoch: 71\tTrain Loss: 2.2661778 \tVal Loss:2.2014996 \tTrain Acc: 26.79348% \tVal Acc: 28.0434784%\n",
      "Epoch: 72\tTrain Loss: 2.2563302 \tVal Loss:2.1277536 \tTrain Acc: 27.98913% \tVal Acc: 29.7826078%\n",
      "Validation Loss decreased from 2.167379 to 2.127754, saving the model weights\n",
      "Epoch: 73\tTrain Loss: 2.2026039 \tVal Loss:2.2195033 \tTrain Acc: 28.91304% \tVal Acc: 28.2608692%\n",
      "Epoch: 74\tTrain Loss: 2.1462373 \tVal Loss:2.0653183 \tTrain Acc: 30.48913% \tVal Acc: 31.9565210%\n",
      "Validation Loss decreased from 2.127754 to 2.065318, saving the model weights\n",
      "Epoch: 75\tTrain Loss: 2.0710617 \tVal Loss:1.9919043 \tTrain Acc: 32.44565% \tVal Acc: 33.9130431%\n",
      "Validation Loss decreased from 2.065318 to 1.991904, saving the model weights\n",
      "Epoch: 76\tTrain Loss: 2.0209716 \tVal Loss:1.9624106 \tTrain Acc: 33.31522% \tVal Acc: 35.8695652%\n",
      "Validation Loss decreased from 1.991904 to 1.962411, saving the model weights\n",
      "Epoch: 77\tTrain Loss: 1.9674396 \tVal Loss:1.9512706 \tTrain Acc: 35.76087% \tVal Acc: 35.8695649%\n",
      "Validation Loss decreased from 1.962411 to 1.951271, saving the model weights\n",
      "Epoch: 78\tTrain Loss: 1.9998368 \tVal Loss:1.9685591 \tTrain Acc: 33.42391% \tVal Acc: 39.1304348%\n",
      "Epoch: 79\tTrain Loss: 2.0104806 \tVal Loss:1.9601101 \tTrain Acc: 33.53261% \tVal Acc: 35.6521737%\n",
      "Epoch: 80\tTrain Loss: 1.9622789 \tVal Loss:1.9040891 \tTrain Acc: 35.97826% \tVal Acc: 37.1739123%\n",
      "Validation Loss decreased from 1.951271 to 1.904089, saving the model weights\n",
      "Epoch: 81\tTrain Loss: 1.9304608 \tVal Loss:1.8436769 \tTrain Acc: 35.59783% \tVal Acc: 41.9565208%\n",
      "Validation Loss decreased from 1.904089 to 1.843677, saving the model weights\n",
      "Epoch: 82\tTrain Loss: 1.9270775 \tVal Loss:1.9024335 \tTrain Acc: 37.77174% \tVal Acc: 36.7391307%\n",
      "Epoch: 83\tTrain Loss: 1.9324578 \tVal Loss:1.9044222 \tTrain Acc: 35.38043% \tVal Acc: 38.0434774%\n",
      "Epoch: 84\tTrain Loss: 1.9757582 \tVal Loss:1.8511353 \tTrain Acc: 34.94565% \tVal Acc: 37.8260870%\n",
      "Epoch: 85\tTrain Loss: 1.8873770 \tVal Loss:1.8812179 \tTrain Acc: 38.91304% \tVal Acc: 37.3913046%\n",
      "Epoch: 86\tTrain Loss: 1.8778750 \tVal Loss:1.8632692 \tTrain Acc: 38.91304% \tVal Acc: 37.6086950%\n",
      "Epoch: 87\tTrain Loss: 1.8496333 \tVal Loss:1.9282623 \tTrain Acc: 38.26087% \tVal Acc: 34.7826075%\n",
      "Epoch: 88\tTrain Loss: 1.8686550 \tVal Loss:1.7800214 \tTrain Acc: 37.77174% \tVal Acc: 38.9130425%\n",
      "Validation Loss decreased from 1.843677 to 1.780021, saving the model weights\n",
      "Epoch: 89\tTrain Loss: 1.7480744 \tVal Loss:1.8084669 \tTrain Acc: 42.11956% \tVal Acc: 40.2173907%\n",
      "Epoch: 90\tTrain Loss: 1.7443790 \tVal Loss:1.7437414 \tTrain Acc: 42.11957% \tVal Acc: 43.9130429%\n",
      "Validation Loss decreased from 1.780021 to 1.743741, saving the model weights\n",
      "Epoch: 91\tTrain Loss: 1.7160781 \tVal Loss:1.6848245 \tTrain Acc: 42.11956% \tVal Acc: 45.4347823%\n",
      "Validation Loss decreased from 1.743741 to 1.684825, saving the model weights\n",
      "Epoch: 92\tTrain Loss: 1.6455320 \tVal Loss:1.6963194 \tTrain Acc: 44.51087% \tVal Acc: 45.4347819%\n",
      "Epoch: 93\tTrain Loss: 1.5990026 \tVal Loss:1.6370207 \tTrain Acc: 47.66304% \tVal Acc: 46.0869558%\n",
      "Validation Loss decreased from 1.684825 to 1.637021, saving the model weights\n",
      "Epoch: 94\tTrain Loss: 1.5429813 \tVal Loss:1.6780702 \tTrain Acc: 47.28261% \tVal Acc: 47.8260860%\n",
      "Epoch: 95\tTrain Loss: 1.5904984 \tVal Loss:1.6145593 \tTrain Acc: 46.95652% \tVal Acc: 48.6956522%\n",
      "Validation Loss decreased from 1.637021 to 1.614559, saving the model weights\n",
      "Epoch: 96\tTrain Loss: 1.5937894 \tVal Loss:1.6440772 \tTrain Acc: 47.06522% \tVal Acc: 43.6956525%\n",
      "Epoch: 97\tTrain Loss: 1.6736063 \tVal Loss:1.6626880 \tTrain Acc: 43.31522% \tVal Acc: 49.7826077%\n",
      "Epoch: 98\tTrain Loss: 1.6692344 \tVal Loss:1.6220154 \tTrain Acc: 43.85869% \tVal Acc: 48.6956514%\n",
      "Epoch: 99\tTrain Loss: 1.5648272 \tVal Loss:1.7150508 \tTrain Acc: 47.3913% \tVal Acc: 42.1739124%\n",
      "Epoch: 100\tTrain Loss: 1.5046732 \tVal Loss:1.7450394 \tTrain Acc: 49.29348% \tVal Acc: 45.8695643%\n",
      "Epoch: 101\tTrain Loss: 1.5021100 \tVal Loss:1.5688494 \tTrain Acc: 50.1087% \tVal Acc: 49.5652169%\n",
      "Validation Loss decreased from 1.614559 to 1.568849, saving the model weights\n",
      "Epoch: 102\tTrain Loss: 1.4223413 \tVal Loss:1.6573355 \tTrain Acc: 51.52174% \tVal Acc: 43.9130425%\n",
      "Epoch: 103\tTrain Loss: 1.4796932 \tVal Loss:1.6377580 \tTrain Acc: 50.43478% \tVal Acc: 43.4782602%\n",
      "Epoch: 104\tTrain Loss: 1.4745995 \tVal Loss:1.5595858 \tTrain Acc: 49.56522% \tVal Acc: 46.9565213%\n",
      "Validation Loss decreased from 1.568849 to 1.559586, saving the model weights\n",
      "Epoch: 105\tTrain Loss: 1.4848591 \tVal Loss:1.5506784 \tTrain Acc: 49.13043% \tVal Acc: 49.7826084%\n",
      "Validation Loss decreased from 1.559586 to 1.550678, saving the model weights\n",
      "Epoch: 106\tTrain Loss: 1.5019957 \tVal Loss:1.5859006 \tTrain Acc: 49.07609% \tVal Acc: 49.1304338%\n",
      "Epoch: 107\tTrain Loss: 1.5315654 \tVal Loss:1.5069794 \tTrain Acc: 47.98913% \tVal Acc: 52.6086949%\n",
      "Validation Loss decreased from 1.550678 to 1.506979, saving the model weights\n",
      "Epoch: 108\tTrain Loss: 1.5181903 \tVal Loss:1.5100617 \tTrain Acc: 49.51087% \tVal Acc: 51.9565210%\n",
      "Epoch: 109\tTrain Loss: 1.5755091 \tVal Loss:1.6658455 \tTrain Acc: 48.31522% \tVal Acc: 45.6521742%\n",
      "Epoch: 110\tTrain Loss: 1.4948889 \tVal Loss:1.5376651 \tTrain Acc: 49.13043% \tVal Acc: 47.3913036%\n",
      "Epoch: 111\tTrain Loss: 1.4080419 \tVal Loss:1.4070532 \tTrain Acc: 49.78261% \tVal Acc: 52.8260864%\n",
      "Validation Loss decreased from 1.506979 to 1.407053, saving the model weights\n",
      "Epoch: 112\tTrain Loss: 1.2870772 \tVal Loss:1.4501506 \tTrain Acc: 55.97826% \tVal Acc: 50.4347824%\n",
      "Epoch: 113\tTrain Loss: 1.2460904 \tVal Loss:1.2793807 \tTrain Acc: 57.66304% \tVal Acc: 57.8260876%\n",
      "Validation Loss decreased from 1.407053 to 1.279381, saving the model weights\n",
      "Epoch: 114\tTrain Loss: 1.1799431 \tVal Loss:1.2901541 \tTrain Acc: 59.40217% \tVal Acc: 61.5217395%\n",
      "Epoch: 115\tTrain Loss: 1.1458115 \tVal Loss:1.2533980 \tTrain Acc: 58.8587% \tVal Acc: 59.3478255%\n",
      "Validation Loss decreased from 1.279381 to 1.253398, saving the model weights\n",
      "Epoch: 116\tTrain Loss: 1.0985587 \tVal Loss:1.2416323 \tTrain Acc: 60.32609% \tVal Acc: 60.6521748%\n",
      "Validation Loss decreased from 1.253398 to 1.241632, saving the model weights\n",
      "Epoch: 117\tTrain Loss: 1.0922551 \tVal Loss:1.2242262 \tTrain Acc: 61.3587% \tVal Acc: 63.6956520%\n",
      "Validation Loss decreased from 1.241632 to 1.224226, saving the model weights\n",
      "Epoch: 118\tTrain Loss: 1.0850733 \tVal Loss:1.2333874 \tTrain Acc: 63.20652% \tVal Acc: 60.8695641%\n",
      "Epoch: 119\tTrain Loss: 1.0670247 \tVal Loss:1.1932042 \tTrain Acc: 62.77174% \tVal Acc: 64.1304344%\n",
      "Validation Loss decreased from 1.224226 to 1.193204, saving the model weights\n",
      "Epoch: 120\tTrain Loss: 1.0147254 \tVal Loss:1.1687356 \tTrain Acc: 63.91304% \tVal Acc: 63.4782605%\n",
      "Validation Loss decreased from 1.193204 to 1.168736, saving the model weights\n",
      "Epoch: 121\tTrain Loss: 1.0036512 \tVal Loss:1.2609962 \tTrain Acc: 63.91304% \tVal Acc: 63.4782590%\n",
      "Epoch: 122\tTrain Loss: 0.9825398 \tVal Loss:1.1262449 \tTrain Acc: 65.76087% \tVal Acc: 63.9130428%\n",
      "Validation Loss decreased from 1.168736 to 1.126245, saving the model weights\n",
      "Epoch: 123\tTrain Loss: 0.9623162 \tVal Loss:1.1096760 \tTrain Acc: 66.08696% \tVal Acc: 65.4347830%\n",
      "Validation Loss decreased from 1.126245 to 1.109676, saving the model weights\n",
      "Epoch: 124\tTrain Loss: 0.9277042 \tVal Loss:1.1694320 \tTrain Acc: 68.6413% \tVal Acc: 61.7391303%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 125\tTrain Loss: 0.9594826 \tVal Loss:1.1261375 \tTrain Acc: 66.25% \tVal Acc: 63.9130443%\n",
      "Epoch: 126\tTrain Loss: 0.9845151 \tVal Loss:1.1035088 \tTrain Acc: 65.16304% \tVal Acc: 65.4347822%\n",
      "Validation Loss decreased from 1.109676 to 1.103509, saving the model weights\n",
      "Epoch: 127\tTrain Loss: 0.9484455 \tVal Loss:1.0867271 \tTrain Acc: 65.97826% \tVal Acc: 65.0000013%\n",
      "Validation Loss decreased from 1.103509 to 1.086727, saving the model weights\n",
      "Epoch: 128\tTrain Loss: 1.0787035 \tVal Loss:1.2981853 \tTrain Acc: 62.3913% \tVal Acc: 58.4782600%\n",
      "Epoch: 129\tTrain Loss: 1.1985149 \tVal Loss:1.1792511 \tTrain Acc: 58.47826% \tVal Acc: 59.1304354%\n",
      "Epoch: 130\tTrain Loss: 1.2207013 \tVal Loss:1.2850288 \tTrain Acc: 57.88043% \tVal Acc: 57.1739115%\n",
      "Epoch: 131\tTrain Loss: 1.0913315 \tVal Loss:1.0721450 \tTrain Acc: 62.22826% \tVal Acc: 65.2173921%\n",
      "Validation Loss decreased from 1.086727 to 1.072145, saving the model weights\n",
      "Epoch: 132\tTrain Loss: 0.9972819 \tVal Loss:1.0782611 \tTrain Acc: 65.32609% \tVal Acc: 67.6086947%\n",
      "Epoch: 133\tTrain Loss: 0.9202253 \tVal Loss:0.9509142 \tTrain Acc: 68.69565% \tVal Acc: 71.0869551%\n",
      "Validation Loss decreased from 1.072145 to 0.950914, saving the model weights\n",
      "Epoch: 134\tTrain Loss: 0.8501804 \tVal Loss:0.9860680 \tTrain Acc: 69.34783% \tVal Acc: 64.3478259%\n",
      "Epoch: 135\tTrain Loss: 0.8136316 \tVal Loss:0.9000571 \tTrain Acc: 72.06522% \tVal Acc: 71.3043481%\n",
      "Validation Loss decreased from 0.950914 to 0.900057, saving the model weights\n",
      "Epoch: 136\tTrain Loss: 0.8002763 \tVal Loss:0.9956304 \tTrain Acc: 72.3913% \tVal Acc: 70.8695635%\n",
      "Epoch: 137\tTrain Loss: 0.7969225 \tVal Loss:0.8805950 \tTrain Acc: 71.3587% \tVal Acc: 73.0434783%\n",
      "Validation Loss decreased from 0.900057 to 0.880595, saving the model weights\n",
      "Epoch: 138\tTrain Loss: 0.7886851 \tVal Loss:0.9148419 \tTrain Acc: 72.98913% \tVal Acc: 63.9130436%\n",
      "Epoch: 139\tTrain Loss: 0.7852491 \tVal Loss:0.9056248 \tTrain Acc: 71.79348% \tVal Acc: 72.3913051%\n",
      "Epoch: 140\tTrain Loss: 0.7886539 \tVal Loss:1.0370017 \tTrain Acc: 73.36956% \tVal Acc: 67.3913047%\n",
      "Epoch: 141\tTrain Loss: 0.7677042 \tVal Loss:0.8853382 \tTrain Acc: 72.71739% \tVal Acc: 74.3478253%\n",
      "Epoch: 142\tTrain Loss: 0.7697268 \tVal Loss:0.8995369 \tTrain Acc: 72.77174% \tVal Acc: 69.1304341%\n",
      "Epoch: 143\tTrain Loss: 0.7603029 \tVal Loss:0.9299845 \tTrain Acc: 72.55435% \tVal Acc: 73.4782606%\n",
      "Epoch: 144\tTrain Loss: 0.7097527 \tVal Loss:0.9002961 \tTrain Acc: 75.0% \tVal Acc: 74.3478268%\n",
      "Epoch: 145\tTrain Loss: 0.7094728 \tVal Loss:0.8449515 \tTrain Acc: 75.16304% \tVal Acc: 71.3043481%\n",
      "Validation Loss decreased from 0.880595 to 0.844951, saving the model weights\n",
      "Epoch: 146\tTrain Loss: 0.6533556 \tVal Loss:0.8326079 \tTrain Acc: 77.28261% \tVal Acc: 74.9999993%\n",
      "Validation Loss decreased from 0.844951 to 0.832608, saving the model weights\n",
      "Epoch: 147\tTrain Loss: 0.6429858 \tVal Loss:0.9151482 \tTrain Acc: 78.47826% \tVal Acc: 75.6521739%\n",
      "Epoch: 148\tTrain Loss: 0.6347303 \tVal Loss:0.7391123 \tTrain Acc: 78.26087% \tVal Acc: 77.8260857%\n",
      "Validation Loss decreased from 0.832608 to 0.739112, saving the model weights\n",
      "Epoch: 149\tTrain Loss: 0.6240318 \tVal Loss:0.8997858 \tTrain Acc: 78.6413% \tVal Acc: 74.7826084%\n",
      "Epoch: 150\tTrain Loss: 0.6298316 \tVal Loss:0.8720463 \tTrain Acc: 78.31522% \tVal Acc: 76.3043478%\n",
      "Epoch: 151\tTrain Loss: 0.6275829 \tVal Loss:0.7326315 \tTrain Acc: 80.43478% \tVal Acc: 78.2608703%\n",
      "Validation Loss decreased from 0.739112 to 0.732631, saving the model weights\n",
      "Epoch: 152\tTrain Loss: 0.5550751 \tVal Loss:0.8003005 \tTrain Acc: 81.57609% \tVal Acc: 77.1739125%\n",
      "Epoch: 153\tTrain Loss: 0.5937606 \tVal Loss:0.8350592 \tTrain Acc: 80.05435% \tVal Acc: 76.7391302%\n",
      "Epoch: 154\tTrain Loss: 0.5824766 \tVal Loss:0.8802093 \tTrain Acc: 80.70652% \tVal Acc: 73.6956522%\n",
      "Epoch: 155\tTrain Loss: 0.6054705 \tVal Loss:0.8912770 \tTrain Acc: 79.83696% \tVal Acc: 75.2173908%\n",
      "Epoch: 156\tTrain Loss: 0.6126653 \tVal Loss:0.7857441 \tTrain Acc: 79.18478% \tVal Acc: 78.6956519%\n",
      "Epoch: 157\tTrain Loss: 0.5782782 \tVal Loss:0.8910697 \tTrain Acc: 80.48913% \tVal Acc: 73.2608698%\n",
      "Epoch: 158\tTrain Loss: 0.6086716 \tVal Loss:0.8138863 \tTrain Acc: 79.67391% \tVal Acc: 77.6086956%\n",
      "Epoch: 159\tTrain Loss: 0.6324979 \tVal Loss:1.0514009 \tTrain Acc: 77.55435% \tVal Acc: 66.5217392%\n",
      "Epoch: 160\tTrain Loss: 0.6995486 \tVal Loss:0.9373791 \tTrain Acc: 76.19565% \tVal Acc: 74.3478253%\n",
      "Epoch: 161\tTrain Loss: 0.6537514 \tVal Loss:0.7504368 \tTrain Acc: 77.66304% \tVal Acc: 78.6956504%\n",
      "Epoch: 162\tTrain Loss: 0.7364989 \tVal Loss:0.9805947 \tTrain Acc: 76.73913% \tVal Acc: 68.0434786%\n",
      "Epoch: 163\tTrain Loss: 0.6969826 \tVal Loss:0.8489911 \tTrain Acc: 75.59783% \tVal Acc: 71.7391305%\n",
      "Epoch: 164\tTrain Loss: 0.7127941 \tVal Loss:0.8480914 \tTrain Acc: 75.32609% \tVal Acc: 71.7391297%\n",
      "Epoch: 165\tTrain Loss: 0.6409001 \tVal Loss:0.7993802 \tTrain Acc: 77.3913% \tVal Acc: 77.6086949%\n",
      "Epoch: 166\tTrain Loss: 0.6551173 \tVal Loss:0.7486670 \tTrain Acc: 76.68478% \tVal Acc: 77.6086956%\n",
      "Epoch: 167\tTrain Loss: 0.6238021 \tVal Loss:0.6731747 \tTrain Acc: 78.75% \tVal Acc: 77.1739140%\n",
      "Validation Loss decreased from 0.732631 to 0.673175, saving the model weights\n",
      "Epoch: 168\tTrain Loss: 0.6091747 \tVal Loss:0.7677381 \tTrain Acc: 79.18478% \tVal Acc: 78.2608703%\n",
      "Epoch: 169\tTrain Loss: 0.5422958 \tVal Loss:0.6039971 \tTrain Acc: 81.52174% \tVal Acc: 82.8260869%\n",
      "Validation Loss decreased from 0.673175 to 0.603997, saving the model weights\n",
      "Epoch: 170\tTrain Loss: 0.4926056 \tVal Loss:0.5265718 \tTrain Acc: 84.23913% \tVal Acc: 87.1739104%\n",
      "Validation Loss decreased from 0.603997 to 0.526572, saving the model weights\n",
      "Epoch: 171\tTrain Loss: 0.4477103 \tVal Loss:0.6298366 \tTrain Acc: 85.05435% \tVal Acc: 83.0434784%\n",
      "Epoch: 172\tTrain Loss: 0.4304240 \tVal Loss:0.5149857 \tTrain Acc: 87.01087% \tVal Acc: 87.3913035%\n",
      "Validation Loss decreased from 0.526572 to 0.514986, saving the model weights\n",
      "Epoch: 173\tTrain Loss: 0.4115948 \tVal Loss:0.5502096 \tTrain Acc: 86.46739% \tVal Acc: 86.3043457%\n",
      "Epoch: 174\tTrain Loss: 0.3975028 \tVal Loss:0.5596801 \tTrain Acc: 86.84782% \tVal Acc: 84.3478262%\n",
      "Epoch: 175\tTrain Loss: 0.3794060 \tVal Loss:0.5517599 \tTrain Acc: 88.75% \tVal Acc: 86.0869557%\n",
      "Epoch: 176\tTrain Loss: 0.3597974 \tVal Loss:0.5149429 \tTrain Acc: 89.02174% \tVal Acc: 85.8695656%\n",
      "Validation Loss decreased from 0.514986 to 0.514943, saving the model weights\n",
      "Epoch: 177\tTrain Loss: 0.3560518 \tVal Loss:0.4953195 \tTrain Acc: 89.02174% \tVal Acc: 86.9565219%\n",
      "Validation Loss decreased from 0.514943 to 0.495320, saving the model weights\n",
      "Epoch: 178\tTrain Loss: 0.3693830 \tVal Loss:0.5295920 \tTrain Acc: 88.47826% \tVal Acc: 86.5217388%\n",
      "Epoch: 179\tTrain Loss: 0.3165119 \tVal Loss:0.5410756 \tTrain Acc: 90.76087% \tVal Acc: 85.4347825%\n",
      "Epoch: 180\tTrain Loss: 0.3351949 \tVal Loss:0.5478253 \tTrain Acc: 89.34783% \tVal Acc: 84.5652178%\n",
      "Epoch: 181\tTrain Loss: 0.3219497 \tVal Loss:0.4435319 \tTrain Acc: 90.65217% \tVal Acc: 87.6086935%\n",
      "Validation Loss decreased from 0.495320 to 0.443532, saving the model weights\n",
      "Epoch: 182\tTrain Loss: 0.3587189 \tVal Loss:0.6309248 \tTrain Acc: 88.09783% \tVal Acc: 83.0434769%\n",
      "Epoch: 183\tTrain Loss: 0.3270164 \tVal Loss:0.4200067 \tTrain Acc: 90.38043% \tVal Acc: 88.2608697%\n",
      "Validation Loss decreased from 0.443532 to 0.420007, saving the model weights\n",
      "Epoch: 184\tTrain Loss: 0.3298500 \tVal Loss:0.4445118 \tTrain Acc: 89.8913% \tVal Acc: 87.3913035%\n",
      "Epoch: 185\tTrain Loss: 0.3022322 \tVal Loss:0.5503489 \tTrain Acc: 91.19565% \tVal Acc: 86.9565219%\n",
      "Epoch: 186\tTrain Loss: 0.3191513 \tVal Loss:0.4836178 \tTrain Acc: 91.30435% \tVal Acc: 86.7391288%\n",
      "Epoch: 187\tTrain Loss: 0.2987143 \tVal Loss:0.6088647 \tTrain Acc: 90.81522% \tVal Acc: 83.6956531%\n",
      "Epoch: 188\tTrain Loss: 0.2913589 \tVal Loss:0.5338631 \tTrain Acc: 91.41304% \tVal Acc: 85.8695656%\n",
      "Epoch: 189\tTrain Loss: 0.2892398 \tVal Loss:0.4095203 \tTrain Acc: 91.90217% \tVal Acc: 88.2608682%\n",
      "Validation Loss decreased from 0.420007 to 0.409520, saving the model weights\n",
      "Epoch: 190\tTrain Loss: 0.2900300 \tVal Loss:0.6134914 \tTrain Acc: 91.35869% \tVal Acc: 83.0434799%\n",
      "Epoch: 191\tTrain Loss: 0.2934508 \tVal Loss:0.5875435 \tTrain Acc: 91.19565% \tVal Acc: 83.9130446%\n",
      "Epoch: 192\tTrain Loss: 0.2900908 \tVal Loss:0.5359041 \tTrain Acc: 91.46739% \tVal Acc: 87.1739134%\n",
      "Epoch: 193\tTrain Loss: 0.2756635 \tVal Loss:0.5528050 \tTrain Acc: 91.3587% \tVal Acc: 85.8695656%\n",
      "Epoch: 194\tTrain Loss: 0.2726307 \tVal Loss:0.5197932 \tTrain Acc: 91.90217% \tVal Acc: 85.4347840%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 195\tTrain Loss: 0.2660764 \tVal Loss:0.5547398 \tTrain Acc: 91.79348% \tVal Acc: 85.2173924%\n",
      "Epoch: 196\tTrain Loss: 0.2624017 \tVal Loss:0.4267513 \tTrain Acc: 92.71739% \tVal Acc: 88.2608697%\n",
      "Epoch: 197\tTrain Loss: 0.2535840 \tVal Loss:0.4352483 \tTrain Acc: 92.60869% \tVal Acc: 87.1739119%\n",
      "Epoch: 198\tTrain Loss: 0.2476774 \tVal Loss:0.4754654 \tTrain Acc: 92.66304% \tVal Acc: 87.6086950%\n",
      "Epoch: 199\tTrain Loss: 0.2364490 \tVal Loss:0.4444946 \tTrain Acc: 93.09783% \tVal Acc: 87.3913035%\n",
      "Epoch: 200\tTrain Loss: 0.2783713 \tVal Loss:0.4555673 \tTrain Acc: 90.70652% \tVal Acc: 86.0869557%\n",
      "Epoch: 201\tTrain Loss: 0.2761138 \tVal Loss:0.6352103 \tTrain Acc: 91.46739% \tVal Acc: 82.3913053%\n",
      "Epoch: 202\tTrain Loss: 0.3056866 \tVal Loss:0.5869964 \tTrain Acc: 90.0% \tVal Acc: 84.3478262%\n",
      "Epoch: 203\tTrain Loss: 0.3187260 \tVal Loss:0.4505945 \tTrain Acc: 89.83696% \tVal Acc: 88.4782612%\n",
      "Epoch: 204\tTrain Loss: 0.2914323 \tVal Loss:0.5617566 \tTrain Acc: 90.92391% \tVal Acc: 84.7826093%\n",
      "Epoch: 205\tTrain Loss: 0.2788032 \tVal Loss:0.5131434 \tTrain Acc: 92.5% \tVal Acc: 86.0869572%\n",
      "Epoch: 206\tTrain Loss: 0.2641959 \tVal Loss:0.4596281 \tTrain Acc: 91.90217% \tVal Acc: 88.6956513%\n",
      "Epoch: 207\tTrain Loss: 0.2426018 \tVal Loss:0.4426902 \tTrain Acc: 93.26087% \tVal Acc: 88.4782612%\n",
      "Epoch: 208\tTrain Loss: 0.2369787 \tVal Loss:0.4617123 \tTrain Acc: 92.93478% \tVal Acc: 87.8260866%\n",
      "Epoch: 209\tTrain Loss: 0.2065955 \tVal Loss:0.3810325 \tTrain Acc: 94.8913% \tVal Acc: 88.6956498%\n",
      "Validation Loss decreased from 0.409520 to 0.381033, saving the model weights\n",
      "Epoch: 210\tTrain Loss: 0.1942672 \tVal Loss:0.4452313 \tTrain Acc: 94.61956% \tVal Acc: 88.9130428%\n",
      "Epoch: 211\tTrain Loss: 0.1838711 \tVal Loss:0.4506545 \tTrain Acc: 95.05435% \tVal Acc: 88.2608697%\n",
      "Epoch: 212\tTrain Loss: 0.1924588 \tVal Loss:0.4383703 \tTrain Acc: 94.67391% \tVal Acc: 88.2608697%\n",
      "Epoch: 213\tTrain Loss: 0.1846962 \tVal Loss:0.4479072 \tTrain Acc: 95.0% \tVal Acc: 87.8260851%\n",
      "Epoch: 214\tTrain Loss: 0.1905393 \tVal Loss:0.4469249 \tTrain Acc: 95.1087% \tVal Acc: 88.9130443%\n",
      "Epoch: 215\tTrain Loss: 0.1806370 \tVal Loss:0.3937564 \tTrain Acc: 94.67391% \tVal Acc: 89.1304344%\n",
      "Epoch: 216\tTrain Loss: 0.1834416 \tVal Loss:0.4563163 \tTrain Acc: 94.78261% \tVal Acc: 86.0869572%\n",
      "Epoch: 217\tTrain Loss: 0.2013822 \tVal Loss:0.4804465 \tTrain Acc: 94.07609% \tVal Acc: 86.0869557%\n",
      "Epoch: 218\tTrain Loss: 0.1998693 \tVal Loss:0.6107432 \tTrain Acc: 94.02174% \tVal Acc: 82.3913053%\n",
      "Epoch: 219\tTrain Loss: 0.2039963 \tVal Loss:0.5630561 \tTrain Acc: 93.75% \tVal Acc: 86.0869557%\n",
      "Epoch: 220\tTrain Loss: 0.2202357 \tVal Loss:0.3479943 \tTrain Acc: 92.93478% \tVal Acc: 89.1304329%\n",
      "Validation Loss decreased from 0.381033 to 0.347994, saving the model weights\n",
      "Epoch: 221\tTrain Loss: 0.2190298 \tVal Loss:0.3868637 \tTrain Acc: 92.88043% \tVal Acc: 87.3913035%\n",
      "Epoch: 222\tTrain Loss: 0.2474339 \tVal Loss:0.6412501 \tTrain Acc: 92.6087% \tVal Acc: 82.8260869%\n",
      "Epoch: 223\tTrain Loss: 0.2776625 \tVal Loss:0.5566209 \tTrain Acc: 90.54348% \tVal Acc: 84.1304347%\n",
      "Epoch: 224\tTrain Loss: 0.3461519 \tVal Loss:0.5962759 \tTrain Acc: 88.96739% \tVal Acc: 84.5652178%\n",
      "Epoch: 225\tTrain Loss: 0.3507497 \tVal Loss:0.6384388 \tTrain Acc: 88.04348% \tVal Acc: 81.5217391%\n",
      "Epoch: 226\tTrain Loss: 0.3961165 \tVal Loss:0.9069163 \tTrain Acc: 87.33696% \tVal Acc: 72.3913044%\n",
      "Epoch: 227\tTrain Loss: 0.3911491 \tVal Loss:0.4267864 \tTrain Acc: 86.90217% \tVal Acc: 87.3913035%\n",
      "Epoch: 228\tTrain Loss: 0.3926537 \tVal Loss:0.5216733 \tTrain Acc: 86.63043% \tVal Acc: 85.6521741%\n",
      "Epoch: 229\tTrain Loss: 0.3662613 \tVal Loss:0.6066659 \tTrain Acc: 88.96739% \tVal Acc: 85.2173924%\n",
      "Epoch: 230\tTrain Loss: 0.2956263 \tVal Loss:0.3694629 \tTrain Acc: 90.0% \tVal Acc: 91.7391315%\n",
      "Epoch: 231\tTrain Loss: 0.2966648 \tVal Loss:0.3579307 \tTrain Acc: 91.52174% \tVal Acc: 91.9565216%\n",
      "Epoch: 232\tTrain Loss: 0.2668346 \tVal Loss:0.5216104 \tTrain Acc: 92.17391% \tVal Acc: 85.6521741%\n",
      "Epoch: 233\tTrain Loss: 0.2790942 \tVal Loss:0.4260600 \tTrain Acc: 91.79348% \tVal Acc: 89.3478259%\n",
      "Epoch: 234\tTrain Loss: 0.2333151 \tVal Loss:0.3358397 \tTrain Acc: 93.26087% \tVal Acc: 90.6521738%\n",
      "Validation Loss decreased from 0.347994 to 0.335840, saving the model weights\n",
      "Epoch: 235\tTrain Loss: 0.1968058 \tVal Loss:0.3786589 \tTrain Acc: 94.13043% \tVal Acc: 89.9999991%\n",
      "Epoch: 236\tTrain Loss: 0.1731796 \tVal Loss:0.3535710 \tTrain Acc: 95.54348% \tVal Acc: 90.8695653%\n",
      "Epoch: 237\tTrain Loss: 0.1594598 \tVal Loss:0.3131536 \tTrain Acc: 95.92391% \tVal Acc: 91.5217400%\n",
      "Validation Loss decreased from 0.335840 to 0.313154, saving the model weights\n",
      "Epoch: 238\tTrain Loss: 0.1422415 \tVal Loss:0.3692962 \tTrain Acc: 96.30435% \tVal Acc: 91.0869554%\n",
      "Epoch: 239\tTrain Loss: 0.1429644 \tVal Loss:0.3553746 \tTrain Acc: 96.57609% \tVal Acc: 89.9999991%\n",
      "Epoch: 240\tTrain Loss: 0.1308173 \tVal Loss:0.2981031 \tTrain Acc: 96.63043% \tVal Acc: 91.3043484%\n",
      "Validation Loss decreased from 0.313154 to 0.298103, saving the model weights\n",
      "Epoch: 241\tTrain Loss: 0.1270349 \tVal Loss:0.3292387 \tTrain Acc: 97.28261% \tVal Acc: 91.0869569%\n",
      "Epoch: 242\tTrain Loss: 0.1214887 \tVal Loss:0.3348410 \tTrain Acc: 97.3913% \tVal Acc: 91.3043484%\n",
      "Epoch: 243\tTrain Loss: 0.1211473 \tVal Loss:0.2949291 \tTrain Acc: 97.11956% \tVal Acc: 91.5217400%\n",
      "Validation Loss decreased from 0.298103 to 0.294929, saving the model weights\n",
      "Epoch: 244\tTrain Loss: 0.1083295 \tVal Loss:0.2831588 \tTrain Acc: 97.82609% \tVal Acc: 91.9565216%\n",
      "Validation Loss decreased from 0.294929 to 0.283159, saving the model weights\n",
      "Epoch: 245\tTrain Loss: 0.1164212 \tVal Loss:0.3062447 \tTrain Acc: 97.01087% \tVal Acc: 90.6521738%\n",
      "Epoch: 246\tTrain Loss: 0.1047890 \tVal Loss:0.3070336 \tTrain Acc: 97.93478% \tVal Acc: 91.5217400%\n",
      "Epoch: 247\tTrain Loss: 0.0996839 \tVal Loss:0.3637423 \tTrain Acc: 97.98913% \tVal Acc: 90.4347822%\n",
      "Epoch: 248\tTrain Loss: 0.1007401 \tVal Loss:0.3024245 \tTrain Acc: 97.82609% \tVal Acc: 90.2173907%\n",
      "Epoch: 249\tTrain Loss: 0.1019606 \tVal Loss:0.3233741 \tTrain Acc: 97.5% \tVal Acc: 89.9999991%\n",
      "Epoch: 250\tTrain Loss: 0.0975020 \tVal Loss:0.3499882 \tTrain Acc: 97.88043% \tVal Acc: 89.7826090%\n",
      "Epoch: 251\tTrain Loss: 0.0933149 \tVal Loss:0.3189923 \tTrain Acc: 98.04348% \tVal Acc: 90.6521738%\n",
      "Epoch: 252\tTrain Loss: 0.0960618 \tVal Loss:0.4034868 \tTrain Acc: 97.93478% \tVal Acc: 88.4782597%\n",
      "Epoch: 253\tTrain Loss: 0.0927800 \tVal Loss:0.3743780 \tTrain Acc: 98.15217% \tVal Acc: 90.4347822%\n",
      "Epoch: 254\tTrain Loss: 0.0964764 \tVal Loss:0.3224042 \tTrain Acc: 97.88043% \tVal Acc: 91.0869569%\n",
      "Epoch: 255\tTrain Loss: 0.1078325 \tVal Loss:0.2885388 \tTrain Acc: 97.71739% \tVal Acc: 90.4347822%\n",
      "Epoch: 256\tTrain Loss: 0.1213507 \tVal Loss:0.3301377 \tTrain Acc: 96.84783% \tVal Acc: 90.4347822%\n",
      "Epoch: 257\tTrain Loss: 0.1121002 \tVal Loss:0.4029721 \tTrain Acc: 96.79348% \tVal Acc: 89.3478259%\n",
      "Epoch: 258\tTrain Loss: 0.1038978 \tVal Loss:0.3101031 \tTrain Acc: 97.60869% \tVal Acc: 90.8695653%\n",
      "Epoch: 259\tTrain Loss: 0.0981992 \tVal Loss:0.3630375 \tTrain Acc: 97.71739% \tVal Acc: 89.9999991%\n",
      "Epoch: 260\tTrain Loss: 0.0948206 \tVal Loss:0.3506549 \tTrain Acc: 97.5% \tVal Acc: 91.0869569%\n",
      "Epoch: 261\tTrain Loss: 0.0909257 \tVal Loss:0.3577334 \tTrain Acc: 97.71739% \tVal Acc: 91.3043484%\n",
      "Epoch: 262\tTrain Loss: 0.0839903 \tVal Loss:0.4089973 \tTrain Acc: 98.15217% \tVal Acc: 90.0000006%\n",
      "Epoch: 263\tTrain Loss: 0.0857412 \tVal Loss:0.2534324 \tTrain Acc: 98.15217% \tVal Acc: 92.1739116%\n",
      "Validation Loss decreased from 0.283159 to 0.253432, saving the model weights\n",
      "Epoch: 264\tTrain Loss: 0.0853790 \tVal Loss:0.2476147 \tTrain Acc: 98.09783% \tVal Acc: 92.1739131%\n",
      "Validation Loss decreased from 0.253432 to 0.247615, saving the model weights\n",
      "Epoch: 265\tTrain Loss: 0.0755835 \tVal Loss:0.2717429 \tTrain Acc: 98.36956% \tVal Acc: 91.0869569%\n",
      "Epoch: 266\tTrain Loss: 0.0931719 \tVal Loss:0.2947530 \tTrain Acc: 97.93478% \tVal Acc: 89.9999991%\n",
      "Epoch: 267\tTrain Loss: 0.0906216 \tVal Loss:0.3062095 \tTrain Acc: 98.04348% \tVal Acc: 90.2173907%\n",
      "Epoch: 268\tTrain Loss: 0.0791193 \tVal Loss:0.3061341 \tTrain Acc: 98.09783% \tVal Acc: 91.7391300%\n",
      "Epoch: 269\tTrain Loss: 0.0819722 \tVal Loss:0.3391486 \tTrain Acc: 98.09783% \tVal Acc: 89.7826076%\n",
      "Epoch: 270\tTrain Loss: 0.0907302 \tVal Loss:0.3737762 \tTrain Acc: 98.20652% \tVal Acc: 89.3478259%\n",
      "Epoch: 271\tTrain Loss: 0.0921867 \tVal Loss:0.2535876 \tTrain Acc: 97.77174% \tVal Acc: 92.6086962%\n",
      "Epoch: 272\tTrain Loss: 0.0966936 \tVal Loss:0.3430370 \tTrain Acc: 97.44565% \tVal Acc: 89.7826076%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 273\tTrain Loss: 0.1208166 \tVal Loss:0.2269965 \tTrain Acc: 96.90217% \tVal Acc: 92.8260848%\n",
      "Validation Loss decreased from 0.247615 to 0.226996, saving the model weights\n",
      "Epoch: 274\tTrain Loss: 0.1130716 \tVal Loss:0.3115350 \tTrain Acc: 97.17391% \tVal Acc: 90.0000006%\n",
      "Epoch: 275\tTrain Loss: 0.1246133 \tVal Loss:0.4842424 \tTrain Acc: 95.92391% \tVal Acc: 85.4347825%\n",
      "Epoch: 276\tTrain Loss: 0.1345046 \tVal Loss:0.2880213 \tTrain Acc: 95.92391% \tVal Acc: 90.8695653%\n",
      "Epoch: 277\tTrain Loss: 0.1411939 \tVal Loss:0.2460197 \tTrain Acc: 95.81522% \tVal Acc: 91.7391300%\n",
      "Epoch: 278\tTrain Loss: 0.1505245 \tVal Loss:0.2347003 \tTrain Acc: 95.48913% \tVal Acc: 92.8260878%\n",
      "Epoch: 279\tTrain Loss: 0.1382496 \tVal Loss:0.3265686 \tTrain Acc: 96.1413% \tVal Acc: 91.3043484%\n",
      "Epoch: 280\tTrain Loss: 0.1111638 \tVal Loss:0.4062714 \tTrain Acc: 96.90217% \tVal Acc: 88.6956513%\n",
      "Epoch: 281\tTrain Loss: 0.1138625 \tVal Loss:0.3403232 \tTrain Acc: 96.79348% \tVal Acc: 90.8695638%\n",
      "Epoch: 282\tTrain Loss: 0.1211178 \tVal Loss:0.3304256 \tTrain Acc: 96.79348% \tVal Acc: 90.6521738%\n",
      "Epoch: 283\tTrain Loss: 0.1267054 \tVal Loss:0.4192759 \tTrain Acc: 96.46739% \tVal Acc: 89.9999976%\n",
      "Epoch: 284\tTrain Loss: 0.1233193 \tVal Loss:0.4101953 \tTrain Acc: 96.08696% \tVal Acc: 89.9999991%\n",
      "Epoch: 285\tTrain Loss: 0.0999654 \tVal Loss:0.3156276 \tTrain Acc: 97.5% \tVal Acc: 91.0869569%\n",
      "Epoch: 286\tTrain Loss: 0.0930944 \tVal Loss:0.3149586 \tTrain Acc: 97.55435% \tVal Acc: 91.7391300%\n",
      "Epoch: 287\tTrain Loss: 0.0794393 \tVal Loss:0.2678039 \tTrain Acc: 97.93478% \tVal Acc: 92.8260863%\n",
      "Epoch: 288\tTrain Loss: 0.0743504 \tVal Loss:0.2639849 \tTrain Acc: 98.26087% \tVal Acc: 92.3913032%\n",
      "Epoch: 289\tTrain Loss: 0.0839346 \tVal Loss:0.3271372 \tTrain Acc: 98.09783% \tVal Acc: 91.7391285%\n",
      "Epoch: 290\tTrain Loss: 0.0729235 \tVal Loss:0.2970624 \tTrain Acc: 98.15217% \tVal Acc: 92.1739131%\n",
      "Epoch: 291\tTrain Loss: 0.0681132 \tVal Loss:0.3078458 \tTrain Acc: 98.53261% \tVal Acc: 92.1739116%\n",
      "Epoch: 292\tTrain Loss: 0.0633335 \tVal Loss:0.2482893 \tTrain Acc: 98.6413% \tVal Acc: 93.9130425%\n",
      "Epoch: 293\tTrain Loss: 0.0576065 \tVal Loss:0.2735398 \tTrain Acc: 99.13043% \tVal Acc: 93.4782609%\n",
      "Epoch: 294\tTrain Loss: 0.0649235 \tVal Loss:0.2712344 \tTrain Acc: 98.58696% \tVal Acc: 92.8260878%\n",
      "Epoch: 295\tTrain Loss: 0.0618589 \tVal Loss:0.2732315 \tTrain Acc: 98.47826% \tVal Acc: 93.2608694%\n",
      "Epoch: 296\tTrain Loss: 0.0557780 \tVal Loss:0.2299490 \tTrain Acc: 98.80435% \tVal Acc: 94.1304356%\n",
      "Epoch: 297\tTrain Loss: 0.0519122 \tVal Loss:0.2721625 \tTrain Acc: 99.02174% \tVal Acc: 92.8260878%\n",
      "Epoch: 298\tTrain Loss: 0.0549925 \tVal Loss:0.2865783 \tTrain Acc: 98.6413% \tVal Acc: 91.7391300%\n",
      "Epoch: 299\tTrain Loss: 0.0625263 \tVal Loss:0.2508848 \tTrain Acc: 98.31522% \tVal Acc: 93.0434778%\n",
      "Epoch: 300\tTrain Loss: 0.0831364 \tVal Loss:0.3044865 \tTrain Acc: 97.71739% \tVal Acc: 91.7391300%\n",
      "Epoch: 301\tTrain Loss: 0.1517430 \tVal Loss:0.4396829 \tTrain Acc: 96.1413% \tVal Acc: 89.5652175%\n",
      "Epoch: 302\tTrain Loss: 0.1444216 \tVal Loss:0.2025426 \tTrain Acc: 96.1413% \tVal Acc: 94.3478271%\n",
      "Validation Loss decreased from 0.226996 to 0.202543, saving the model weights\n",
      "Epoch: 303\tTrain Loss: 0.1356070 \tVal Loss:0.2072245 \tTrain Acc: 96.46739% \tVal Acc: 94.3478256%\n",
      "Epoch: 304\tTrain Loss: 0.1152718 \tVal Loss:0.2115900 \tTrain Acc: 96.68478% \tVal Acc: 93.9130425%\n",
      "Epoch: 305\tTrain Loss: 0.1172678 \tVal Loss:0.3364613 \tTrain Acc: 96.90217% \tVal Acc: 90.6521738%\n",
      "Epoch: 306\tTrain Loss: 0.0755219 \tVal Loss:0.1866571 \tTrain Acc: 98.31522% \tVal Acc: 94.3478256%\n",
      "Validation Loss decreased from 0.202543 to 0.186657, saving the model weights\n",
      "Epoch: 307\tTrain Loss: 0.0725425 \tVal Loss:0.2231913 \tTrain Acc: 98.15217% \tVal Acc: 94.5652157%\n",
      "Epoch: 308\tTrain Loss: 0.0724984 \tVal Loss:0.2381841 \tTrain Acc: 98.47826% \tVal Acc: 93.2608694%\n",
      "Epoch: 309\tTrain Loss: 0.0666528 \tVal Loss:0.2302639 \tTrain Acc: 98.80435% \tVal Acc: 93.0434778%\n",
      "Epoch: 310\tTrain Loss: 0.0569439 \tVal Loss:0.2405125 \tTrain Acc: 98.75% \tVal Acc: 93.6956525%\n",
      "Epoch: 311\tTrain Loss: 0.0591829 \tVal Loss:0.2367040 \tTrain Acc: 99.02174% \tVal Acc: 93.2608679%\n",
      "Epoch: 312\tTrain Loss: 0.0615580 \tVal Loss:0.2478861 \tTrain Acc: 98.42391% \tVal Acc: 93.4782609%\n",
      "Epoch: 313\tTrain Loss: 0.0516477 \tVal Loss:0.2417647 \tTrain Acc: 98.85869% \tVal Acc: 93.2608694%\n",
      "Epoch: 314\tTrain Loss: 0.0526369 \tVal Loss:0.2609543 \tTrain Acc: 99.02174% \tVal Acc: 92.6086947%\n",
      "Epoch: 315\tTrain Loss: 0.0539532 \tVal Loss:0.2777802 \tTrain Acc: 98.80435% \tVal Acc: 92.8260878%\n",
      "Epoch: 316\tTrain Loss: 0.0548958 \tVal Loss:0.2474459 \tTrain Acc: 98.80435% \tVal Acc: 92.8260863%\n",
      "Epoch: 317\tTrain Loss: 0.0468034 \tVal Loss:0.2980091 \tTrain Acc: 98.91304% \tVal Acc: 92.3913047%\n",
      "Epoch: 318\tTrain Loss: 0.0453187 \tVal Loss:0.2616658 \tTrain Acc: 99.13043% \tVal Acc: 93.6956510%\n",
      "Epoch: 319\tTrain Loss: 0.0469249 \tVal Loss:0.2524537 \tTrain Acc: 99.18478% \tVal Acc: 93.4782609%\n",
      "Epoch: 320\tTrain Loss: 0.0461299 \tVal Loss:0.2479947 \tTrain Acc: 99.18478% \tVal Acc: 93.2608679%\n",
      "Epoch: 321\tTrain Loss: 0.0475148 \tVal Loss:0.2140635 \tTrain Acc: 99.18478% \tVal Acc: 93.4782594%\n",
      "Epoch: 322\tTrain Loss: 0.0531148 \tVal Loss:0.3366046 \tTrain Acc: 98.8587% \tVal Acc: 91.9565201%\n",
      "Epoch: 323\tTrain Loss: 0.0449475 \tVal Loss:0.2701006 \tTrain Acc: 99.13043% \tVal Acc: 92.8260848%\n",
      "Epoch: 324\tTrain Loss: 0.0459467 \tVal Loss:0.3078932 \tTrain Acc: 99.23913% \tVal Acc: 91.7391300%\n",
      "Epoch: 325\tTrain Loss: 0.0572783 \tVal Loss:0.4026239 \tTrain Acc: 98.75% \tVal Acc: 89.1304344%\n",
      "Epoch: 326\tTrain Loss: 0.0704741 \tVal Loss:0.4806296 \tTrain Acc: 98.31522% \tVal Acc: 88.6956528%\n",
      "Epoch: 327\tTrain Loss: 0.1384721 \tVal Loss:0.2539597 \tTrain Acc: 96.25% \tVal Acc: 92.6086932%\n",
      "Epoch: 328\tTrain Loss: 0.1056778 \tVal Loss:0.3229233 \tTrain Acc: 96.79348% \tVal Acc: 89.1304344%\n",
      "Epoch: 329\tTrain Loss: 0.1354206 \tVal Loss:0.3083698 \tTrain Acc: 95.81522% \tVal Acc: 91.5217385%\n",
      "Epoch: 330\tTrain Loss: 0.1392059 \tVal Loss:0.3496624 \tTrain Acc: 95.48913% \tVal Acc: 91.5217385%\n",
      "Epoch: 331\tTrain Loss: 0.1397105 \tVal Loss:0.2796459 \tTrain Acc: 95.70652% \tVal Acc: 94.7826073%\n",
      "Epoch: 332\tTrain Loss: 0.1086880 \tVal Loss:0.4230443 \tTrain Acc: 97.11956% \tVal Acc: 90.8695638%\n",
      "Epoch: 333\tTrain Loss: 0.1095944 \tVal Loss:0.3077129 \tTrain Acc: 96.63043% \tVal Acc: 92.1739131%\n",
      "Epoch: 334\tTrain Loss: 0.0839962 \tVal Loss:0.2388265 \tTrain Acc: 97.66304% \tVal Acc: 93.9130440%\n",
      "Epoch: 335\tTrain Loss: 0.0814212 \tVal Loss:0.2712777 \tTrain Acc: 97.93478% \tVal Acc: 94.1304341%\n",
      "Epoch: 336\tTrain Loss: 0.0758380 \tVal Loss:0.4007582 \tTrain Acc: 97.93478% \tVal Acc: 90.8695668%\n",
      "Epoch: 337\tTrain Loss: 0.0855294 \tVal Loss:0.2337519 \tTrain Acc: 97.93478% \tVal Acc: 94.1304326%\n",
      "Epoch: 338\tTrain Loss: 0.0640852 \tVal Loss:0.3157343 \tTrain Acc: 98.6413% \tVal Acc: 92.3913032%\n",
      "Epoch: 339\tTrain Loss: 0.0548857 \tVal Loss:0.2913541 \tTrain Acc: 98.85869% \tVal Acc: 93.9130440%\n",
      "Epoch: 340\tTrain Loss: 0.0467411 \tVal Loss:0.2799091 \tTrain Acc: 99.02174% \tVal Acc: 92.6086962%\n",
      "Epoch: 341\tTrain Loss: 0.0475996 \tVal Loss:0.2502644 \tTrain Acc: 99.02174% \tVal Acc: 92.6086962%\n",
      "Epoch: 342\tTrain Loss: 0.0408686 \tVal Loss:0.2675829 \tTrain Acc: 99.02174% \tVal Acc: 93.9130425%\n",
      "Epoch: 343\tTrain Loss: 0.0420251 \tVal Loss:0.2608535 \tTrain Acc: 99.40217% \tVal Acc: 92.6086962%\n",
      "Epoch: 344\tTrain Loss: 0.0475090 \tVal Loss:0.2951660 \tTrain Acc: 98.8587% \tVal Acc: 92.3913047%\n",
      "Epoch: 345\tTrain Loss: 0.0541347 \tVal Loss:0.3356699 \tTrain Acc: 98.80435% \tVal Acc: 91.5217385%\n",
      "Epoch: 346\tTrain Loss: 0.0626541 \tVal Loss:0.2968691 \tTrain Acc: 98.58696% \tVal Acc: 92.1739131%\n",
      "Epoch: 347\tTrain Loss: 0.0558705 \tVal Loss:0.3239243 \tTrain Acc: 98.69565% \tVal Acc: 92.3913047%\n",
      "Epoch: 348\tTrain Loss: 0.0662727 \tVal Loss:0.2265482 \tTrain Acc: 97.82609% \tVal Acc: 93.4782609%\n",
      "Epoch: 349\tTrain Loss: 0.0562392 \tVal Loss:0.3115133 \tTrain Acc: 98.53261% \tVal Acc: 92.3913047%\n",
      "Epoch: 350\tTrain Loss: 0.0504988 \tVal Loss:0.2114313 \tTrain Acc: 98.85869% \tVal Acc: 94.1304341%\n",
      "Epoch: 351\tTrain Loss: 0.0526561 \tVal Loss:0.2526701 \tTrain Acc: 98.47826% \tVal Acc: 94.3478256%\n",
      "Epoch: 352\tTrain Loss: 0.0493519 \tVal Loss:0.2231237 \tTrain Acc: 98.91304% \tVal Acc: 93.6956510%\n",
      "Epoch: 353\tTrain Loss: 0.0401256 \tVal Loss:0.2527797 \tTrain Acc: 99.13043% \tVal Acc: 93.2608694%\n",
      "Epoch: 354\tTrain Loss: 0.0337044 \tVal Loss:0.2728191 \tTrain Acc: 99.45652% \tVal Acc: 92.3913032%\n",
      "Epoch: 355\tTrain Loss: 0.0422143 \tVal Loss:0.3032994 \tTrain Acc: 99.23913% \tVal Acc: 93.2608694%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 356\tTrain Loss: 0.0339312 \tVal Loss:0.2424775 \tTrain Acc: 99.34783% \tVal Acc: 93.6956510%\n",
      "Epoch: 357\tTrain Loss: 0.0364217 \tVal Loss:0.2164057 \tTrain Acc: 99.18478% \tVal Acc: 95.2173904%\n",
      "Epoch: 358\tTrain Loss: 0.0362722 \tVal Loss:0.2184731 \tTrain Acc: 99.18478% \tVal Acc: 95.0000003%\n",
      "Epoch: 359\tTrain Loss: 0.0384921 \tVal Loss:0.2761793 \tTrain Acc: 98.91304% \tVal Acc: 93.0434793%\n",
      "Epoch: 360\tTrain Loss: 0.0313821 \tVal Loss:0.2332259 \tTrain Acc: 99.34783% \tVal Acc: 94.1304326%\n",
      "Epoch: 361\tTrain Loss: 0.0362576 \tVal Loss:0.2328502 \tTrain Acc: 99.45652% \tVal Acc: 93.9130425%\n",
      "Epoch: 362\tTrain Loss: 0.0349799 \tVal Loss:0.2280926 \tTrain Acc: 99.13043% \tVal Acc: 94.9999988%\n",
      "Epoch: 363\tTrain Loss: 0.0267541 \tVal Loss:0.2653196 \tTrain Acc: 99.45652% \tVal Acc: 92.8260863%\n",
      "Epoch: 364\tTrain Loss: 0.0305953 \tVal Loss:0.2466757 \tTrain Acc: 99.45652% \tVal Acc: 94.3478242%\n",
      "Epoch: 365\tTrain Loss: 0.0301339 \tVal Loss:0.2661777 \tTrain Acc: 99.40217% \tVal Acc: 93.6956525%\n",
      "Epoch: 366\tTrain Loss: 0.0334891 \tVal Loss:0.3294491 \tTrain Acc: 99.18478% \tVal Acc: 93.2608679%\n",
      "Epoch: 367\tTrain Loss: 0.0290981 \tVal Loss:0.2653159 \tTrain Acc: 99.51087% \tVal Acc: 93.4782594%\n",
      "Epoch: 368\tTrain Loss: 0.0276013 \tVal Loss:0.2668965 \tTrain Acc: 99.40217% \tVal Acc: 94.1304326%\n",
      "Epoch: 369\tTrain Loss: 0.0277630 \tVal Loss:0.2138007 \tTrain Acc: 99.40217% \tVal Acc: 94.9999988%\n",
      "Epoch: 370\tTrain Loss: 0.0278969 \tVal Loss:0.2457177 \tTrain Acc: 99.51087% \tVal Acc: 94.5652172%\n",
      "Epoch: 371\tTrain Loss: 0.0288868 \tVal Loss:0.1932896 \tTrain Acc: 99.29348% \tVal Acc: 95.6521735%\n",
      "Epoch: 372\tTrain Loss: 0.0322514 \tVal Loss:0.2164893 \tTrain Acc: 99.40217% \tVal Acc: 94.5652172%\n",
      "Epoch: 373\tTrain Loss: 0.0304843 \tVal Loss:0.2348350 \tTrain Acc: 99.34783% \tVal Acc: 94.3478271%\n",
      "Epoch: 374\tTrain Loss: 0.0335329 \tVal Loss:0.2861806 \tTrain Acc: 99.29348% \tVal Acc: 93.4782609%\n",
      "Epoch: 375\tTrain Loss: 0.0468444 \tVal Loss:0.2559505 \tTrain Acc: 98.91304% \tVal Acc: 93.6956525%\n",
      "Epoch: 376\tTrain Loss: 0.0371204 \tVal Loss:0.2529715 \tTrain Acc: 99.23913% \tVal Acc: 94.1304341%\n",
      "Epoch: 377\tTrain Loss: 0.0344333 \tVal Loss:0.2575838 \tTrain Acc: 99.34783% \tVal Acc: 93.6956510%\n",
      "Epoch: 378\tTrain Loss: 0.0342678 \tVal Loss:0.2668408 \tTrain Acc: 99.34783% \tVal Acc: 93.9130425%\n",
      "Epoch: 379\tTrain Loss: 0.0296098 \tVal Loss:0.2856125 \tTrain Acc: 99.40217% \tVal Acc: 93.6956510%\n",
      "Epoch: 380\tTrain Loss: 0.0269565 \tVal Loss:0.2881890 \tTrain Acc: 99.45652% \tVal Acc: 94.1304341%\n",
      "Epoch: 381\tTrain Loss: 0.0308089 \tVal Loss:0.2956188 \tTrain Acc: 99.23913% \tVal Acc: 93.9130425%\n",
      "Epoch: 382\tTrain Loss: 0.0298026 \tVal Loss:0.2670677 \tTrain Acc: 99.18478% \tVal Acc: 94.3478271%\n",
      "Epoch: 383\tTrain Loss: 0.0312416 \tVal Loss:0.2197152 \tTrain Acc: 99.18478% \tVal Acc: 94.9999988%\n",
      "Epoch: 384\tTrain Loss: 0.0284988 \tVal Loss:0.3356752 \tTrain Acc: 99.34783% \tVal Acc: 93.2608679%\n",
      "Epoch: 385\tTrain Loss: 0.0324066 \tVal Loss:0.2745778 \tTrain Acc: 99.18478% \tVal Acc: 94.7826073%\n",
      "Epoch: 386\tTrain Loss: 0.0297950 \tVal Loss:0.2539726 \tTrain Acc: 99.40217% \tVal Acc: 93.4782594%\n",
      "Epoch: 387\tTrain Loss: 0.0321888 \tVal Loss:0.2778470 \tTrain Acc: 99.40217% \tVal Acc: 93.6956525%\n",
      "Epoch: 388\tTrain Loss: 0.0443251 \tVal Loss:0.2893554 \tTrain Acc: 99.13043% \tVal Acc: 93.4782594%\n",
      "Epoch: 389\tTrain Loss: 0.1295278 \tVal Loss:0.4014546 \tTrain Acc: 96.1413% \tVal Acc: 89.7826090%\n",
      "Epoch: 390\tTrain Loss: 0.4603198 \tVal Loss:1.2023721 \tTrain Acc: 87.06522% \tVal Acc: 69.3478256%\n",
      "Epoch: 391\tTrain Loss: 1.4456107 \tVal Loss:1.1790862 \tTrain Acc: 63.80435% \tVal Acc: 65.2173907%\n",
      "Epoch: 392\tTrain Loss: 1.5834228 \tVal Loss:0.9798616 \tTrain Acc: 58.58696% \tVal Acc: 68.6956510%\n",
      "Epoch: 393\tTrain Loss: 1.5201704 \tVal Loss:0.9833363 \tTrain Acc: 60.05435% \tVal Acc: 69.1304334%\n",
      "Epoch: 394\tTrain Loss: 0.8572836 \tVal Loss:0.7528315 \tTrain Acc: 72.66304% \tVal Acc: 81.3043475%\n",
      "Epoch: 395\tTrain Loss: 0.6708863 \tVal Loss:0.5272872 \tTrain Acc: 78.47826% \tVal Acc: 85.8695641%\n",
      "Epoch: 396\tTrain Loss: 0.5386229 \tVal Loss:0.6754902 \tTrain Acc: 83.47826% \tVal Acc: 82.6086938%\n",
      "Epoch: 397\tTrain Loss: 0.4567222 \tVal Loss:0.9383399 \tTrain Acc: 86.08696% \tVal Acc: 71.5217397%\n",
      "Epoch: 398\tTrain Loss: 0.5556242 \tVal Loss:0.3276244 \tTrain Acc: 82.22826% \tVal Acc: 90.4347822%\n",
      "Epoch: 399\tTrain Loss: 0.4335335 \tVal Loss:0.4882697 \tTrain Acc: 85.65217% \tVal Acc: 86.9565219%\n",
      "Epoch: 400\tTrain Loss: 0.3300070 \tVal Loss:0.3896237 \tTrain Acc: 90.10869% \tVal Acc: 91.3043484%\n",
      "Epoch: 401\tTrain Loss: 0.2384077 \tVal Loss:0.3082143 \tTrain Acc: 91.90217% \tVal Acc: 93.6956510%\n",
      "Epoch: 402\tTrain Loss: 0.1512025 \tVal Loss:0.2832722 \tTrain Acc: 95.48913% \tVal Acc: 93.4782594%\n",
      "Epoch: 403\tTrain Loss: 0.1125355 \tVal Loss:0.2863402 \tTrain Acc: 97.60869% \tVal Acc: 94.1304341%\n",
      "Epoch: 404\tTrain Loss: 0.1120410 \tVal Loss:0.2786852 \tTrain Acc: 97.3913% \tVal Acc: 93.4782594%\n",
      "Epoch: 405\tTrain Loss: 0.0914027 \tVal Loss:0.2818657 \tTrain Acc: 97.71739% \tVal Acc: 93.6956510%\n",
      "Epoch: 406\tTrain Loss: 0.0872746 \tVal Loss:0.2869277 \tTrain Acc: 97.98913% \tVal Acc: 93.4782594%\n",
      "Epoch: 407\tTrain Loss: 0.0908859 \tVal Loss:0.2837730 \tTrain Acc: 97.82609% \tVal Acc: 92.8260848%\n",
      "Epoch: 408\tTrain Loss: 0.0771988 \tVal Loss:0.2869419 \tTrain Acc: 98.6413% \tVal Acc: 93.2608679%\n",
      "Epoch: 409\tTrain Loss: 0.0756373 \tVal Loss:0.2917384 \tTrain Acc: 98.69565% \tVal Acc: 93.2608679%\n",
      "Epoch: 410\tTrain Loss: 0.0693077 \tVal Loss:0.2835652 \tTrain Acc: 98.58696% \tVal Acc: 93.6956510%\n",
      "Epoch: 411\tTrain Loss: 0.0656255 \tVal Loss:0.2641704 \tTrain Acc: 98.31522% \tVal Acc: 93.6956510%\n",
      "Epoch: 412\tTrain Loss: 0.0634915 \tVal Loss:0.2702571 \tTrain Acc: 98.31522% \tVal Acc: 93.6956510%\n",
      "Epoch: 413\tTrain Loss: 0.0634382 \tVal Loss:0.2950861 \tTrain Acc: 98.6413% \tVal Acc: 93.2608679%\n",
      "Epoch: 414\tTrain Loss: 0.0571790 \tVal Loss:0.2868731 \tTrain Acc: 98.75% \tVal Acc: 93.4782594%\n",
      "Epoch: 415\tTrain Loss: 0.0661732 \tVal Loss:0.2862268 \tTrain Acc: 98.69565% \tVal Acc: 93.4782594%\n",
      "Epoch: 416\tTrain Loss: 0.0539325 \tVal Loss:0.2821736 \tTrain Acc: 98.96739% \tVal Acc: 93.9130425%\n",
      "Epoch: 417\tTrain Loss: 0.0532524 \tVal Loss:0.2838401 \tTrain Acc: 98.96739% \tVal Acc: 93.2608679%\n",
      "Epoch: 418\tTrain Loss: 0.0545943 \tVal Loss:0.2785931 \tTrain Acc: 98.85869% \tVal Acc: 93.6956510%\n",
      "Epoch: 419\tTrain Loss: 0.0502412 \tVal Loss:0.2713996 \tTrain Acc: 99.23913% \tVal Acc: 93.4782594%\n",
      "Epoch: 420\tTrain Loss: 0.0476848 \tVal Loss:0.2732092 \tTrain Acc: 99.02174% \tVal Acc: 93.9130425%\n",
      "Epoch: 421\tTrain Loss: 0.0429254 \tVal Loss:0.2687600 \tTrain Acc: 99.29348% \tVal Acc: 94.1304341%\n",
      "Epoch: 422\tTrain Loss: 0.0485107 \tVal Loss:0.2781201 \tTrain Acc: 98.91304% \tVal Acc: 93.4782594%\n",
      "Epoch: 423\tTrain Loss: 0.0489783 \tVal Loss:0.2849773 \tTrain Acc: 98.85869% \tVal Acc: 93.4782594%\n",
      "Epoch: 424\tTrain Loss: 0.0456390 \tVal Loss:0.2765861 \tTrain Acc: 99.07609% \tVal Acc: 93.4782594%\n",
      "Epoch: 425\tTrain Loss: 0.0424177 \tVal Loss:0.2628564 \tTrain Acc: 99.07609% \tVal Acc: 94.1304341%\n",
      "Epoch: 426\tTrain Loss: 0.0421427 \tVal Loss:0.2637679 \tTrain Acc: 99.23913% \tVal Acc: 93.4782609%\n",
      "Epoch: 427\tTrain Loss: 0.0416356 \tVal Loss:0.2727434 \tTrain Acc: 98.96739% \tVal Acc: 93.4782594%\n",
      "Epoch: 428\tTrain Loss: 0.0445640 \tVal Loss:0.2696453 \tTrain Acc: 99.23913% \tVal Acc: 94.1304341%\n",
      "Epoch: 429\tTrain Loss: 0.0390086 \tVal Loss:0.2531678 \tTrain Acc: 99.34783% \tVal Acc: 94.3478256%\n",
      "Epoch: 430\tTrain Loss: 0.0405171 \tVal Loss:0.2648174 \tTrain Acc: 99.07609% \tVal Acc: 93.9130425%\n",
      "Epoch: 431\tTrain Loss: 0.0415618 \tVal Loss:0.2608160 \tTrain Acc: 99.07609% \tVal Acc: 94.3478256%\n",
      "Epoch: 432\tTrain Loss: 0.0376796 \tVal Loss:0.2591811 \tTrain Acc: 99.13043% \tVal Acc: 94.7826073%\n",
      "Epoch: 433\tTrain Loss: 0.0392601 \tVal Loss:0.2430705 \tTrain Acc: 99.02174% \tVal Acc: 94.7826073%\n",
      "Epoch: 434\tTrain Loss: 0.0387245 \tVal Loss:0.2466808 \tTrain Acc: 98.96739% \tVal Acc: 94.5652157%\n",
      "Epoch: 435\tTrain Loss: 0.0410580 \tVal Loss:0.2525014 \tTrain Acc: 99.02174% \tVal Acc: 94.5652157%\n",
      "Epoch: 436\tTrain Loss: 0.0389347 \tVal Loss:0.2401154 \tTrain Acc: 99.13043% \tVal Acc: 95.4347819%\n",
      "Epoch: 437\tTrain Loss: 0.0355945 \tVal Loss:0.2606370 \tTrain Acc: 99.40217% \tVal Acc: 94.5652157%\n",
      "Epoch: 438\tTrain Loss: 0.0351179 \tVal Loss:0.2779259 \tTrain Acc: 99.40217% \tVal Acc: 94.3478242%\n",
      "Epoch: 439\tTrain Loss: 0.0334640 \tVal Loss:0.2721461 \tTrain Acc: 99.45652% \tVal Acc: 94.3478242%\n",
      "Epoch: 440\tTrain Loss: 0.0363426 \tVal Loss:0.2847259 \tTrain Acc: 99.23913% \tVal Acc: 93.9130425%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 441\tTrain Loss: 0.0360420 \tVal Loss:0.2723735 \tTrain Acc: 99.29348% \tVal Acc: 94.3478242%\n",
      "Epoch: 442\tTrain Loss: 0.0338480 \tVal Loss:0.2721491 \tTrain Acc: 99.51087% \tVal Acc: 93.9130425%\n",
      "Epoch: 443\tTrain Loss: 0.0340063 \tVal Loss:0.2801941 \tTrain Acc: 99.40217% \tVal Acc: 94.1304341%\n",
      "Epoch: 444\tTrain Loss: 0.0356678 \tVal Loss:0.2780287 \tTrain Acc: 98.80435% \tVal Acc: 93.9130425%\n",
      "Epoch: 445\tTrain Loss: 0.0328779 \tVal Loss:0.2803798 \tTrain Acc: 99.45652% \tVal Acc: 93.9130425%\n",
      "Epoch: 446\tTrain Loss: 0.0287683 \tVal Loss:0.2760672 \tTrain Acc: 99.67391% \tVal Acc: 94.1304326%\n",
      "Epoch: 447\tTrain Loss: 0.0332231 \tVal Loss:0.2885443 \tTrain Acc: 99.18478% \tVal Acc: 93.4782609%\n",
      "Epoch: 448\tTrain Loss: 0.0306620 \tVal Loss:0.2908644 \tTrain Acc: 99.67391% \tVal Acc: 93.0434763%\n",
      "Epoch: 449\tTrain Loss: 0.0361704 \tVal Loss:0.3042476 \tTrain Acc: 99.13043% \tVal Acc: 93.2608679%\n",
      "Epoch: 450\tTrain Loss: 0.0322805 \tVal Loss:0.3101678 \tTrain Acc: 99.29348% \tVal Acc: 92.8260863%\n",
      "Epoch: 451\tTrain Loss: 0.0270925 \tVal Loss:0.3007050 \tTrain Acc: 99.45652% \tVal Acc: 93.0434793%\n",
      "Epoch: 452\tTrain Loss: 0.0275034 \tVal Loss:0.2953876 \tTrain Acc: 99.51087% \tVal Acc: 93.0434763%\n",
      "Epoch: 453\tTrain Loss: 0.0283496 \tVal Loss:0.2978224 \tTrain Acc: 99.34783% \tVal Acc: 94.3478256%\n",
      "Epoch: 454\tTrain Loss: 0.0337174 \tVal Loss:0.3558836 \tTrain Acc: 99.34783% \tVal Acc: 91.9565201%\n",
      "Epoch: 455\tTrain Loss: 0.0849794 \tVal Loss:0.2788757 \tTrain Acc: 98.26087% \tVal Acc: 93.4782609%\n",
      "Epoch: 456\tTrain Loss: 0.0658721 \tVal Loss:0.2856798 \tTrain Acc: 98.36956% \tVal Acc: 92.8260863%\n",
      "Epoch: 457\tTrain Loss: 0.0685969 \tVal Loss:0.2803002 \tTrain Acc: 97.82609% \tVal Acc: 92.6086947%\n",
      "Epoch: 458\tTrain Loss: 0.0511861 \tVal Loss:0.2896133 \tTrain Acc: 99.07609% \tVal Acc: 93.4782594%\n",
      "Epoch: 459\tTrain Loss: 0.0437528 \tVal Loss:0.3061011 \tTrain Acc: 98.96739% \tVal Acc: 93.0434763%\n",
      "Epoch: 460\tTrain Loss: 0.0431942 \tVal Loss:0.2849640 \tTrain Acc: 99.18478% \tVal Acc: 93.2608679%\n",
      "Epoch: 461\tTrain Loss: 0.0386311 \tVal Loss:0.2988667 \tTrain Acc: 98.91304% \tVal Acc: 92.6086947%\n",
      "Epoch: 462\tTrain Loss: 0.0318989 \tVal Loss:0.2877503 \tTrain Acc: 99.29348% \tVal Acc: 93.2608679%\n",
      "Epoch: 463\tTrain Loss: 0.0290461 \tVal Loss:0.2840706 \tTrain Acc: 99.51087% \tVal Acc: 93.2608679%\n",
      "Epoch: 464\tTrain Loss: 0.0384152 \tVal Loss:0.2833322 \tTrain Acc: 98.85869% \tVal Acc: 93.6956510%\n",
      "Epoch: 465\tTrain Loss: 0.0263639 \tVal Loss:0.2959892 \tTrain Acc: 99.61956% \tVal Acc: 94.1304341%\n",
      "Epoch: 466\tTrain Loss: 0.0292376 \tVal Loss:0.2956490 \tTrain Acc: 99.45652% \tVal Acc: 94.1304341%\n",
      "Epoch: 467\tTrain Loss: 0.0318693 \tVal Loss:0.2922652 \tTrain Acc: 99.07609% \tVal Acc: 93.6956510%\n",
      "Epoch: 468\tTrain Loss: 0.0264833 \tVal Loss:0.2872876 \tTrain Acc: 99.56522% \tVal Acc: 94.3478256%\n",
      "Epoch: 469\tTrain Loss: 0.0354229 \tVal Loss:0.3202954 \tTrain Acc: 99.18478% \tVal Acc: 93.0434763%\n",
      "Epoch: 470\tTrain Loss: 0.0428662 \tVal Loss:0.3370227 \tTrain Acc: 98.80435% \tVal Acc: 93.0434763%\n",
      "Epoch: 471\tTrain Loss: 0.0505756 \tVal Loss:0.3313337 \tTrain Acc: 98.6413% \tVal Acc: 91.9565216%\n",
      "Epoch: 472\tTrain Loss: 0.0408439 \tVal Loss:0.3514399 \tTrain Acc: 98.91304% \tVal Acc: 90.8695653%\n",
      "Epoch: 473\tTrain Loss: 0.0285301 \tVal Loss:0.2992182 \tTrain Acc: 99.45652% \tVal Acc: 92.1739116%\n",
      "Epoch: 474\tTrain Loss: 0.0278924 \tVal Loss:0.3235177 \tTrain Acc: 99.45652% \tVal Acc: 92.1739116%\n",
      "Epoch: 475\tTrain Loss: 0.0300275 \tVal Loss:0.2889987 \tTrain Acc: 99.40217% \tVal Acc: 93.4782594%\n",
      "Epoch: 476\tTrain Loss: 0.0260975 \tVal Loss:0.2733668 \tTrain Acc: 99.56522% \tVal Acc: 93.6956510%\n",
      "Epoch: 477\tTrain Loss: 0.0282634 \tVal Loss:0.2745266 \tTrain Acc: 99.23913% \tVal Acc: 93.9130425%\n",
      "Epoch: 478\tTrain Loss: 0.0285868 \tVal Loss:0.2757059 \tTrain Acc: 99.29348% \tVal Acc: 94.3478256%\n",
      "Epoch: 479\tTrain Loss: 0.0276189 \tVal Loss:0.2786218 \tTrain Acc: 99.23913% \tVal Acc: 94.3478256%\n",
      "Epoch: 480\tTrain Loss: 0.0309939 \tVal Loss:0.2702207 \tTrain Acc: 99.34783% \tVal Acc: 94.1304341%\n",
      "Epoch: 481\tTrain Loss: 0.0243112 \tVal Loss:0.2474935 \tTrain Acc: 99.45652% \tVal Acc: 94.7826073%\n",
      "Epoch: 482\tTrain Loss: 0.0195727 \tVal Loss:0.2500389 \tTrain Acc: 99.72826% \tVal Acc: 94.5652157%\n",
      "Epoch: 483\tTrain Loss: 0.0233782 \tVal Loss:0.2469297 \tTrain Acc: 99.61956% \tVal Acc: 94.3478242%\n",
      "Epoch: 484\tTrain Loss: 0.0238309 \tVal Loss:0.2537857 \tTrain Acc: 99.40217% \tVal Acc: 94.1304326%\n",
      "Epoch: 485\tTrain Loss: 0.0251361 \tVal Loss:0.3246981 \tTrain Acc: 99.34783% \tVal Acc: 92.8260863%\n",
      "Epoch: 486\tTrain Loss: 0.0181277 \tVal Loss:0.2989966 \tTrain Acc: 99.67391% \tVal Acc: 93.4782609%\n",
      "Epoch: 487\tTrain Loss: 0.0258588 \tVal Loss:0.2979210 \tTrain Acc: 99.45652% \tVal Acc: 93.2608679%\n",
      "Epoch: 488\tTrain Loss: 0.0242078 \tVal Loss:0.2986090 \tTrain Acc: 99.51087% \tVal Acc: 93.4782594%\n",
      "Epoch: 489\tTrain Loss: 0.0231670 \tVal Loss:0.2932246 \tTrain Acc: 99.51087% \tVal Acc: 93.2608679%\n",
      "Epoch: 490\tTrain Loss: 0.0267595 \tVal Loss:0.2874989 \tTrain Acc: 99.29348% \tVal Acc: 93.9130425%\n",
      "Epoch: 491\tTrain Loss: 0.0236539 \tVal Loss:0.2653965 \tTrain Acc: 99.56522% \tVal Acc: 94.7826073%\n",
      "Epoch: 492\tTrain Loss: 0.0253229 \tVal Loss:0.2742601 \tTrain Acc: 99.45652% \tVal Acc: 94.7826073%\n",
      "Epoch: 493\tTrain Loss: 0.0198441 \tVal Loss:0.2781260 \tTrain Acc: 99.61956% \tVal Acc: 94.5652157%\n",
      "Epoch: 494\tTrain Loss: 0.0267221 \tVal Loss:0.2786537 \tTrain Acc: 99.23913% \tVal Acc: 94.1304341%\n",
      "Epoch: 495\tTrain Loss: 0.0224046 \tVal Loss:0.2679659 \tTrain Acc: 99.51087% \tVal Acc: 93.4782609%\n",
      "Epoch: 496\tTrain Loss: 0.0208481 \tVal Loss:0.2751304 \tTrain Acc: 99.67391% \tVal Acc: 93.9130425%\n",
      "Epoch: 497\tTrain Loss: 0.0201666 \tVal Loss:0.2958442 \tTrain Acc: 99.72826% \tVal Acc: 93.4782594%\n",
      "Epoch: 498\tTrain Loss: 0.0224321 \tVal Loss:0.3755995 \tTrain Acc: 99.61956% \tVal Acc: 91.9565201%\n",
      "Epoch: 499\tTrain Loss: 0.0395710 \tVal Loss:0.4719783 \tTrain Acc: 98.96739% \tVal Acc: 89.3478259%\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "min_val_loss = np.Inf\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    train_accuracy = 0\n",
    "    val_accuracy = 0\n",
    "    \n",
    "    \n",
    "    hidden = model.hidden_init(train_batch_size)    \n",
    "    #print('hidden[0].shape:- ',hidden[0].shape)\n",
    "    \n",
    "    for inputs,labels in train_loader:\n",
    "        #print(inputs.shape)\n",
    "\n",
    "        '''\n",
    "        Creating new variables for the hidden state, otherwise\n",
    "        we'd backprop through the entire training history\n",
    "        '''\n",
    "        h = tuple([each.data for each in hidden])\n",
    "        \n",
    "\n",
    "        # zero accumulated gradients\n",
    "        model.zero_grad()\n",
    "       \n",
    "        # get the output from the model\n",
    "        output, h = model.forward(inputs, h,train_batch_size)\n",
    "        #print('OUTPUT', output)\n",
    "        \n",
    "        \n",
    "        #print('Labels Shape :-', (torch.max(labels, 1)[1]).shape)\n",
    "    \n",
    "        # calculate the loss and perform backprop\n",
    "        #print('Labels Long :-', labels.long())\n",
    "        loss = criterion(output,labels.long())\n",
    "        #print('LOSS IS :-', loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #calculate training accuracy\n",
    "        output = F.softmax(output, dim = 1)\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "        logging.debug(' top probab {} top class {}'.format(top_p.view(-1, top_p.shape[0]), top_class.view(-1, top_p.shape[0])))\n",
    "\n",
    "        equals = top_class == labels.long().view(*top_class.shape)\n",
    "        train_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        \n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        #nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        #print(train_loss)\n",
    "              \n",
    "    model.eval()\n",
    "    for inputs, labels in val_loader:\n",
    "                \n",
    "        val_h = tuple([each.data for each in hidden])\n",
    "        \n",
    "        output, hidden = model.forward(inputs, val_h,val_batch_size)\n",
    "       \n",
    "        loss = criterion(output,labels.long())\n",
    "        \n",
    "        val_loss += loss.item()\n",
    "        \n",
    "        #calculate validation accuracy\n",
    "        output = F.softmax(output, dim = 1)\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "        \n",
    "        #logging.debug(output)\n",
    "        #logging.debug('VALIDATION top probab {} VALIDATION top class {}'.format(top_p.view(-1, top_p.shape[0]), top_class.view(-1, top_p.shape[0])))\n",
    "\n",
    "        #print('Top Class:- ',top_class)\n",
    "        equals = top_class == labels.long().view(*top_class.shape)\n",
    "        #print('Equals:- ', equals)\n",
    "        val_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    #Averaging losses\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    val_loss = val_loss/len(val_loader)\n",
    "    val_accuracy = val_accuracy/len(val_loader)\n",
    "    train_accuracy = train_accuracy/len(train_loader)\n",
    "    \n",
    "    print('Epoch: {}\\tTrain Loss: {:.7f} \\tVal Loss:{:.7f} \\tTrain Acc: {:.7}% \\tVal Acc: {:.7f}%'.format(e, train_loss, val_loss, train_accuracy*100,val_accuracy*100))\n",
    "    \n",
    "    #saving the model if validation loss is decreased\n",
    "    if val_loss <= min_val_loss:\n",
    "        print('Validation Loss decreased from {:6f} to {:6f}, saving the model weights'.format(min_val_loss, val_loss))\n",
    "        torch.save(model.state_dict(), 'lstm_state_256_hidden_size_sorted.pt')\n",
    "        min_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Music Genaration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stacked_LSTM(\n",
       "  (lstm): LSTM(1, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=256, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights\n",
    "test_model = Stacked_LSTM(input_size,hidden_size,num_layer,output_size)\n",
    "test_model.load_state_dict(torch.load('lstm_state_256_hidden_size_sorted.pt'))\n",
    "test_model.eval()\n",
    "test_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load population database\n",
    "\n",
    "#testing_data = np.ones(200)*1\n",
    "testing_data = list(range(50,90))\n",
    "testing_data.extend(testing_data[::-1])\n",
    "testing_data_rev = testing_data[::-1]\n",
    "testing_data_rev.extend(testing_data)\n",
    "testing_data = testing_data_rev\n",
    "\n",
    "\n",
    "testing_data = np.asarray(testing_data)\n",
    "testing_data = testing_data.reshape(testing_data.shape[0],1)\n",
    "\n",
    "initial_seq = [network_input[0][1:].cpu().numpy().tolist()]\n",
    "\n",
    "testing_data_unnorm = testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "testing_data=testing_data.tolist()\n",
    "for i in range(len(testing_data)):\n",
    "    list1.extend(testing_data[i])\n",
    "\n",
    "#list1\n",
    "\n",
    "for i in range(len(list1)):\n",
    "    list1[i]=(list1[i]-50)/(89-50)\n",
    "\n",
    "list1 = np.asarray(list1)\n",
    "list1 = list1.reshape(list1.shape[0],1)\n",
    "testing_data = list1\n",
    "#list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting\n",
    "def prediction_with_influence(influence,int2note,initial_seq, max_note, test_batch_size = 1):\n",
    "\n",
    "    predicted_notes = []\n",
    "    initial_seq[0].extend([[0]]*len(testing_data))\n",
    "    test_seq = torch.Tensor(initial_seq).cuda()\n",
    "    \n",
    "    test_hidden = test_model.hidden_init(test_batch_size)\n",
    "\n",
    "    \n",
    "    for i in range(len(influence)):\n",
    "        \n",
    "        test_seq[0][sequence_length - 1 + i][0] = float(influence[i])\n",
    "        \n",
    "        test_slice = test_seq[0][i : i + sequence_length]        \n",
    "        test_slice = test_slice.view(1, test_slice.shape[0], test_slice.shape[1])\n",
    "        \n",
    "        test_output,_ = test_model.forward(test_slice, test_hidden, test_batch_size)\n",
    "        test_output = F.softmax(test_output, dim = 1)\n",
    "    \n",
    "        top_p, top_class = test_output.topk(1,dim =1)\n",
    "        test_seq[0][sequence_length - 1 + i][0] = int2note[top_class.item()]/max_note\n",
    "        \n",
    "        predicted_notes.append(int2note[top_class.item()])\n",
    "        \n",
    "    return predicted_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_notes_lst = prediction_with_influence(testing_data,int_to_note,initial_seq, max_midi_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_notes_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c9573a25f8>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 369
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(list(np.ones(200)*89))\n",
    "\n",
    "#plt.plot(list(np.ones(200)*50))\n",
    "#plt.plot(list(np.ones(20)*50))\n",
    "plt.plot(testing_data_unnorm)\n",
    "plt.plot(predicted_notes_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({72: 12, 74: 20, 76: 2, 79: 32, 81: 1, 83: 69, 78: 4, 84: 20})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter(predicted_notes_lst)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
