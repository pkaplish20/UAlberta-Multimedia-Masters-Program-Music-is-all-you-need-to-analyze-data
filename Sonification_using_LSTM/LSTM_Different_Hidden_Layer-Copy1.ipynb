{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.tensorboard as tb\n",
    "from Preprocessing.preprocessing import PreprocessingTrainingData\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as  plt\n",
    "import os\n",
    "import logging\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#static parameters\n",
    "train_batch_size = 170\n",
    "val_batch_size = 170\n",
    "sequence_length=50\n",
    "test_batch_size = 1\n",
    "input_size = 1\n",
    "hidden_size = 256\n",
    "num_layer = 2\n",
    "output_size = 38\n",
    "clip = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from preprocessing.py\n",
    "dataset_path = os.path.join(os.path.abspath('..'),'Dataset\\\\Clementi dataset\\\\Clementi dataset' )\n",
    "network_input,network_output,max_midi_number,min_midi_number,int_to_note = PreprocessingTrainingData().preprocess_notes(dataset_path)\n",
    "network_input, network_output = network_input.cuda(), network_output.cuda()\n",
    "\n",
    "# print(network_input)\n",
    "#print(network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(37, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(network_output.max())\n",
    "print(network_output.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "89\n",
      "50\n",
      "{0: 50, 1: 52, 2: 53, 3: 54, 4: 55, 5: 56, 6: 57, 7: 58, 8: 59, 9: 60, 10: 61, 11: 62, 12: 63, 13: 64, 14: 65, 15: 66, 16: 67, 17: 68, 18: 69, 19: 70, 20: 71, 21: 72, 22: 73, 23: 74, 24: 75, 25: 76, 26: 77, 27: 78, 28: 79, 29: 80, 30: 81, 31: 82, 32: 83, 33: 84, 34: 85, 35: 86, 36: 88, 37: 89}\n"
     ]
    }
   ],
   "source": [
    "print(network_input.max())\n",
    "print(network_input.min())\n",
    "print(max_midi_number)\n",
    "print(min_midi_number)\n",
    "print(int_to_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utkar\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\utkar\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    values\n",
       "0         \n",
       "0        2\n",
       "1        3\n",
       "2        7\n",
       "3        2\n",
       "4       24\n",
       "5        3\n",
       "6       21\n",
       "7        4\n",
       "8       39\n",
       "9       96\n",
       "10      45\n",
       "11     273\n",
       "12      19\n",
       "13     368\n",
       "14     171\n",
       "15     353\n",
       "16     572\n",
       "17     112\n",
       "18     739\n",
       "19     103\n",
       "20     726\n",
       "21     565\n",
       "22     298\n",
       "23     960\n",
       "24      70\n",
       "25     684\n",
       "26     263\n",
       "27     343\n",
       "28     565\n",
       "29      30\n",
       "30     463\n",
       "31      32\n",
       "32     248\n",
       "33     144\n",
       "34      64\n",
       "35     164\n",
       "36      37\n",
       "37       5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 378
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "data is highly unbalanced\n",
    "# '''\n",
    "sns.distplot(torch.tensor(network_output).cpu())\n",
    "xx = pd.DataFrame(torch.tensor(network_output).cpu())\n",
    "xx.groupby(0).size().to_frame(name='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8500, 50, 1])\n",
      "torch.Size([8500])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "to make batch of equal sizes\n",
    "Quick Fix\n",
    "'''\n",
    "network_input = network_input[: -117]\n",
    "network_output = network_output[: -117]\n",
    "\n",
    "print(network_input.shape)\n",
    "print(network_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create Stacked LSTM model\n",
    "'''\n",
    "class Stacked_LSTM(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size = input_size, hidden_size = hidden_size, batch_first = True)\n",
    "        self.lstm2 = nn.LSTM(input_size = hidden_size, hidden_size = output_size,batch_first = True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(output_size, output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hidden1, hidden2,batch_size):\n",
    "        \n",
    "        output, _ = self.lstm1(x)        \n",
    "        #print(output.shape)\n",
    "        \n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        output, _ = self.lstm2(output)\n",
    "        #print(output.shape)\n",
    "        \n",
    "        # stack up lstm outputs\n",
    "        output = output.contiguous().view(-1, 38)\n",
    "        #print(output.shape)\n",
    "        \n",
    "        output = self.dropout(output)\n",
    "        output = self.linear(output)\n",
    "        #print('Linear Output :-',output.shape)\n",
    "        \n",
    "        #output = F.softmax(output, dim = 1)\n",
    "        #print('SOFTMAX OUTPUT :--', output)\n",
    "        \n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        output = output.view(batch_size, -1)\n",
    "        #print('Reshape to batch size first :-',output.shape)\n",
    "        \n",
    "        output = output[:, -self.output_size:] # get last batch of labels\n",
    "        #print('Final Output :-',output)\n",
    "        #print('RESHAPE SIZE :-', output.shape)\n",
    "        \n",
    "        return output, hidden2\n",
    "    \n",
    "    def hidden_init(self,batch_size):\n",
    "        \n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden1 = (weight.new(1, batch_size, self.hidden_size).zero_().cuda(),\n",
    "          weight.new(1, batch_size, self.hidden_size).zero_().cuda())\n",
    "        \n",
    "        hidden2 = (weight.new(1, batch_size, 38).zero_().cuda(),\n",
    "          weight.new(1, batch_size, 38).zero_().cuda())\n",
    "        return hidden1,hidden2\n",
    "\n",
    "#initialize the weights of LSTM using Xavier initialization    \n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Divide the dataset into train/val \n",
    "'''\n",
    "train_size = 0.8\n",
    "indices = list(range(len(network_input)))\n",
    "split = int(np.floor(train_size*len(network_input)))\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "train_sampler = SequentialSampler(train_idx)\n",
    "val_sampler = SequentialSampler(val_idx)\n",
    "\n",
    "dataset = TensorDataset(network_input,network_output)\n",
    "train_loader = DataLoader(dataset, batch_size= train_batch_size, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset, batch_size= val_batch_size,sampler= val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stacked_LSTM(\n",
       "  (lstm1): LSTM(1, 256, batch_first=True)\n",
       "  (lstm2): LSTM(256, 38, batch_first=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=38, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optimizer\n",
    "\n",
    "model = Stacked_LSTM(input_size,hidden_size,num_layer,output_size)\n",
    "model.apply(init_weights)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optimizer.AdamW(model.parameters())\n",
    "#optimizer = optimizer.RMSprop(model.parameters(), lr = 0.001, weight_decay = 0.01)\n",
    "\n",
    "\n",
    "#make sure to transfer model to GPU after initializing optimizer\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden = model.hidden_init(train_batch_size) \n",
    "#hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTrain Loss: 3.0305562 \tVal Loss:2.9375344 \tTrain Acc: 9.985294% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from    inf to 2.937534, saving the model weights\n",
      "Epoch: 1\tTrain Loss: 3.0294230 \tVal Loss:2.9288061 \tTrain Acc: 10.69118% \tVal Acc: 11.4117651%\n",
      "Validation Loss decreased from 2.937534 to 2.928806, saving the model weights\n",
      "Epoch: 2\tTrain Loss: 3.0119009 \tVal Loss:2.8572389 \tTrain Acc: 10.75% \tVal Acc: 13.0000003%\n",
      "Validation Loss decreased from 2.928806 to 2.857239, saving the model weights\n",
      "Epoch: 3\tTrain Loss: 2.9647393 \tVal Loss:2.8269452 \tTrain Acc: 10.98529% \tVal Acc: 12.4117650%\n",
      "Validation Loss decreased from 2.857239 to 2.826945, saving the model weights\n",
      "Epoch: 4\tTrain Loss: 2.8721788 \tVal Loss:2.7354527 \tTrain Acc: 12.47059% \tVal Acc: 12.9411768%\n",
      "Validation Loss decreased from 2.826945 to 2.735453, saving the model weights\n",
      "Epoch: 5\tTrain Loss: 2.8226022 \tVal Loss:2.6582330 \tTrain Acc: 12.85294% \tVal Acc: 13.4117650%\n",
      "Validation Loss decreased from 2.735453 to 2.658233, saving the model weights\n",
      "Epoch: 6\tTrain Loss: 2.7517486 \tVal Loss:2.6198016 \tTrain Acc: 14.41177% \tVal Acc: 13.1176474%\n",
      "Validation Loss decreased from 2.658233 to 2.619802, saving the model weights\n",
      "Epoch: 7\tTrain Loss: 2.6991816 \tVal Loss:2.6086248 \tTrain Acc: 14.41177% \tVal Acc: 14.5882357%\n",
      "Validation Loss decreased from 2.619802 to 2.608625, saving the model weights\n",
      "Epoch: 8\tTrain Loss: 2.6562797 \tVal Loss:2.5629522 \tTrain Acc: 15.17647% \tVal Acc: 14.9411769%\n",
      "Validation Loss decreased from 2.608625 to 2.562952, saving the model weights\n",
      "Epoch: 9\tTrain Loss: 2.6396327 \tVal Loss:2.5770116 \tTrain Acc: 15.08824% \tVal Acc: 14.5882357%\n",
      "Epoch: 10\tTrain Loss: 2.6095760 \tVal Loss:2.5342009 \tTrain Acc: 15.58824% \tVal Acc: 15.4117651%\n",
      "Validation Loss decreased from 2.562952 to 2.534201, saving the model weights\n",
      "Epoch: 11\tTrain Loss: 2.5746321 \tVal Loss:2.5206266 \tTrain Acc: 16.11765% \tVal Acc: 15.5882357%\n",
      "Validation Loss decreased from 2.534201 to 2.520627, saving the model weights\n",
      "Epoch: 12\tTrain Loss: 2.5691664 \tVal Loss:2.5111399 \tTrain Acc: 15.73529% \tVal Acc: 14.9411769%\n",
      "Validation Loss decreased from 2.520627 to 2.511140, saving the model weights\n",
      "Epoch: 13\tTrain Loss: 2.5600957 \tVal Loss:2.4819141 \tTrain Acc: 16.23529% \tVal Acc: 15.2941181%\n",
      "Validation Loss decreased from 2.511140 to 2.481914, saving the model weights\n",
      "Epoch: 14\tTrain Loss: 2.5391128 \tVal Loss:2.4772175 \tTrain Acc: 16.76471% \tVal Acc: 15.5294120%\n",
      "Validation Loss decreased from 2.481914 to 2.477217, saving the model weights\n",
      "Epoch: 15\tTrain Loss: 2.5302311 \tVal Loss:2.4625858 \tTrain Acc: 16.07353% \tVal Acc: 15.0000003%\n",
      "Validation Loss decreased from 2.477217 to 2.462586, saving the model weights\n",
      "Epoch: 16\tTrain Loss: 2.5228098 \tVal Loss:2.4587081 \tTrain Acc: 17.54412% \tVal Acc: 15.1176473%\n",
      "Validation Loss decreased from 2.462586 to 2.458708, saving the model weights\n",
      "Epoch: 17\tTrain Loss: 2.5076116 \tVal Loss:2.4550279 \tTrain Acc: 16.44118% \tVal Acc: 14.4705886%\n",
      "Validation Loss decreased from 2.458708 to 2.455028, saving the model weights\n",
      "Epoch: 18\tTrain Loss: 2.5098065 \tVal Loss:2.4504396 \tTrain Acc: 17.13235% \tVal Acc: 14.5294121%\n",
      "Validation Loss decreased from 2.455028 to 2.450440, saving the model weights\n",
      "Epoch: 19\tTrain Loss: 2.4915695 \tVal Loss:2.4514926 \tTrain Acc: 17.33824% \tVal Acc: 14.9411768%\n",
      "Epoch: 20\tTrain Loss: 2.4855975 \tVal Loss:2.4229758 \tTrain Acc: 17.66177% \tVal Acc: 14.8823532%\n",
      "Validation Loss decreased from 2.450440 to 2.422976, saving the model weights\n",
      "Epoch: 21\tTrain Loss: 2.4803486 \tVal Loss:2.4322336 \tTrain Acc: 17.48529% \tVal Acc: 15.1176473%\n",
      "Epoch: 22\tTrain Loss: 2.4737563 \tVal Loss:2.4264646 \tTrain Acc: 17.23529% \tVal Acc: 14.9411768%\n",
      "Epoch: 23\tTrain Loss: 2.4672545 \tVal Loss:2.4188483 \tTrain Acc: 17.57353% \tVal Acc: 15.3529415%\n",
      "Validation Loss decreased from 2.422976 to 2.418848, saving the model weights\n",
      "Epoch: 24\tTrain Loss: 2.4654266 \tVal Loss:2.4124331 \tTrain Acc: 17.54412% \tVal Acc: 15.7647064%\n",
      "Validation Loss decreased from 2.418848 to 2.412433, saving the model weights\n",
      "Epoch: 25\tTrain Loss: 2.4632127 \tVal Loss:2.4097081 \tTrain Acc: 17.85294% \tVal Acc: 16.8823534%\n",
      "Validation Loss decreased from 2.412433 to 2.409708, saving the model weights\n",
      "Epoch: 26\tTrain Loss: 2.4622460 \tVal Loss:2.4357568 \tTrain Acc: 17.72059% \tVal Acc: 15.0000004%\n",
      "Epoch: 27\tTrain Loss: 2.4566930 \tVal Loss:2.4102454 \tTrain Acc: 16.97059% \tVal Acc: 15.4705887%\n",
      "Epoch: 28\tTrain Loss: 2.4578418 \tVal Loss:2.4071887 \tTrain Acc: 17.20588% \tVal Acc: 15.9411769%\n",
      "Validation Loss decreased from 2.409708 to 2.407189, saving the model weights\n",
      "Epoch: 29\tTrain Loss: 2.4442407 \tVal Loss:2.4021778 \tTrain Acc: 17.91177% \tVal Acc: 14.9411769%\n",
      "Validation Loss decreased from 2.407189 to 2.402178, saving the model weights\n",
      "Epoch: 30\tTrain Loss: 2.4472567 \tVal Loss:2.4143470 \tTrain Acc: 17.67647% \tVal Acc: 15.3529416%\n",
      "Epoch: 31\tTrain Loss: 2.4392556 \tVal Loss:2.4015582 \tTrain Acc: 17.86765% \tVal Acc: 15.7647062%\n",
      "Validation Loss decreased from 2.402178 to 2.401558, saving the model weights\n",
      "Epoch: 32\tTrain Loss: 2.4368006 \tVal Loss:2.3911426 \tTrain Acc: 18.29412% \tVal Acc: 16.4117650%\n",
      "Validation Loss decreased from 2.401558 to 2.391143, saving the model weights\n",
      "Epoch: 33\tTrain Loss: 2.4377488 \tVal Loss:2.3987458 \tTrain Acc: 17.97059% \tVal Acc: 15.2941180%\n",
      "Epoch: 34\tTrain Loss: 2.4204136 \tVal Loss:2.4036522 \tTrain Acc: 18.39706% \tVal Acc: 15.7647062%\n",
      "Epoch: 35\tTrain Loss: 2.4264257 \tVal Loss:2.3942831 \tTrain Acc: 18.36765% \tVal Acc: 16.8235297%\n",
      "Epoch: 36\tTrain Loss: 2.4246678 \tVal Loss:2.3779974 \tTrain Acc: 18.38235% \tVal Acc: 16.0588239%\n",
      "Validation Loss decreased from 2.391143 to 2.377997, saving the model weights\n",
      "Epoch: 37\tTrain Loss: 2.4234071 \tVal Loss:2.3969678 \tTrain Acc: 18.27941% \tVal Acc: 17.4705886%\n",
      "Epoch: 38\tTrain Loss: 2.4234346 \tVal Loss:2.3823891 \tTrain Acc: 18.82353% \tVal Acc: 16.5294122%\n",
      "Epoch: 39\tTrain Loss: 2.4171806 \tVal Loss:2.3730091 \tTrain Acc: 18.98529% \tVal Acc: 16.7058827%\n",
      "Validation Loss decreased from 2.377997 to 2.373009, saving the model weights\n",
      "Epoch: 40\tTrain Loss: 2.4063381 \tVal Loss:2.3744203 \tTrain Acc: 18.83824% \tVal Acc: 16.7647063%\n",
      "Epoch: 41\tTrain Loss: 2.4089383 \tVal Loss:2.3802234 \tTrain Acc: 18.79412% \tVal Acc: 18.9411768%\n",
      "Epoch: 42\tTrain Loss: 2.4148729 \tVal Loss:2.3652661 \tTrain Acc: 19.07353% \tVal Acc: 17.1176475%\n",
      "Validation Loss decreased from 2.373009 to 2.365266, saving the model weights\n",
      "Epoch: 43\tTrain Loss: 2.4081638 \tVal Loss:2.3669262 \tTrain Acc: 19.33824% \tVal Acc: 17.5294122%\n",
      "Epoch: 44\tTrain Loss: 2.3909578 \tVal Loss:2.3597509 \tTrain Acc: 19.82353% \tVal Acc: 17.2352946%\n",
      "Validation Loss decreased from 2.365266 to 2.359751, saving the model weights\n",
      "Epoch: 45\tTrain Loss: 2.3920965 \tVal Loss:2.3455944 \tTrain Acc: 20.54412% \tVal Acc: 19.0588239%\n",
      "Validation Loss decreased from 2.359751 to 2.345594, saving the model weights\n",
      "Epoch: 46\tTrain Loss: 2.3758126 \tVal Loss:2.3612710 \tTrain Acc: 20.86765% \tVal Acc: 17.0588240%\n",
      "Epoch: 47\tTrain Loss: 2.3880669 \tVal Loss:2.3466855 \tTrain Acc: 19.66177% \tVal Acc: 17.6470593%\n",
      "Epoch: 48\tTrain Loss: 2.3765066 \tVal Loss:2.3439055 \tTrain Acc: 20.26471% \tVal Acc: 17.0000005%\n",
      "Validation Loss decreased from 2.345594 to 2.343905, saving the model weights\n",
      "Epoch: 49\tTrain Loss: 2.3820647 \tVal Loss:2.3517556 \tTrain Acc: 20.73529% \tVal Acc: 17.6470592%\n",
      "Epoch: 50\tTrain Loss: 2.3714692 \tVal Loss:2.3526910 \tTrain Acc: 20.17647% \tVal Acc: 15.8823535%\n",
      "Epoch: 51\tTrain Loss: 2.3683135 \tVal Loss:2.3377013 \tTrain Acc: 20.63235% \tVal Acc: 18.3529416%\n",
      "Validation Loss decreased from 2.343905 to 2.337701, saving the model weights\n",
      "Epoch: 52\tTrain Loss: 2.3633461 \tVal Loss:2.3385677 \tTrain Acc: 20.89706% \tVal Acc: 17.5882357%\n",
      "Epoch: 53\tTrain Loss: 2.3516758 \tVal Loss:2.3185591 \tTrain Acc: 21.63235% \tVal Acc: 18.6470592%\n",
      "Validation Loss decreased from 2.337701 to 2.318559, saving the model weights\n",
      "Epoch: 54\tTrain Loss: 2.3457151 \tVal Loss:2.3204376 \tTrain Acc: 21.55882% \tVal Acc: 17.9411769%\n",
      "Epoch: 55\tTrain Loss: 2.3422998 \tVal Loss:2.2979290 \tTrain Acc: 21.63235% \tVal Acc: 20.0000004%\n",
      "Validation Loss decreased from 2.318559 to 2.297929, saving the model weights\n",
      "Epoch: 56\tTrain Loss: 2.3288330 \tVal Loss:2.3197796 \tTrain Acc: 22.20588% \tVal Acc: 18.1764710%\n",
      "Epoch: 57\tTrain Loss: 2.3441080 \tVal Loss:2.3143074 \tTrain Acc: 22.23529% \tVal Acc: 17.7058828%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58\tTrain Loss: 2.3442806 \tVal Loss:2.3192040 \tTrain Acc: 22.0% \tVal Acc: 18.1764710%\n",
      "Epoch: 59\tTrain Loss: 2.3399081 \tVal Loss:2.3143006 \tTrain Acc: 21.19118% \tVal Acc: 17.9411769%\n",
      "Epoch: 60\tTrain Loss: 2.3416007 \tVal Loss:2.2969794 \tTrain Acc: 20.98529% \tVal Acc: 19.8235299%\n",
      "Validation Loss decreased from 2.297929 to 2.296979, saving the model weights\n",
      "Epoch: 61\tTrain Loss: 2.3137733 \tVal Loss:2.2814265 \tTrain Acc: 22.02941% \tVal Acc: 19.8235299%\n",
      "Validation Loss decreased from 2.296979 to 2.281427, saving the model weights\n",
      "Epoch: 62\tTrain Loss: 2.3186954 \tVal Loss:2.2859871 \tTrain Acc: 22.41177% \tVal Acc: 20.7647064%\n",
      "Epoch: 63\tTrain Loss: 2.3099184 \tVal Loss:2.2843409 \tTrain Acc: 22.82353% \tVal Acc: 20.0000003%\n",
      "Epoch: 64\tTrain Loss: 2.3079038 \tVal Loss:2.2862053 \tTrain Acc: 22.83824% \tVal Acc: 20.8823535%\n",
      "Epoch: 65\tTrain Loss: 2.3034010 \tVal Loss:2.2697633 \tTrain Acc: 22.83824% \tVal Acc: 21.4705886%\n",
      "Validation Loss decreased from 2.281427 to 2.269763, saving the model weights\n",
      "Epoch: 66\tTrain Loss: 2.2992722 \tVal Loss:2.2916211 \tTrain Acc: 23.17647% \tVal Acc: 17.9411769%\n",
      "Epoch: 67\tTrain Loss: 2.2913780 \tVal Loss:2.2740769 \tTrain Acc: 23.42647% \tVal Acc: 19.6470593%\n",
      "Epoch: 68\tTrain Loss: 2.2812439 \tVal Loss:2.2648244 \tTrain Acc: 23.98529% \tVal Acc: 20.2352946%\n",
      "Validation Loss decreased from 2.269763 to 2.264824, saving the model weights\n",
      "Epoch: 69\tTrain Loss: 2.2811934 \tVal Loss:2.2541021 \tTrain Acc: 23.85294% \tVal Acc: 20.1764710%\n",
      "Validation Loss decreased from 2.264824 to 2.254102, saving the model weights\n",
      "Epoch: 70\tTrain Loss: 2.2844952 \tVal Loss:2.2384554 \tTrain Acc: 23.13235% \tVal Acc: 22.0000003%\n",
      "Validation Loss decreased from 2.254102 to 2.238455, saving the model weights\n",
      "Epoch: 71\tTrain Loss: 2.2770678 \tVal Loss:2.2334702 \tTrain Acc: 23.45588% \tVal Acc: 21.5294121%\n",
      "Validation Loss decreased from 2.238455 to 2.233470, saving the model weights\n",
      "Epoch: 72\tTrain Loss: 2.2837037 \tVal Loss:2.2362448 \tTrain Acc: 23.20588% \tVal Acc: 23.5294123%\n",
      "Epoch: 73\tTrain Loss: 2.2714823 \tVal Loss:2.2106192 \tTrain Acc: 23.80882% \tVal Acc: 24.2941184%\n",
      "Validation Loss decreased from 2.233470 to 2.210619, saving the model weights\n",
      "Epoch: 74\tTrain Loss: 2.2707121 \tVal Loss:2.2031872 \tTrain Acc: 24.08824% \tVal Acc: 27.3529424%\n",
      "Validation Loss decreased from 2.210619 to 2.203187, saving the model weights\n",
      "Epoch: 75\tTrain Loss: 2.2723868 \tVal Loss:2.2157328 \tTrain Acc: 22.98529% \tVal Acc: 24.8823538%\n",
      "Epoch: 76\tTrain Loss: 2.2593476 \tVal Loss:2.2146214 \tTrain Acc: 24.54412% \tVal Acc: 24.8823538%\n",
      "Epoch: 77\tTrain Loss: 2.2504529 \tVal Loss:2.2034156 \tTrain Acc: 24.89706% \tVal Acc: 24.4117655%\n",
      "Epoch: 78\tTrain Loss: 2.2480261 \tVal Loss:2.2006162 \tTrain Acc: 25.01471% \tVal Acc: 23.5294120%\n",
      "Validation Loss decreased from 2.203187 to 2.200616, saving the model weights\n",
      "Epoch: 79\tTrain Loss: 2.2391987 \tVal Loss:2.1852497 \tTrain Acc: 25.48529% \tVal Acc: 25.2941182%\n",
      "Validation Loss decreased from 2.200616 to 2.185250, saving the model weights\n",
      "Epoch: 80\tTrain Loss: 2.2317876 \tVal Loss:2.1851583 \tTrain Acc: 24.89706% \tVal Acc: 26.0588245%\n",
      "Validation Loss decreased from 2.185250 to 2.185158, saving the model weights\n",
      "Epoch: 81\tTrain Loss: 2.2330132 \tVal Loss:2.1730550 \tTrain Acc: 25.36765% \tVal Acc: 25.1176478%\n",
      "Validation Loss decreased from 2.185158 to 2.173055, saving the model weights\n",
      "Epoch: 82\tTrain Loss: 2.2127528 \tVal Loss:2.1682770 \tTrain Acc: 25.66177% \tVal Acc: 25.9411775%\n",
      "Validation Loss decreased from 2.173055 to 2.168277, saving the model weights\n",
      "Epoch: 83\tTrain Loss: 2.2235177 \tVal Loss:2.1861334 \tTrain Acc: 25.55882% \tVal Acc: 25.4117656%\n",
      "Epoch: 84\tTrain Loss: 2.2292563 \tVal Loss:2.1868462 \tTrain Acc: 25.5% \tVal Acc: 26.4705892%\n",
      "Epoch: 85\tTrain Loss: 2.2103900 \tVal Loss:2.1500700 \tTrain Acc: 26.63235% \tVal Acc: 25.7647067%\n",
      "Validation Loss decreased from 2.168277 to 2.150070, saving the model weights\n",
      "Epoch: 86\tTrain Loss: 2.1983494 \tVal Loss:2.1332889 \tTrain Acc: 26.48529% \tVal Acc: 28.2941186%\n",
      "Validation Loss decreased from 2.150070 to 2.133289, saving the model weights\n",
      "Epoch: 87\tTrain Loss: 2.1839590 \tVal Loss:2.1332239 \tTrain Acc: 26.72059% \tVal Acc: 27.5294128%\n",
      "Validation Loss decreased from 2.133289 to 2.133224, saving the model weights\n",
      "Epoch: 88\tTrain Loss: 2.1826140 \tVal Loss:2.1136906 \tTrain Acc: 26.92647% \tVal Acc: 30.3529422%\n",
      "Validation Loss decreased from 2.133224 to 2.113691, saving the model weights\n",
      "Epoch: 89\tTrain Loss: 2.1812955 \tVal Loss:2.1216659 \tTrain Acc: 27.48529% \tVal Acc: 30.4705893%\n",
      "Epoch: 90\tTrain Loss: 2.1788718 \tVal Loss:2.1213853 \tTrain Acc: 27.5% \tVal Acc: 30.1764716%\n",
      "Epoch: 91\tTrain Loss: 2.1730595 \tVal Loss:2.1343894 \tTrain Acc: 27.19118% \tVal Acc: 27.7058832%\n",
      "Epoch: 92\tTrain Loss: 2.1590036 \tVal Loss:2.1115458 \tTrain Acc: 28.08824% \tVal Acc: 28.1764714%\n",
      "Validation Loss decreased from 2.113691 to 2.111546, saving the model weights\n",
      "Epoch: 93\tTrain Loss: 2.1715548 \tVal Loss:2.1004586 \tTrain Acc: 27.01471% \tVal Acc: 29.7058834%\n",
      "Validation Loss decreased from 2.111546 to 2.100459, saving the model weights\n",
      "Epoch: 94\tTrain Loss: 2.1501021 \tVal Loss:2.0834568 \tTrain Acc: 28.44118% \tVal Acc: 30.0000010%\n",
      "Validation Loss decreased from 2.100459 to 2.083457, saving the model weights\n",
      "Epoch: 95\tTrain Loss: 2.1315943 \tVal Loss:2.0919797 \tTrain Acc: 28.66177% \tVal Acc: 28.7058832%\n",
      "Epoch: 96\tTrain Loss: 2.1348781 \tVal Loss:2.1073291 \tTrain Acc: 28.95588% \tVal Acc: 30.1176481%\n",
      "Epoch: 97\tTrain Loss: 2.1269509 \tVal Loss:2.0885618 \tTrain Acc: 28.72059% \tVal Acc: 29.8235303%\n",
      "Epoch: 98\tTrain Loss: 2.1260671 \tVal Loss:2.0666330 \tTrain Acc: 29.89706% \tVal Acc: 31.8823539%\n",
      "Validation Loss decreased from 2.083457 to 2.066633, saving the model weights\n",
      "Epoch: 99\tTrain Loss: 2.1183507 \tVal Loss:2.1288682 \tTrain Acc: 30.10294% \tVal Acc: 28.2941186%\n",
      "Epoch: 100\tTrain Loss: 2.1181249 \tVal Loss:2.1084404 \tTrain Acc: 28.54412% \tVal Acc: 29.4705890%\n",
      "Epoch: 101\tTrain Loss: 2.1458984 \tVal Loss:2.1193556 \tTrain Acc: 27.92647% \tVal Acc: 28.8235304%\n",
      "Epoch: 102\tTrain Loss: 2.1311791 \tVal Loss:2.0849857 \tTrain Acc: 28.47059% \tVal Acc: 32.0000011%\n",
      "Epoch: 103\tTrain Loss: 2.1137464 \tVal Loss:2.0832667 \tTrain Acc: 29.42647% \tVal Acc: 30.5882360%\n",
      "Epoch: 104\tTrain Loss: 2.0912060 \tVal Loss:2.1141088 \tTrain Acc: 30.5% \tVal Acc: 29.7058833%\n",
      "Epoch: 105\tTrain Loss: 2.0877288 \tVal Loss:2.1061335 \tTrain Acc: 30.75% \tVal Acc: 29.4117655%\n",
      "Epoch: 106\tTrain Loss: 2.1078605 \tVal Loss:2.0919323 \tTrain Acc: 29.94118% \tVal Acc: 29.8235303%\n",
      "Epoch: 107\tTrain Loss: 2.0920181 \tVal Loss:2.1617353 \tTrain Acc: 30.02941% \tVal Acc: 27.8823535%\n",
      "Epoch: 108\tTrain Loss: 2.1042158 \tVal Loss:2.1284158 \tTrain Acc: 30.30882% \tVal Acc: 28.7058832%\n",
      "Epoch: 109\tTrain Loss: 2.1117301 \tVal Loss:2.1406283 \tTrain Acc: 29.01471% \tVal Acc: 28.8235301%\n",
      "Epoch: 110\tTrain Loss: 2.1325105 \tVal Loss:2.1174327 \tTrain Acc: 28.77941% \tVal Acc: 30.1176478%\n",
      "Epoch: 111\tTrain Loss: 2.1386876 \tVal Loss:2.0351352 \tTrain Acc: 28.26471% \tVal Acc: 31.8823540%\n",
      "Validation Loss decreased from 2.066633 to 2.035135, saving the model weights\n",
      "Epoch: 112\tTrain Loss: 2.1152008 \tVal Loss:1.9918729 \tTrain Acc: 28.61765% \tVal Acc: 35.0588244%\n",
      "Validation Loss decreased from 2.035135 to 1.991873, saving the model weights\n",
      "Epoch: 113\tTrain Loss: 2.1237447 \tVal Loss:1.9468407 \tTrain Acc: 28.89706% \tVal Acc: 38.3529419%\n",
      "Validation Loss decreased from 1.991873 to 1.946841, saving the model weights\n",
      "Epoch: 114\tTrain Loss: 2.0770253 \tVal Loss:1.9844963 \tTrain Acc: 30.52941% \tVal Acc: 36.7058831%\n",
      "Epoch: 115\tTrain Loss: 2.0578005 \tVal Loss:1.9600676 \tTrain Acc: 31.79412% \tVal Acc: 35.5882362%\n",
      "Epoch: 116\tTrain Loss: 2.0111221 \tVal Loss:1.9379756 \tTrain Acc: 32.82353% \tVal Acc: 36.9411772%\n",
      "Validation Loss decreased from 1.946841 to 1.937976, saving the model weights\n",
      "Epoch: 117\tTrain Loss: 1.9773916 \tVal Loss:1.9107342 \tTrain Acc: 34.54412% \tVal Acc: 36.3529420%\n",
      "Validation Loss decreased from 1.937976 to 1.910734, saving the model weights\n",
      "Epoch: 118\tTrain Loss: 1.9873726 \tVal Loss:1.9231065 \tTrain Acc: 34.11765% \tVal Acc: 37.3529419%\n",
      "Epoch: 119\tTrain Loss: 1.9438247 \tVal Loss:1.8904938 \tTrain Acc: 35.86765% \tVal Acc: 39.8235300%\n",
      "Validation Loss decreased from 1.910734 to 1.890494, saving the model weights\n",
      "Epoch: 120\tTrain Loss: 1.9412106 \tVal Loss:1.8993117 \tTrain Acc: 34.72059% \tVal Acc: 37.4705890%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 121\tTrain Loss: 1.9441544 \tVal Loss:1.8723162 \tTrain Acc: 35.44118% \tVal Acc: 38.4705889%\n",
      "Validation Loss decreased from 1.890494 to 1.872316, saving the model weights\n",
      "Epoch: 122\tTrain Loss: 1.9420622 \tVal Loss:1.8696297 \tTrain Acc: 34.47059% \tVal Acc: 37.5882360%\n",
      "Validation Loss decreased from 1.872316 to 1.869630, saving the model weights\n",
      "Epoch: 123\tTrain Loss: 1.9517780 \tVal Loss:1.8767270 \tTrain Acc: 34.57353% \tVal Acc: 37.6470596%\n",
      "Epoch: 124\tTrain Loss: 1.9218104 \tVal Loss:1.8707884 \tTrain Acc: 35.58824% \tVal Acc: 40.3529418%\n",
      "Epoch: 125\tTrain Loss: 1.9301995 \tVal Loss:1.7915739 \tTrain Acc: 35.02941% \tVal Acc: 41.1176476%\n",
      "Validation Loss decreased from 1.869630 to 1.791574, saving the model weights\n",
      "Epoch: 126\tTrain Loss: 1.8993551 \tVal Loss:1.7970177 \tTrain Acc: 36.88235% \tVal Acc: 41.3529420%\n",
      "Epoch: 127\tTrain Loss: 1.8861517 \tVal Loss:1.7883075 \tTrain Acc: 36.86765% \tVal Acc: 41.5882361%\n",
      "Validation Loss decreased from 1.791574 to 1.788307, saving the model weights\n",
      "Epoch: 128\tTrain Loss: 1.8886306 \tVal Loss:1.8124743 \tTrain Acc: 37.61765% \tVal Acc: 41.5294123%\n",
      "Epoch: 129\tTrain Loss: 1.8847336 \tVal Loss:1.8066961 \tTrain Acc: 36.73529% \tVal Acc: 40.0588244%\n",
      "Epoch: 130\tTrain Loss: 1.8892653 \tVal Loss:1.7934442 \tTrain Acc: 37.30882% \tVal Acc: 39.6470594%\n",
      "Epoch: 131\tTrain Loss: 1.8691694 \tVal Loss:1.7670935 \tTrain Acc: 37.35294% \tVal Acc: 41.5882361%\n",
      "Validation Loss decreased from 1.788307 to 1.767093, saving the model weights\n",
      "Epoch: 132\tTrain Loss: 1.8531364 \tVal Loss:1.8083704 \tTrain Acc: 38.44118% \tVal Acc: 39.5294124%\n",
      "Epoch: 133\tTrain Loss: 1.8722423 \tVal Loss:1.7759040 \tTrain Acc: 36.55882% \tVal Acc: 41.8235299%\n",
      "Epoch: 134\tTrain Loss: 1.8488724 \tVal Loss:1.7753332 \tTrain Acc: 38.35294% \tVal Acc: 42.1176478%\n",
      "Epoch: 135\tTrain Loss: 1.8392029 \tVal Loss:1.7304084 \tTrain Acc: 38.14706% \tVal Acc: 42.8823534%\n",
      "Validation Loss decreased from 1.767093 to 1.730408, saving the model weights\n",
      "Epoch: 136\tTrain Loss: 1.8357883 \tVal Loss:1.7308467 \tTrain Acc: 38.25% \tVal Acc: 43.2352948%\n",
      "Epoch: 137\tTrain Loss: 1.7977027 \tVal Loss:1.6955479 \tTrain Acc: 39.82353% \tVal Acc: 44.8823532%\n",
      "Validation Loss decreased from 1.730408 to 1.695548, saving the model weights\n",
      "Epoch: 138\tTrain Loss: 1.7887425 \tVal Loss:1.6525119 \tTrain Acc: 39.91177% \tVal Acc: 47.5882360%\n",
      "Validation Loss decreased from 1.695548 to 1.652512, saving the model weights\n",
      "Epoch: 139\tTrain Loss: 1.7679745 \tVal Loss:1.6839204 \tTrain Acc: 41.36765% \tVal Acc: 45.2941179%\n",
      "Epoch: 140\tTrain Loss: 1.7867328 \tVal Loss:1.6980479 \tTrain Acc: 41.30882% \tVal Acc: 45.9411767%\n",
      "Epoch: 141\tTrain Loss: 1.7742474 \tVal Loss:1.6941471 \tTrain Acc: 41.22059% \tVal Acc: 45.7058832%\n",
      "Epoch: 142\tTrain Loss: 1.7576476 \tVal Loss:1.6279021 \tTrain Acc: 41.52941% \tVal Acc: 49.5882359%\n",
      "Validation Loss decreased from 1.652512 to 1.627902, saving the model weights\n",
      "Epoch: 143\tTrain Loss: 1.7434619 \tVal Loss:1.6154323 \tTrain Acc: 41.41177% \tVal Acc: 49.0000004%\n",
      "Validation Loss decreased from 1.627902 to 1.615432, saving the model weights\n",
      "Epoch: 144\tTrain Loss: 1.7327467 \tVal Loss:1.6417503 \tTrain Acc: 41.69118% \tVal Acc: 46.8235299%\n",
      "Epoch: 145\tTrain Loss: 1.7230762 \tVal Loss:1.6102254 \tTrain Acc: 42.51471% \tVal Acc: 50.7647064%\n",
      "Validation Loss decreased from 1.615432 to 1.610225, saving the model weights\n",
      "Epoch: 146\tTrain Loss: 1.7311977 \tVal Loss:1.5728813 \tTrain Acc: 42.11765% \tVal Acc: 49.0588236%\n",
      "Validation Loss decreased from 1.610225 to 1.572881, saving the model weights\n",
      "Epoch: 147\tTrain Loss: 1.7067447 \tVal Loss:1.5445170 \tTrain Acc: 43.88235% \tVal Acc: 50.8823538%\n",
      "Validation Loss decreased from 1.572881 to 1.544517, saving the model weights\n",
      "Epoch: 148\tTrain Loss: 1.6766842 \tVal Loss:1.5413266 \tTrain Acc: 43.70588% \tVal Acc: 51.1764717%\n",
      "Validation Loss decreased from 1.544517 to 1.541327, saving the model weights\n",
      "Epoch: 149\tTrain Loss: 1.6750283 \tVal Loss:1.4962135 \tTrain Acc: 44.29412% \tVal Acc: 52.8235301%\n",
      "Validation Loss decreased from 1.541327 to 1.496214, saving the model weights\n",
      "Epoch: 150\tTrain Loss: 1.6653362 \tVal Loss:1.5698010 \tTrain Acc: 45.08824% \tVal Acc: 49.5882362%\n",
      "Epoch: 151\tTrain Loss: 1.6628053 \tVal Loss:1.5194303 \tTrain Acc: 44.01471% \tVal Acc: 52.3529428%\n",
      "Epoch: 152\tTrain Loss: 1.6488560 \tVal Loss:1.5005669 \tTrain Acc: 44.73529% \tVal Acc: 51.7058828%\n",
      "Epoch: 153\tTrain Loss: 1.6459561 \tVal Loss:1.5020599 \tTrain Acc: 45.75% \tVal Acc: 50.8823535%\n",
      "Epoch: 154\tTrain Loss: 1.6164026 \tVal Loss:1.4579196 \tTrain Acc: 45.95588% \tVal Acc: 54.9411780%\n",
      "Validation Loss decreased from 1.496214 to 1.457920, saving the model weights\n",
      "Epoch: 155\tTrain Loss: 1.6135638 \tVal Loss:1.4770038 \tTrain Acc: 46.17647% \tVal Acc: 54.0588248%\n",
      "Epoch: 156\tTrain Loss: 1.6149369 \tVal Loss:1.4330184 \tTrain Acc: 46.77941% \tVal Acc: 54.1176474%\n",
      "Validation Loss decreased from 1.457920 to 1.433018, saving the model weights\n",
      "Epoch: 157\tTrain Loss: 1.5890109 \tVal Loss:1.4626129 \tTrain Acc: 47.07353% \tVal Acc: 52.8235307%\n",
      "Epoch: 158\tTrain Loss: 1.5779242 \tVal Loss:1.4099420 \tTrain Acc: 47.86765% \tVal Acc: 54.9411777%\n",
      "Validation Loss decreased from 1.433018 to 1.409942, saving the model weights\n",
      "Epoch: 159\tTrain Loss: 1.5812808 \tVal Loss:1.4003966 \tTrain Acc: 47.23529% \tVal Acc: 54.5294124%\n",
      "Validation Loss decreased from 1.409942 to 1.400397, saving the model weights\n",
      "Epoch: 160\tTrain Loss: 1.5588152 \tVal Loss:1.4140286 \tTrain Acc: 47.95588% \tVal Acc: 55.8235300%\n",
      "Epoch: 161\tTrain Loss: 1.5601007 \tVal Loss:1.3649565 \tTrain Acc: 47.83824% \tVal Acc: 57.4705884%\n",
      "Validation Loss decreased from 1.400397 to 1.364956, saving the model weights\n",
      "Epoch: 162\tTrain Loss: 1.5393776 \tVal Loss:1.3397196 \tTrain Acc: 49.05882% \tVal Acc: 58.5294133%\n",
      "Validation Loss decreased from 1.364956 to 1.339720, saving the model weights\n",
      "Epoch: 163\tTrain Loss: 1.5226008 \tVal Loss:1.3461298 \tTrain Acc: 50.02941% \tVal Acc: 57.6470605%\n",
      "Epoch: 164\tTrain Loss: 1.5187078 \tVal Loss:1.3340601 \tTrain Acc: 49.41177% \tVal Acc: 57.4117658%\n",
      "Validation Loss decreased from 1.339720 to 1.334060, saving the model weights\n",
      "Epoch: 165\tTrain Loss: 1.5093370 \tVal Loss:1.3358315 \tTrain Acc: 49.94118% \tVal Acc: 59.7647062%\n",
      "Epoch: 166\tTrain Loss: 1.5059167 \tVal Loss:1.3513807 \tTrain Acc: 50.35294% \tVal Acc: 57.9411772%\n",
      "Epoch: 167\tTrain Loss: 1.5054577 \tVal Loss:1.3124416 \tTrain Acc: 50.14706% \tVal Acc: 59.2352951%\n",
      "Validation Loss decreased from 1.334060 to 1.312442, saving the model weights\n",
      "Epoch: 168\tTrain Loss: 1.5048869 \tVal Loss:1.3190677 \tTrain Acc: 50.55882% \tVal Acc: 59.0588239%\n",
      "Epoch: 169\tTrain Loss: 1.5013653 \tVal Loss:1.3805271 \tTrain Acc: 50.32353% \tVal Acc: 56.6470599%\n",
      "Epoch: 170\tTrain Loss: 1.4857283 \tVal Loss:1.3346486 \tTrain Acc: 51.0% \tVal Acc: 56.7647064%\n",
      "Epoch: 171\tTrain Loss: 1.4673038 \tVal Loss:1.3479686 \tTrain Acc: 51.57353% \tVal Acc: 58.0588251%\n",
      "Epoch: 172\tTrain Loss: 1.4617367 \tVal Loss:1.3556829 \tTrain Acc: 51.98529% \tVal Acc: 57.7647066%\n",
      "Epoch: 173\tTrain Loss: 1.4645583 \tVal Loss:1.3384919 \tTrain Acc: 52.07353% \tVal Acc: 58.6470592%\n",
      "Epoch: 174\tTrain Loss: 1.4727812 \tVal Loss:1.3874807 \tTrain Acc: 51.38235% \tVal Acc: 57.5882360%\n",
      "Epoch: 175\tTrain Loss: 1.4418988 \tVal Loss:1.3088288 \tTrain Acc: 53.36765% \tVal Acc: 59.5294127%\n",
      "Validation Loss decreased from 1.312442 to 1.308829, saving the model weights\n",
      "Epoch: 176\tTrain Loss: 1.4412868 \tVal Loss:1.3294882 \tTrain Acc: 53.17647% \tVal Acc: 59.0588251%\n",
      "Epoch: 177\tTrain Loss: 1.4112609 \tVal Loss:1.3654339 \tTrain Acc: 53.77941% \tVal Acc: 58.1176472%\n",
      "Epoch: 178\tTrain Loss: 1.4131189 \tVal Loss:1.3520267 \tTrain Acc: 54.33824% \tVal Acc: 56.5882361%\n",
      "Epoch: 179\tTrain Loss: 1.3981240 \tVal Loss:1.2767816 \tTrain Acc: 53.58824% \tVal Acc: 61.2941191%\n",
      "Validation Loss decreased from 1.308829 to 1.276782, saving the model weights\n",
      "Epoch: 180\tTrain Loss: 1.3744106 \tVal Loss:1.2940491 \tTrain Acc: 54.82353% \tVal Acc: 60.0000012%\n",
      "Epoch: 181\tTrain Loss: 1.3620395 \tVal Loss:1.3161834 \tTrain Acc: 56.38235% \tVal Acc: 59.7058827%\n",
      "Epoch: 182\tTrain Loss: 1.3792097 \tVal Loss:1.2519684 \tTrain Acc: 54.97059% \tVal Acc: 60.5294126%\n",
      "Validation Loss decreased from 1.276782 to 1.251968, saving the model weights\n",
      "Epoch: 183\tTrain Loss: 1.3563340 \tVal Loss:1.2643740 \tTrain Acc: 56.07353% \tVal Acc: 61.8235296%\n",
      "Epoch: 184\tTrain Loss: 1.3375846 \tVal Loss:1.1506651 \tTrain Acc: 56.23529% \tVal Acc: 65.2352953%\n",
      "Validation Loss decreased from 1.251968 to 1.150665, saving the model weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 185\tTrain Loss: 1.2932688 \tVal Loss:1.0886159 \tTrain Acc: 57.91177% \tVal Acc: 65.5882353%\n",
      "Validation Loss decreased from 1.150665 to 1.088616, saving the model weights\n",
      "Epoch: 186\tTrain Loss: 1.2827869 \tVal Loss:1.0900188 \tTrain Acc: 57.92647% \tVal Acc: 65.2941179%\n",
      "Epoch: 187\tTrain Loss: 1.3097592 \tVal Loss:1.1367617 \tTrain Acc: 57.01471% \tVal Acc: 65.8235294%\n",
      "Epoch: 188\tTrain Loss: 1.3441963 \tVal Loss:1.0675265 \tTrain Acc: 55.89706% \tVal Acc: 66.1176473%\n",
      "Validation Loss decreased from 1.088616 to 1.067527, saving the model weights\n",
      "Epoch: 189\tTrain Loss: 1.3046138 \tVal Loss:1.0420449 \tTrain Acc: 56.98529% \tVal Acc: 68.5882360%\n",
      "Validation Loss decreased from 1.067527 to 1.042045, saving the model weights\n",
      "Epoch: 190\tTrain Loss: 1.2720761 \tVal Loss:1.0560046 \tTrain Acc: 58.57353% \tVal Acc: 68.0588245%\n",
      "Epoch: 191\tTrain Loss: 1.2491718 \tVal Loss:0.9551613 \tTrain Acc: 59.0% \tVal Acc: 71.8235296%\n",
      "Validation Loss decreased from 1.042045 to 0.955161, saving the model weights\n",
      "Epoch: 192\tTrain Loss: 1.2331828 \tVal Loss:1.0144223 \tTrain Acc: 60.48529% \tVal Acc: 69.2941177%\n",
      "Epoch: 193\tTrain Loss: 1.2071778 \tVal Loss:1.0100081 \tTrain Acc: 60.92647% \tVal Acc: 69.2352939%\n",
      "Epoch: 194\tTrain Loss: 1.1902645 \tVal Loss:0.9893011 \tTrain Acc: 60.94118% \tVal Acc: 69.2941177%\n",
      "Epoch: 195\tTrain Loss: 1.1979530 \tVal Loss:0.9552997 \tTrain Acc: 61.02941% \tVal Acc: 72.0000011%\n",
      "Epoch: 196\tTrain Loss: 1.1677578 \tVal Loss:1.0145809 \tTrain Acc: 62.11765% \tVal Acc: 69.7647059%\n",
      "Epoch: 197\tTrain Loss: 1.1820286 \tVal Loss:0.9113579 \tTrain Acc: 61.77941% \tVal Acc: 73.9411759%\n",
      "Validation Loss decreased from 0.955161 to 0.911358, saving the model weights\n",
      "Epoch: 198\tTrain Loss: 1.1605773 \tVal Loss:0.9496664 \tTrain Acc: 62.60294% \tVal Acc: 72.1764708%\n",
      "Epoch: 199\tTrain Loss: 1.1725017 \tVal Loss:0.8739165 \tTrain Acc: 61.42647% \tVal Acc: 75.1764709%\n",
      "Validation Loss decreased from 0.911358 to 0.873916, saving the model weights\n",
      "Epoch: 200\tTrain Loss: 1.1373973 \tVal Loss:0.8770327 \tTrain Acc: 62.82353% \tVal Acc: 75.2352935%\n",
      "Epoch: 201\tTrain Loss: 1.1406018 \tVal Loss:0.8774761 \tTrain Acc: 62.45588% \tVal Acc: 74.2941177%\n",
      "Epoch: 202\tTrain Loss: 1.1061384 \tVal Loss:0.8902430 \tTrain Acc: 63.54412% \tVal Acc: 73.0000001%\n",
      "Epoch: 203\tTrain Loss: 1.0933195 \tVal Loss:0.9397865 \tTrain Acc: 65.05882% \tVal Acc: 72.0000005%\n",
      "Epoch: 204\tTrain Loss: 1.0991933 \tVal Loss:0.9563287 \tTrain Acc: 64.23529% \tVal Acc: 72.7647054%\n",
      "Epoch: 205\tTrain Loss: 1.1102050 \tVal Loss:0.9398537 \tTrain Acc: 64.44118% \tVal Acc: 73.1764698%\n",
      "Epoch: 206\tTrain Loss: 1.0955859 \tVal Loss:0.8130437 \tTrain Acc: 63.98529% \tVal Acc: 78.0000001%\n",
      "Validation Loss decreased from 0.873916 to 0.813044, saving the model weights\n",
      "Epoch: 207\tTrain Loss: 1.0584839 \tVal Loss:0.8384517 \tTrain Acc: 67.19118% \tVal Acc: 76.1176479%\n",
      "Epoch: 208\tTrain Loss: 1.0362595 \tVal Loss:0.7614802 \tTrain Acc: 66.76471% \tVal Acc: 79.1176462%\n",
      "Validation Loss decreased from 0.813044 to 0.761480, saving the model weights\n",
      "Epoch: 209\tTrain Loss: 1.0205277 \tVal Loss:0.7330118 \tTrain Acc: 66.82353% \tVal Acc: 79.5882344%\n",
      "Validation Loss decreased from 0.761480 to 0.733012, saving the model weights\n",
      "Epoch: 210\tTrain Loss: 1.0175882 \tVal Loss:0.7145846 \tTrain Acc: 67.70588% \tVal Acc: 81.4705884%\n",
      "Validation Loss decreased from 0.733012 to 0.714585, saving the model weights\n",
      "Epoch: 211\tTrain Loss: 1.0195378 \tVal Loss:0.7416017 \tTrain Acc: 67.22059% \tVal Acc: 79.1176468%\n",
      "Epoch: 212\tTrain Loss: 1.0076502 \tVal Loss:0.7205750 \tTrain Acc: 67.5% \tVal Acc: 79.2352933%\n",
      "Epoch: 213\tTrain Loss: 1.0165900 \tVal Loss:0.7066649 \tTrain Acc: 66.77941% \tVal Acc: 79.8235285%\n",
      "Validation Loss decreased from 0.714585 to 0.706665, saving the model weights\n",
      "Epoch: 214\tTrain Loss: 0.9789810 \tVal Loss:0.7221394 \tTrain Acc: 69.08824% \tVal Acc: 78.6470586%\n",
      "Epoch: 215\tTrain Loss: 0.9772514 \tVal Loss:0.7903546 \tTrain Acc: 69.10294% \tVal Acc: 78.0000001%\n",
      "Epoch: 216\tTrain Loss: 0.9580545 \tVal Loss:0.8126707 \tTrain Acc: 68.89706% \tVal Acc: 77.0588243%\n",
      "Epoch: 217\tTrain Loss: 0.9657043 \tVal Loss:0.7900500 \tTrain Acc: 68.57353% \tVal Acc: 78.0588239%\n",
      "Epoch: 218\tTrain Loss: 0.9663501 \tVal Loss:0.7196760 \tTrain Acc: 68.66177% \tVal Acc: 79.9411762%\n",
      "Epoch: 219\tTrain Loss: 0.9446878 \tVal Loss:0.6940844 \tTrain Acc: 69.98529% \tVal Acc: 80.1764703%\n",
      "Validation Loss decreased from 0.706665 to 0.694084, saving the model weights\n",
      "Epoch: 220\tTrain Loss: 0.9480686 \tVal Loss:0.6633343 \tTrain Acc: 69.51471% \tVal Acc: 80.8823526%\n",
      "Validation Loss decreased from 0.694084 to 0.663334, saving the model weights\n",
      "Epoch: 221\tTrain Loss: 0.9269503 \tVal Loss:0.6811372 \tTrain Acc: 70.26471% \tVal Acc: 80.8823520%\n",
      "Epoch: 222\tTrain Loss: 0.9253623 \tVal Loss:0.6921682 \tTrain Acc: 71.02941% \tVal Acc: 80.7058823%\n",
      "Epoch: 223\tTrain Loss: 0.9143676 \tVal Loss:0.7025743 \tTrain Acc: 71.30882% \tVal Acc: 79.7647047%\n",
      "Epoch: 224\tTrain Loss: 0.9082451 \tVal Loss:0.7394628 \tTrain Acc: 70.88235% \tVal Acc: 78.4117639%\n",
      "Epoch: 225\tTrain Loss: 0.8850038 \tVal Loss:0.7529166 \tTrain Acc: 71.44118% \tVal Acc: 77.8235292%\n",
      "Epoch: 226\tTrain Loss: 0.8860661 \tVal Loss:0.6423795 \tTrain Acc: 71.73529% \tVal Acc: 82.1764708%\n",
      "Validation Loss decreased from 0.663334 to 0.642379, saving the model weights\n",
      "Epoch: 227\tTrain Loss: 0.8738579 \tVal Loss:0.6529671 \tTrain Acc: 72.75% \tVal Acc: 81.7647052%\n",
      "Epoch: 228\tTrain Loss: 0.8677592 \tVal Loss:0.6528468 \tTrain Acc: 72.14706% \tVal Acc: 80.7058823%\n",
      "Epoch: 229\tTrain Loss: 0.8551290 \tVal Loss:0.6142841 \tTrain Acc: 72.86765% \tVal Acc: 82.6470584%\n",
      "Validation Loss decreased from 0.642379 to 0.614284, saving the model weights\n",
      "Epoch: 230\tTrain Loss: 0.8484020 \tVal Loss:0.6721376 \tTrain Acc: 73.11765% \tVal Acc: 81.4705878%\n",
      "Epoch: 231\tTrain Loss: 0.8133613 \tVal Loss:0.5922663 \tTrain Acc: 74.25% \tVal Acc: 84.0588230%\n",
      "Validation Loss decreased from 0.614284 to 0.592266, saving the model weights\n",
      "Epoch: 232\tTrain Loss: 0.8061741 \tVal Loss:0.5935795 \tTrain Acc: 74.67647% \tVal Acc: 83.4117639%\n",
      "Epoch: 233\tTrain Loss: 0.7994412 \tVal Loss:0.6091531 \tTrain Acc: 74.05882% \tVal Acc: 83.9411753%\n",
      "Epoch: 234\tTrain Loss: 0.8171106 \tVal Loss:0.5566848 \tTrain Acc: 74.30882% \tVal Acc: 84.5882356%\n",
      "Validation Loss decreased from 0.592266 to 0.556685, saving the model weights\n",
      "Epoch: 235\tTrain Loss: 0.8416656 \tVal Loss:0.5539692 \tTrain Acc: 73.86765% \tVal Acc: 84.3529409%\n",
      "Validation Loss decreased from 0.556685 to 0.553969, saving the model weights\n",
      "Epoch: 236\tTrain Loss: 0.8115269 \tVal Loss:0.5296865 \tTrain Acc: 74.22059% \tVal Acc: 86.8823516%\n",
      "Validation Loss decreased from 0.553969 to 0.529687, saving the model weights\n",
      "Epoch: 237\tTrain Loss: 0.7977693 \tVal Loss:0.5649231 \tTrain Acc: 74.52941% \tVal Acc: 83.8235283%\n",
      "Epoch: 238\tTrain Loss: 0.8273439 \tVal Loss:0.5531599 \tTrain Acc: 73.66176% \tVal Acc: 84.4117635%\n",
      "Epoch: 239\tTrain Loss: 0.8353334 \tVal Loss:0.5543765 \tTrain Acc: 73.23529% \tVal Acc: 85.1764697%\n",
      "Epoch: 240\tTrain Loss: 0.8499236 \tVal Loss:0.5349317 \tTrain Acc: 72.94118% \tVal Acc: 85.7647049%\n",
      "Epoch: 241\tTrain Loss: 0.8321452 \tVal Loss:0.6274029 \tTrain Acc: 73.36765% \tVal Acc: 82.5882351%\n",
      "Epoch: 242\tTrain Loss: 0.8005729 \tVal Loss:0.5771984 \tTrain Acc: 74.29412% \tVal Acc: 83.2352930%\n",
      "Epoch: 243\tTrain Loss: 0.7826528 \tVal Loss:0.6618167 \tTrain Acc: 75.42647% \tVal Acc: 80.8823526%\n",
      "Epoch: 244\tTrain Loss: 0.7684251 \tVal Loss:0.5785823 \tTrain Acc: 75.77941% \tVal Acc: 82.8235298%\n",
      "Epoch: 245\tTrain Loss: 0.7641134 \tVal Loss:0.4919745 \tTrain Acc: 75.54412% \tVal Acc: 86.4705873%\n",
      "Validation Loss decreased from 0.529687 to 0.491975, saving the model weights\n",
      "Epoch: 246\tTrain Loss: 0.7473133 \tVal Loss:0.5129859 \tTrain Acc: 76.69118% \tVal Acc: 84.7058821%\n",
      "Epoch: 247\tTrain Loss: 0.7547126 \tVal Loss:0.4655164 \tTrain Acc: 75.83824% \tVal Acc: 87.8823525%\n",
      "Validation Loss decreased from 0.491975 to 0.465516, saving the model weights\n",
      "Epoch: 248\tTrain Loss: 0.7438480 \tVal Loss:0.5476845 \tTrain Acc: 75.82353% \tVal Acc: 84.4705874%\n",
      "Epoch: 249\tTrain Loss: 0.7270564 \tVal Loss:0.6203889 \tTrain Acc: 76.91176% \tVal Acc: 82.0588231%\n",
      "Epoch: 250\tTrain Loss: 0.7126103 \tVal Loss:0.4939798 \tTrain Acc: 77.27941% \tVal Acc: 85.8235294%\n",
      "Epoch: 251\tTrain Loss: 0.7387667 \tVal Loss:0.4218273 \tTrain Acc: 76.51471% \tVal Acc: 88.6470580%\n",
      "Validation Loss decreased from 0.465516 to 0.421827, saving the model weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 252\tTrain Loss: 0.7244441 \tVal Loss:0.4134104 \tTrain Acc: 76.92647% \tVal Acc: 89.6470582%\n",
      "Validation Loss decreased from 0.421827 to 0.413410, saving the model weights\n",
      "Epoch: 253\tTrain Loss: 0.7241521 \tVal Loss:0.4502451 \tTrain Acc: 76.98529% \tVal Acc: 87.5882339%\n",
      "Epoch: 254\tTrain Loss: 0.7398014 \tVal Loss:0.4582875 \tTrain Acc: 76.64706% \tVal Acc: 87.3529404%\n",
      "Epoch: 255\tTrain Loss: 0.7390928 \tVal Loss:0.4666015 \tTrain Acc: 76.47059% \tVal Acc: 87.2352934%\n",
      "Epoch: 256\tTrain Loss: 0.7126986 \tVal Loss:0.4396753 \tTrain Acc: 77.41176% \tVal Acc: 87.9411763%\n",
      "Epoch: 257\tTrain Loss: 0.7189913 \tVal Loss:0.3951257 \tTrain Acc: 76.86765% \tVal Acc: 89.5882344%\n",
      "Validation Loss decreased from 0.413410 to 0.395126, saving the model weights\n",
      "Epoch: 258\tTrain Loss: 0.7133607 \tVal Loss:0.3922655 \tTrain Acc: 76.94118% \tVal Acc: 88.5882348%\n",
      "Validation Loss decreased from 0.395126 to 0.392265, saving the model weights\n",
      "Epoch: 259\tTrain Loss: 0.7228808 \tVal Loss:0.4724909 \tTrain Acc: 77.36765% \tVal Acc: 86.9999993%\n",
      "Epoch: 260\tTrain Loss: 0.7608913 \tVal Loss:0.4050189 \tTrain Acc: 75.75% \tVal Acc: 88.6470574%\n",
      "Epoch: 261\tTrain Loss: 0.7217946 \tVal Loss:0.3767041 \tTrain Acc: 76.79412% \tVal Acc: 89.5294112%\n",
      "Validation Loss decreased from 0.392265 to 0.376704, saving the model weights\n",
      "Epoch: 262\tTrain Loss: 0.7247429 \tVal Loss:0.3694197 \tTrain Acc: 76.88235% \tVal Acc: 90.5294108%\n",
      "Validation Loss decreased from 0.376704 to 0.369420, saving the model weights\n",
      "Epoch: 263\tTrain Loss: 0.6902918 \tVal Loss:0.3443629 \tTrain Acc: 77.76471% \tVal Acc: 91.2941164%\n",
      "Validation Loss decreased from 0.369420 to 0.344363, saving the model weights\n",
      "Epoch: 264\tTrain Loss: 0.6575779 \tVal Loss:0.3891400 \tTrain Acc: 79.39706% \tVal Acc: 89.1764688%\n",
      "Epoch: 265\tTrain Loss: 0.6680576 \tVal Loss:0.3669056 \tTrain Acc: 78.17647% \tVal Acc: 90.1176471%\n",
      "Epoch: 266\tTrain Loss: 0.6995562 \tVal Loss:0.3400071 \tTrain Acc: 77.11765% \tVal Acc: 91.4117640%\n",
      "Validation Loss decreased from 0.344363 to 0.340007, saving the model weights\n",
      "Epoch: 267\tTrain Loss: 0.6849669 \tVal Loss:0.3363484 \tTrain Acc: 78.04412% \tVal Acc: 91.3529396%\n",
      "Validation Loss decreased from 0.340007 to 0.336348, saving the model weights\n",
      "Epoch: 268\tTrain Loss: 0.6619088 \tVal Loss:0.3774510 \tTrain Acc: 78.91176% \tVal Acc: 88.7647057%\n",
      "Epoch: 269\tTrain Loss: 0.6518366 \tVal Loss:0.4285514 \tTrain Acc: 79.35294% \tVal Acc: 87.2941172%\n",
      "Epoch: 270\tTrain Loss: 0.6613906 \tVal Loss:0.3619122 \tTrain Acc: 79.32353% \tVal Acc: 89.8235285%\n",
      "Epoch: 271\tTrain Loss: 0.7088392 \tVal Loss:0.3536463 \tTrain Acc: 77.05882% \tVal Acc: 90.2352935%\n",
      "Epoch: 272\tTrain Loss: 0.7308054 \tVal Loss:0.3516684 \tTrain Acc: 76.77941% \tVal Acc: 91.5294111%\n",
      "Epoch: 273\tTrain Loss: 0.6931283 \tVal Loss:0.4213614 \tTrain Acc: 78.10294% \tVal Acc: 88.0588228%\n",
      "Epoch: 274\tTrain Loss: 0.6909619 \tVal Loss:0.4748238 \tTrain Acc: 77.66176% \tVal Acc: 84.8823524%\n",
      "Epoch: 275\tTrain Loss: 0.6847774 \tVal Loss:0.4390339 \tTrain Acc: 78.47059% \tVal Acc: 87.3529398%\n",
      "Epoch: 276\tTrain Loss: 0.6695970 \tVal Loss:0.5420934 \tTrain Acc: 78.54412% \tVal Acc: 83.4705877%\n",
      "Epoch: 277\tTrain Loss: 0.6667619 \tVal Loss:0.5477695 \tTrain Acc: 78.55882% \tVal Acc: 82.7058810%\n",
      "Epoch: 278\tTrain Loss: 0.6487464 \tVal Loss:0.6566156 \tTrain Acc: 79.16176% \tVal Acc: 80.0588232%\n",
      "Epoch: 279\tTrain Loss: 0.6421032 \tVal Loss:0.6626415 \tTrain Acc: 79.63235% \tVal Acc: 80.1176471%\n",
      "Epoch: 280\tTrain Loss: 0.6525696 \tVal Loss:0.5815489 \tTrain Acc: 78.91176% \tVal Acc: 81.7647052%\n",
      "Epoch: 281\tTrain Loss: 0.6724623 \tVal Loss:0.4850301 \tTrain Acc: 77.86765% \tVal Acc: 85.4705870%\n",
      "Epoch: 282\tTrain Loss: 0.7578201 \tVal Loss:0.5222945 \tTrain Acc: 75.86765% \tVal Acc: 84.5882350%\n",
      "Epoch: 283\tTrain Loss: 0.7781119 \tVal Loss:0.6172704 \tTrain Acc: 75.91176% \tVal Acc: 80.9411758%\n",
      "Epoch: 284\tTrain Loss: 0.7072547 \tVal Loss:0.5397841 \tTrain Acc: 77.25% \tVal Acc: 83.6470586%\n",
      "Epoch: 285\tTrain Loss: 0.6356629 \tVal Loss:0.3674812 \tTrain Acc: 79.97059% \tVal Acc: 90.3529412%\n",
      "Epoch: 286\tTrain Loss: 0.6377285 \tVal Loss:0.3476720 \tTrain Acc: 79.89706% \tVal Acc: 90.6470585%\n",
      "Epoch: 287\tTrain Loss: 0.5976906 \tVal Loss:0.2730893 \tTrain Acc: 81.13235% \tVal Acc: 92.7647048%\n",
      "Validation Loss decreased from 0.336348 to 0.273089, saving the model weights\n",
      "Epoch: 288\tTrain Loss: 0.5676936 \tVal Loss:0.2394476 \tTrain Acc: 81.97059% \tVal Acc: 94.5294112%\n",
      "Validation Loss decreased from 0.273089 to 0.239448, saving the model weights\n",
      "Epoch: 289\tTrain Loss: 0.5310625 \tVal Loss:0.2181707 \tTrain Acc: 83.30882% \tVal Acc: 94.7647047%\n",
      "Validation Loss decreased from 0.239448 to 0.218171, saving the model weights\n",
      "Epoch: 290\tTrain Loss: 0.5289084 \tVal Loss:0.2045354 \tTrain Acc: 83.76471% \tVal Acc: 95.5294102%\n",
      "Validation Loss decreased from 0.218171 to 0.204535, saving the model weights\n",
      "Epoch: 291\tTrain Loss: 0.4930405 \tVal Loss:0.1826342 \tTrain Acc: 84.86765% \tVal Acc: 95.8823520%\n",
      "Validation Loss decreased from 0.204535 to 0.182634, saving the model weights\n",
      "Epoch: 292\tTrain Loss: 0.4571024 \tVal Loss:0.1752245 \tTrain Acc: 85.60294% \tVal Acc: 96.4117628%\n",
      "Validation Loss decreased from 0.182634 to 0.175224, saving the model weights\n",
      "Epoch: 293\tTrain Loss: 0.4417919 \tVal Loss:0.1582460 \tTrain Acc: 86.25% \tVal Acc: 96.8823516%\n",
      "Validation Loss decreased from 0.175224 to 0.158246, saving the model weights\n",
      "Epoch: 294\tTrain Loss: 0.4372419 \tVal Loss:0.1706200 \tTrain Acc: 86.98529% \tVal Acc: 96.7058814%\n",
      "Epoch: 295\tTrain Loss: 0.4430698 \tVal Loss:0.1746113 \tTrain Acc: 86.48529% \tVal Acc: 95.9411752%\n",
      "Epoch: 296\tTrain Loss: 0.4367402 \tVal Loss:0.1550023 \tTrain Acc: 86.70588% \tVal Acc: 96.4117634%\n",
      "Validation Loss decreased from 0.158246 to 0.155002, saving the model weights\n",
      "Epoch: 297\tTrain Loss: 0.4144978 \tVal Loss:0.1495927 \tTrain Acc: 87.19118% \tVal Acc: 96.7058808%\n",
      "Validation Loss decreased from 0.155002 to 0.149593, saving the model weights\n",
      "Epoch: 298\tTrain Loss: 0.4168655 \tVal Loss:0.1566343 \tTrain Acc: 87.44118% \tVal Acc: 96.8235284%\n",
      "Epoch: 299\tTrain Loss: 0.4172348 \tVal Loss:0.1560336 \tTrain Acc: 87.19118% \tVal Acc: 96.7058814%\n",
      "Epoch: 300\tTrain Loss: 0.4421578 \tVal Loss:0.1665346 \tTrain Acc: 86.22059% \tVal Acc: 96.3529402%\n",
      "Epoch: 301\tTrain Loss: 0.4348736 \tVal Loss:0.1507817 \tTrain Acc: 86.25% \tVal Acc: 96.8235278%\n",
      "Epoch: 302\tTrain Loss: 0.4250552 \tVal Loss:0.1618151 \tTrain Acc: 86.63235% \tVal Acc: 96.5882343%\n",
      "Epoch: 303\tTrain Loss: 0.4179792 \tVal Loss:0.1649625 \tTrain Acc: 87.0% \tVal Acc: 96.7058814%\n",
      "Epoch: 304\tTrain Loss: 0.4129080 \tVal Loss:0.1376711 \tTrain Acc: 86.88235% \tVal Acc: 97.7058810%\n",
      "Validation Loss decreased from 0.149593 to 0.137671, saving the model weights\n",
      "Epoch: 305\tTrain Loss: 0.4147027 \tVal Loss:0.1609524 \tTrain Acc: 86.95588% \tVal Acc: 96.5294099%\n",
      "Epoch: 306\tTrain Loss: 0.4237837 \tVal Loss:0.1547617 \tTrain Acc: 86.66176% \tVal Acc: 96.5882343%\n",
      "Epoch: 307\tTrain Loss: 0.4045912 \tVal Loss:0.1386392 \tTrain Acc: 87.26471% \tVal Acc: 96.9411743%\n",
      "Epoch: 308\tTrain Loss: 0.3895473 \tVal Loss:0.1443377 \tTrain Acc: 88.08823% \tVal Acc: 96.8823510%\n",
      "Epoch: 309\tTrain Loss: 0.4146576 \tVal Loss:0.1368259 \tTrain Acc: 86.61765% \tVal Acc: 96.9999987%\n",
      "Validation Loss decreased from 0.137671 to 0.136826, saving the model weights\n",
      "Epoch: 310\tTrain Loss: 0.3853167 \tVal Loss:0.1389960 \tTrain Acc: 88.33823% \tVal Acc: 97.6470578%\n",
      "Epoch: 311\tTrain Loss: 0.4116189 \tVal Loss:0.1448013 \tTrain Acc: 87.0% \tVal Acc: 96.8235290%\n",
      "Epoch: 312\tTrain Loss: 0.4249150 \tVal Loss:0.1686031 \tTrain Acc: 86.20588% \tVal Acc: 95.5882335%\n",
      "Epoch: 313\tTrain Loss: 0.4157159 \tVal Loss:0.1520926 \tTrain Acc: 86.75% \tVal Acc: 96.5294099%\n",
      "Epoch: 314\tTrain Loss: 0.3887482 \tVal Loss:0.1265456 \tTrain Acc: 87.82353% \tVal Acc: 97.7647048%\n",
      "Validation Loss decreased from 0.136826 to 0.126546, saving the model weights\n",
      "Epoch: 315\tTrain Loss: 0.4201865 \tVal Loss:0.1716025 \tTrain Acc: 86.44118% \tVal Acc: 96.0588229%\n",
      "Epoch: 316\tTrain Loss: 0.4390588 \tVal Loss:0.1408420 \tTrain Acc: 85.82353% \tVal Acc: 96.8235284%\n",
      "Epoch: 317\tTrain Loss: 0.4071580 \tVal Loss:0.1330723 \tTrain Acc: 86.94118% \tVal Acc: 97.4117631%\n",
      "Epoch: 318\tTrain Loss: 0.3920846 \tVal Loss:0.1263354 \tTrain Acc: 87.75% \tVal Acc: 97.4705875%\n",
      "Validation Loss decreased from 0.126546 to 0.126335, saving the model weights\n",
      "Epoch: 319\tTrain Loss: 0.3690147 \tVal Loss:0.1278377 \tTrain Acc: 88.39706% \tVal Acc: 97.1176463%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 320\tTrain Loss: 0.3651269 \tVal Loss:0.1256826 \tTrain Acc: 88.80882% \tVal Acc: 96.9999993%\n",
      "Validation Loss decreased from 0.126335 to 0.125683, saving the model weights\n",
      "Epoch: 321\tTrain Loss: 0.3606538 \tVal Loss:0.1167430 \tTrain Acc: 89.41176% \tVal Acc: 97.8823513%\n",
      "Validation Loss decreased from 0.125683 to 0.116743, saving the model weights\n",
      "Epoch: 322\tTrain Loss: 0.3690703 \tVal Loss:0.1138524 \tTrain Acc: 88.25% \tVal Acc: 97.7058804%\n",
      "Validation Loss decreased from 0.116743 to 0.113852, saving the model weights\n",
      "Epoch: 323\tTrain Loss: 0.3518079 \tVal Loss:0.0918861 \tTrain Acc: 88.91176% \tVal Acc: 98.3529401%\n",
      "Validation Loss decreased from 0.113852 to 0.091886, saving the model weights\n",
      "Epoch: 324\tTrain Loss: 0.3504415 \tVal Loss:0.1051986 \tTrain Acc: 88.67647% \tVal Acc: 97.6470584%\n",
      "Epoch: 325\tTrain Loss: 0.3402987 \tVal Loss:0.1140292 \tTrain Acc: 89.25% \tVal Acc: 97.8823519%\n",
      "Epoch: 326\tTrain Loss: 0.3529135 \tVal Loss:0.1146619 \tTrain Acc: 88.64706% \tVal Acc: 97.6470572%\n",
      "Epoch: 327\tTrain Loss: 0.3483542 \tVal Loss:0.1006258 \tTrain Acc: 89.14706% \tVal Acc: 97.6470578%\n",
      "Epoch: 328\tTrain Loss: 0.3458825 \tVal Loss:0.0954070 \tTrain Acc: 89.07353% \tVal Acc: 97.9999983%\n",
      "Epoch: 329\tTrain Loss: 0.3287889 \tVal Loss:0.0931516 \tTrain Acc: 89.82353% \tVal Acc: 98.3529395%\n",
      "Epoch: 330\tTrain Loss: 0.3195006 \tVal Loss:0.0901932 \tTrain Acc: 89.72059% \tVal Acc: 97.9411751%\n",
      "Validation Loss decreased from 0.091886 to 0.090193, saving the model weights\n",
      "Epoch: 331\tTrain Loss: 0.3166744 \tVal Loss:0.1005784 \tTrain Acc: 90.29412% \tVal Acc: 97.8235275%\n",
      "Epoch: 332\tTrain Loss: 0.3324570 \tVal Loss:0.1052503 \tTrain Acc: 89.70588% \tVal Acc: 97.7058810%\n",
      "Epoch: 333\tTrain Loss: 0.4645592 \tVal Loss:0.3244297 \tTrain Acc: 85.13235% \tVal Acc: 90.7058811%\n",
      "Epoch: 334\tTrain Loss: 0.5078899 \tVal Loss:0.2411140 \tTrain Acc: 83.85294% \tVal Acc: 93.1764692%\n",
      "Epoch: 335\tTrain Loss: 0.4725541 \tVal Loss:0.1776559 \tTrain Acc: 85.54412% \tVal Acc: 94.6470577%\n",
      "Epoch: 336\tTrain Loss: 0.4156048 \tVal Loss:0.1472930 \tTrain Acc: 87.0% \tVal Acc: 96.5294111%\n",
      "Epoch: 337\tTrain Loss: 0.3803438 \tVal Loss:0.1111859 \tTrain Acc: 87.94118% \tVal Acc: 97.7647042%\n",
      "Epoch: 338\tTrain Loss: 0.3573742 \tVal Loss:0.0949377 \tTrain Acc: 88.92647% \tVal Acc: 97.9999983%\n",
      "Epoch: 339\tTrain Loss: 0.3145039 \tVal Loss:0.0818215 \tTrain Acc: 90.51471% \tVal Acc: 98.8235283%\n",
      "Validation Loss decreased from 0.090193 to 0.081821, saving the model weights\n",
      "Epoch: 340\tTrain Loss: 0.3034460 \tVal Loss:0.0770895 \tTrain Acc: 90.88235% \tVal Acc: 98.2352930%\n",
      "Validation Loss decreased from 0.081821 to 0.077089, saving the model weights\n",
      "Epoch: 341\tTrain Loss: 0.2935665 \tVal Loss:0.0647465 \tTrain Acc: 90.85294% \tVal Acc: 98.8235283%\n",
      "Validation Loss decreased from 0.077089 to 0.064746, saving the model weights\n",
      "Epoch: 342\tTrain Loss: 0.2909174 \tVal Loss:0.0690046 \tTrain Acc: 90.86765% \tVal Acc: 98.5882348%\n",
      "Epoch: 343\tTrain Loss: 0.2756622 \tVal Loss:0.0645233 \tTrain Acc: 91.5147% \tVal Acc: 98.7647051%\n",
      "Validation Loss decreased from 0.064746 to 0.064523, saving the model weights\n",
      "Epoch: 344\tTrain Loss: 0.2699580 \tVal Loss:0.0678041 \tTrain Acc: 92.0% \tVal Acc: 98.7647051%\n",
      "Epoch: 345\tTrain Loss: 0.2769355 \tVal Loss:0.0890140 \tTrain Acc: 91.58823% \tVal Acc: 97.9999983%\n",
      "Epoch: 346\tTrain Loss: 0.2833029 \tVal Loss:0.0832813 \tTrain Acc: 91.32353% \tVal Acc: 97.9999983%\n",
      "Epoch: 347\tTrain Loss: 0.2985639 \tVal Loss:0.0822009 \tTrain Acc: 91.29412% \tVal Acc: 97.7058816%\n",
      "Epoch: 348\tTrain Loss: 0.2857053 \tVal Loss:0.0785171 \tTrain Acc: 91.10294% \tVal Acc: 98.4117639%\n",
      "Epoch: 349\tTrain Loss: 0.2762652 \tVal Loss:0.0810699 \tTrain Acc: 91.42647% \tVal Acc: 97.9999983%\n",
      "Epoch: 350\tTrain Loss: 0.3213829 \tVal Loss:0.1156411 \tTrain Acc: 90.10294% \tVal Acc: 96.9411749%\n",
      "Epoch: 351\tTrain Loss: 0.3012196 \tVal Loss:0.0934496 \tTrain Acc: 90.54412% \tVal Acc: 98.1764692%\n",
      "Epoch: 352\tTrain Loss: 0.3011153 \tVal Loss:0.0801606 \tTrain Acc: 90.20588% \tVal Acc: 98.1764692%\n",
      "Epoch: 353\tTrain Loss: 0.2669408 \tVal Loss:0.0649934 \tTrain Acc: 91.63235% \tVal Acc: 98.7058806%\n",
      "Epoch: 354\tTrain Loss: 0.2715953 \tVal Loss:0.0775038 \tTrain Acc: 91.92647% \tVal Acc: 98.2941157%\n",
      "Epoch: 355\tTrain Loss: 0.2852543 \tVal Loss:0.0659899 \tTrain Acc: 91.32353% \tVal Acc: 98.4117633%\n",
      "Epoch: 356\tTrain Loss: 0.2866628 \tVal Loss:0.0825933 \tTrain Acc: 91.25% \tVal Acc: 98.1176460%\n",
      "Epoch: 357\tTrain Loss: 0.3369793 \tVal Loss:0.1119351 \tTrain Acc: 89.83823% \tVal Acc: 97.3529404%\n",
      "Epoch: 358\tTrain Loss: 0.3343993 \tVal Loss:0.0857412 \tTrain Acc: 89.51471% \tVal Acc: 98.2941163%\n",
      "Epoch: 359\tTrain Loss: 0.2901573 \tVal Loss:0.0601283 \tTrain Acc: 90.79412% \tVal Acc: 98.9411759%\n",
      "Validation Loss decreased from 0.064523 to 0.060128, saving the model weights\n",
      "Epoch: 360\tTrain Loss: 0.2558112 \tVal Loss:0.0893590 \tTrain Acc: 92.39706% \tVal Acc: 97.8823513%\n",
      "Epoch: 361\tTrain Loss: 0.2521034 \tVal Loss:0.0683300 \tTrain Acc: 92.48529% \tVal Acc: 98.7647039%\n",
      "Epoch: 362\tTrain Loss: 0.2352843 \tVal Loss:0.0641549 \tTrain Acc: 92.86765% \tVal Acc: 98.9999992%\n",
      "Epoch: 363\tTrain Loss: 0.2344248 \tVal Loss:0.0443410 \tTrain Acc: 92.80882% \tVal Acc: 99.0588218%\n",
      "Validation Loss decreased from 0.060128 to 0.044341, saving the model weights\n",
      "Epoch: 364\tTrain Loss: 0.2058704 \tVal Loss:0.0416077 \tTrain Acc: 94.19118% \tVal Acc: 99.3529397%\n",
      "Validation Loss decreased from 0.044341 to 0.041608, saving the model weights\n",
      "Epoch: 365\tTrain Loss: 0.2094754 \tVal Loss:0.0394426 \tTrain Acc: 94.11765% \tVal Acc: 99.3529403%\n",
      "Validation Loss decreased from 0.041608 to 0.039443, saving the model weights\n",
      "Epoch: 366\tTrain Loss: 0.2155939 \tVal Loss:0.0452173 \tTrain Acc: 93.41176% \tVal Acc: 99.0588224%\n",
      "Epoch: 367\tTrain Loss: 0.2236471 \tVal Loss:0.0446887 \tTrain Acc: 93.52941% \tVal Acc: 99.0588224%\n",
      "Epoch: 368\tTrain Loss: 0.2173387 \tVal Loss:0.0431261 \tTrain Acc: 93.39706% \tVal Acc: 99.2352927%\n",
      "Epoch: 369\tTrain Loss: 0.2251006 \tVal Loss:0.0428494 \tTrain Acc: 93.17647% \tVal Acc: 98.9411747%\n",
      "Epoch: 370\tTrain Loss: 0.2111012 \tVal Loss:0.0476181 \tTrain Acc: 93.73529% \tVal Acc: 99.1176462%\n",
      "Epoch: 371\tTrain Loss: 0.2324729 \tVal Loss:0.0558525 \tTrain Acc: 92.66176% \tVal Acc: 98.5882342%\n",
      "Epoch: 372\tTrain Loss: 0.2360527 \tVal Loss:0.0483687 \tTrain Acc: 92.98529% \tVal Acc: 98.8235289%\n",
      "Epoch: 373\tTrain Loss: 0.2405902 \tVal Loss:0.0590082 \tTrain Acc: 92.89706% \tVal Acc: 98.6470574%\n",
      "Epoch: 374\tTrain Loss: 0.2684085 \tVal Loss:0.0763933 \tTrain Acc: 91.72059% \tVal Acc: 98.2941163%\n",
      "Epoch: 375\tTrain Loss: 0.2999362 \tVal Loss:0.0960003 \tTrain Acc: 91.10294% \tVal Acc: 97.6470584%\n",
      "Epoch: 376\tTrain Loss: 0.3278137 \tVal Loss:0.1556148 \tTrain Acc: 89.97059% \tVal Acc: 95.7647043%\n",
      "Epoch: 377\tTrain Loss: 0.3554755 \tVal Loss:0.1662871 \tTrain Acc: 88.82353% \tVal Acc: 94.8235285%\n",
      "Epoch: 378\tTrain Loss: 0.3593028 \tVal Loss:0.2463878 \tTrain Acc: 88.86765% \tVal Acc: 93.0588228%\n",
      "Epoch: 379\tTrain Loss: 0.3952687 \tVal Loss:0.1883010 \tTrain Acc: 87.97059% \tVal Acc: 94.8235285%\n",
      "Epoch: 380\tTrain Loss: 0.3824938 \tVal Loss:0.1161185 \tTrain Acc: 87.85294% \tVal Acc: 97.1176457%\n",
      "Epoch: 381\tTrain Loss: 0.3451680 \tVal Loss:0.0969249 \tTrain Acc: 88.52941% \tVal Acc: 97.1176463%\n",
      "Epoch: 382\tTrain Loss: 0.3010880 \tVal Loss:0.0793053 \tTrain Acc: 90.07353% \tVal Acc: 98.5294104%\n",
      "Epoch: 383\tTrain Loss: 0.2661654 \tVal Loss:0.0592218 \tTrain Acc: 92.04412% \tVal Acc: 98.8235283%\n",
      "Epoch: 384\tTrain Loss: 0.2285298 \tVal Loss:0.0464791 \tTrain Acc: 92.88235% \tVal Acc: 99.3529403%\n",
      "Epoch: 385\tTrain Loss: 0.2180407 \tVal Loss:0.0457075 \tTrain Acc: 93.42647% \tVal Acc: 98.9999986%\n",
      "Epoch: 386\tTrain Loss: 0.2005312 \tVal Loss:0.0426039 \tTrain Acc: 94.22059% \tVal Acc: 99.2941171%\n",
      "Epoch: 387\tTrain Loss: 0.1963555 \tVal Loss:0.0348941 \tTrain Acc: 94.25% \tVal Acc: 99.1764694%\n",
      "Validation Loss decreased from 0.039443 to 0.034894, saving the model weights\n",
      "Epoch: 388\tTrain Loss: 0.1896987 \tVal Loss:0.0317359 \tTrain Acc: 94.48529% \tVal Acc: 99.3529409%\n",
      "Validation Loss decreased from 0.034894 to 0.031736, saving the model weights\n",
      "Epoch: 389\tTrain Loss: 0.1878450 \tVal Loss:0.0335034 \tTrain Acc: 94.32353% \tVal Acc: 99.1176462%\n",
      "Epoch: 390\tTrain Loss: 0.1857869 \tVal Loss:0.0265851 \tTrain Acc: 94.29412% \tVal Acc: 99.4705880%\n",
      "Validation Loss decreased from 0.031736 to 0.026585, saving the model weights\n",
      "Epoch: 391\tTrain Loss: 0.1690735 \tVal Loss:0.0260322 \tTrain Acc: 95.48529% \tVal Acc: 99.4117630%\n",
      "Validation Loss decreased from 0.026585 to 0.026032, saving the model weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 392\tTrain Loss: 0.1577290 \tVal Loss:0.0314668 \tTrain Acc: 95.20588% \tVal Acc: 99.2352933%\n",
      "Epoch: 393\tTrain Loss: 0.1645756 \tVal Loss:0.0320018 \tTrain Acc: 95.19118% \tVal Acc: 99.2352927%\n",
      "Epoch: 394\tTrain Loss: 0.1796114 \tVal Loss:0.0354582 \tTrain Acc: 94.42647% \tVal Acc: 99.1764700%\n",
      "Epoch: 395\tTrain Loss: 0.1772296 \tVal Loss:0.0325412 \tTrain Acc: 94.79412% \tVal Acc: 99.2941165%\n",
      "Epoch: 396\tTrain Loss: 0.1851037 \tVal Loss:0.0303015 \tTrain Acc: 94.61765% \tVal Acc: 99.4117641%\n",
      "Epoch: 397\tTrain Loss: 0.1886626 \tVal Loss:0.0326893 \tTrain Acc: 94.54412% \tVal Acc: 99.2941165%\n",
      "Epoch: 398\tTrain Loss: 0.1781358 \tVal Loss:0.0344161 \tTrain Acc: 94.66176% \tVal Acc: 99.0588230%\n",
      "Epoch: 399\tTrain Loss: 0.1976542 \tVal Loss:0.0622033 \tTrain Acc: 94.07353% \tVal Acc: 98.4117633%\n",
      "Epoch: 400\tTrain Loss: 0.2309575 \tVal Loss:0.0559805 \tTrain Acc: 92.95588% \tVal Acc: 98.5294116%\n",
      "Epoch: 401\tTrain Loss: 0.2300948 \tVal Loss:0.0583752 \tTrain Acc: 92.89706% \tVal Acc: 98.2941163%\n",
      "Epoch: 402\tTrain Loss: 0.2485909 \tVal Loss:0.0595680 \tTrain Acc: 92.27941% \tVal Acc: 98.4705865%\n",
      "Epoch: 403\tTrain Loss: 0.2309643 \tVal Loss:0.0473236 \tTrain Acc: 92.88235% \tVal Acc: 98.8823521%\n",
      "Epoch: 404\tTrain Loss: 0.2164566 \tVal Loss:0.0486183 \tTrain Acc: 93.47059% \tVal Acc: 98.7647045%\n",
      "Epoch: 405\tTrain Loss: 0.2312808 \tVal Loss:0.0520010 \tTrain Acc: 92.80882% \tVal Acc: 98.9411747%\n",
      "Epoch: 406\tTrain Loss: 0.2370142 \tVal Loss:0.0633617 \tTrain Acc: 92.55882% \tVal Acc: 98.5294110%\n",
      "Epoch: 407\tTrain Loss: 0.2386096 \tVal Loss:0.0526336 \tTrain Acc: 92.7647% \tVal Acc: 98.5294098%\n",
      "Epoch: 408\tTrain Loss: 0.2314919 \tVal Loss:0.0604819 \tTrain Acc: 92.69118% \tVal Acc: 98.2352930%\n",
      "Epoch: 409\tTrain Loss: 0.2267349 \tVal Loss:0.0552115 \tTrain Acc: 93.13235% \tVal Acc: 98.7058806%\n",
      "Epoch: 410\tTrain Loss: 0.2297077 \tVal Loss:0.0444992 \tTrain Acc: 92.94118% \tVal Acc: 98.9999992%\n",
      "Epoch: 411\tTrain Loss: 0.2004558 \tVal Loss:0.0396633 \tTrain Acc: 93.92647% \tVal Acc: 99.1176462%\n",
      "Epoch: 412\tTrain Loss: 0.2029288 \tVal Loss:0.0473028 \tTrain Acc: 93.69118% \tVal Acc: 98.8823515%\n",
      "Epoch: 413\tTrain Loss: 0.1922070 \tVal Loss:0.0379189 \tTrain Acc: 93.95588% \tVal Acc: 99.1764694%\n",
      "Epoch: 414\tTrain Loss: 0.1932710 \tVal Loss:0.0398311 \tTrain Acc: 94.07353% \tVal Acc: 98.9411753%\n",
      "Epoch: 415\tTrain Loss: 0.1851938 \tVal Loss:0.0423458 \tTrain Acc: 94.02941% \tVal Acc: 98.9411747%\n",
      "Epoch: 416\tTrain Loss: 0.2094679 \tVal Loss:0.0426182 \tTrain Acc: 93.33823% \tVal Acc: 98.8823515%\n",
      "Epoch: 417\tTrain Loss: 0.1872911 \tVal Loss:0.0475920 \tTrain Acc: 94.27941% \tVal Acc: 98.6470580%\n",
      "Epoch: 418\tTrain Loss: 0.2243051 \tVal Loss:0.0717188 \tTrain Acc: 93.19118% \tVal Acc: 98.2352930%\n",
      "Epoch: 419\tTrain Loss: 0.2092442 \tVal Loss:0.0532907 \tTrain Acc: 93.30882% \tVal Acc: 98.7647045%\n",
      "Epoch: 420\tTrain Loss: 0.2020220 \tVal Loss:0.0339828 \tTrain Acc: 93.98529% \tVal Acc: 99.1764694%\n",
      "Epoch: 421\tTrain Loss: 0.2091019 \tVal Loss:0.0446495 \tTrain Acc: 93.41176% \tVal Acc: 99.0588218%\n",
      "Epoch: 422\tTrain Loss: 0.1949553 \tVal Loss:0.0586004 \tTrain Acc: 94.04412% \tVal Acc: 98.9999986%\n",
      "Epoch: 423\tTrain Loss: 0.2198392 \tVal Loss:0.0499940 \tTrain Acc: 93.45588% \tVal Acc: 98.4705877%\n",
      "Epoch: 424\tTrain Loss: 0.2051370 \tVal Loss:0.0467554 \tTrain Acc: 93.86765% \tVal Acc: 98.9411747%\n",
      "Epoch: 425\tTrain Loss: 0.2080074 \tVal Loss:0.0503272 \tTrain Acc: 93.64706% \tVal Acc: 98.6470574%\n",
      "Epoch: 426\tTrain Loss: 0.2144459 \tVal Loss:0.0572105 \tTrain Acc: 93.17647% \tVal Acc: 98.4705877%\n",
      "Epoch: 427\tTrain Loss: 0.2265612 \tVal Loss:0.0397971 \tTrain Acc: 93.20588% \tVal Acc: 99.0588218%\n",
      "Epoch: 428\tTrain Loss: 0.2164864 \tVal Loss:0.0439442 \tTrain Acc: 93.07353% \tVal Acc: 98.7647045%\n",
      "Epoch: 429\tTrain Loss: 0.2075853 \tVal Loss:0.0593239 \tTrain Acc: 93.5% \tVal Acc: 98.6470568%\n",
      "Epoch: 430\tTrain Loss: 0.1954475 \tVal Loss:0.0666229 \tTrain Acc: 94.2647% \tVal Acc: 98.2941163%\n",
      "Epoch: 431\tTrain Loss: 0.1892350 \tVal Loss:0.0480167 \tTrain Acc: 94.36765% \tVal Acc: 98.5882336%\n",
      "Epoch: 432\tTrain Loss: 0.1784852 \tVal Loss:0.0609706 \tTrain Acc: 94.57353% \tVal Acc: 98.3529389%\n",
      "Epoch: 433\tTrain Loss: 0.1702027 \tVal Loss:0.0421139 \tTrain Acc: 94.75% \tVal Acc: 98.8235277%\n",
      "Epoch: 434\tTrain Loss: 0.1618753 \tVal Loss:0.0317996 \tTrain Acc: 94.98529% \tVal Acc: 99.1764694%\n",
      "Epoch: 435\tTrain Loss: 0.1476267 \tVal Loss:0.0230699 \tTrain Acc: 95.64706% \tVal Acc: 99.3529397%\n",
      "Validation Loss decreased from 0.026032 to 0.023070, saving the model weights\n",
      "Epoch: 436\tTrain Loss: 0.1383890 \tVal Loss:0.0214046 \tTrain Acc: 95.67647% \tVal Acc: 99.3529397%\n",
      "Validation Loss decreased from 0.023070 to 0.021405, saving the model weights\n",
      "Epoch: 437\tTrain Loss: 0.1474909 \tVal Loss:0.0185945 \tTrain Acc: 95.41176% \tVal Acc: 99.5882344%\n",
      "Validation Loss decreased from 0.021405 to 0.018595, saving the model weights\n",
      "Epoch: 438\tTrain Loss: 0.1361187 \tVal Loss:0.0196687 \tTrain Acc: 96.08823% \tVal Acc: 99.5294106%\n",
      "Epoch: 439\tTrain Loss: 0.1349810 \tVal Loss:0.0298881 \tTrain Acc: 96.19118% \tVal Acc: 99.1764688%\n",
      "Epoch: 440\tTrain Loss: 0.1358997 \tVal Loss:0.0196795 \tTrain Acc: 95.85294% \tVal Acc: 99.4705868%\n",
      "Epoch: 441\tTrain Loss: 0.1373064 \tVal Loss:0.0203737 \tTrain Acc: 95.7647% \tVal Acc: 99.4705874%\n",
      "Epoch: 442\tTrain Loss: 0.1356299 \tVal Loss:0.0192911 \tTrain Acc: 96.22059% \tVal Acc: 99.5882344%\n",
      "Epoch: 443\tTrain Loss: 0.1287278 \tVal Loss:0.0183427 \tTrain Acc: 96.47059% \tVal Acc: 99.4705880%\n",
      "Validation Loss decreased from 0.018595 to 0.018343, saving the model weights\n",
      "Epoch: 444\tTrain Loss: 0.1306304 \tVal Loss:0.0356084 \tTrain Acc: 96.32353% \tVal Acc: 98.9999992%\n",
      "Epoch: 445\tTrain Loss: 0.1280722 \tVal Loss:0.0249164 \tTrain Acc: 96.17647% \tVal Acc: 99.2941165%\n",
      "Epoch: 446\tTrain Loss: 0.1337237 \tVal Loss:0.0255549 \tTrain Acc: 95.92647% \tVal Acc: 99.2941165%\n",
      "Epoch: 447\tTrain Loss: 0.1417096 \tVal Loss:0.0321125 \tTrain Acc: 95.91176% \tVal Acc: 99.2941165%\n",
      "Epoch: 448\tTrain Loss: 0.1709556 \tVal Loss:0.0461362 \tTrain Acc: 95.19118% \tVal Acc: 98.6470574%\n",
      "Epoch: 449\tTrain Loss: 0.1715022 \tVal Loss:0.0254621 \tTrain Acc: 94.86765% \tVal Acc: 99.2941171%\n",
      "Epoch: 450\tTrain Loss: 0.1589489 \tVal Loss:0.0232145 \tTrain Acc: 95.20588% \tVal Acc: 99.4117635%\n",
      "Epoch: 451\tTrain Loss: 0.1481969 \tVal Loss:0.0279443 \tTrain Acc: 95.83823% \tVal Acc: 99.1764700%\n",
      "Epoch: 452\tTrain Loss: 0.1660370 \tVal Loss:0.0648508 \tTrain Acc: 95.08823% \tVal Acc: 98.2941163%\n",
      "Epoch: 453\tTrain Loss: 0.1957897 \tVal Loss:0.0503391 \tTrain Acc: 94.05882% \tVal Acc: 98.5882342%\n",
      "Epoch: 454\tTrain Loss: 0.2192279 \tVal Loss:0.0632625 \tTrain Acc: 93.42647% \tVal Acc: 98.3529407%\n",
      "Epoch: 455\tTrain Loss: 0.2061610 \tVal Loss:0.0714285 \tTrain Acc: 93.35294% \tVal Acc: 98.5294110%\n",
      "Epoch: 456\tTrain Loss: 0.1917729 \tVal Loss:0.0324333 \tTrain Acc: 94.2647% \tVal Acc: 99.1176450%\n",
      "Epoch: 457\tTrain Loss: 0.1858621 \tVal Loss:0.0447444 \tTrain Acc: 94.02941% \tVal Acc: 98.8235277%\n",
      "Epoch: 458\tTrain Loss: 0.2555489 \tVal Loss:0.1135813 \tTrain Acc: 92.11765% \tVal Acc: 97.0588219%\n",
      "Epoch: 459\tTrain Loss: 0.2760514 \tVal Loss:0.0612219 \tTrain Acc: 91.44118% \tVal Acc: 98.5882342%\n",
      "Epoch: 460\tTrain Loss: 0.2302294 \tVal Loss:0.0574348 \tTrain Acc: 93.07353% \tVal Acc: 98.3529395%\n",
      "Epoch: 461\tTrain Loss: 0.1953177 \tVal Loss:0.0391938 \tTrain Acc: 93.76471% \tVal Acc: 98.8235289%\n",
      "Epoch: 462\tTrain Loss: 0.1670505 \tVal Loss:0.0375126 \tTrain Acc: 95.0147% \tVal Acc: 98.9999986%\n",
      "Epoch: 463\tTrain Loss: 0.1625020 \tVal Loss:0.0292947 \tTrain Acc: 95.22059% \tVal Acc: 98.9999986%\n",
      "Epoch: 464\tTrain Loss: 0.1488668 \tVal Loss:0.0226927 \tTrain Acc: 95.60294% \tVal Acc: 99.4705874%\n",
      "Epoch: 465\tTrain Loss: 0.1300735 \tVal Loss:0.0174949 \tTrain Acc: 96.39706% \tVal Acc: 99.4705874%\n",
      "Validation Loss decreased from 0.018343 to 0.017495, saving the model weights\n",
      "Epoch: 466\tTrain Loss: 0.1184045 \tVal Loss:0.0186180 \tTrain Acc: 96.61765% \tVal Acc: 99.4705874%\n",
      "Epoch: 467\tTrain Loss: 0.1100747 \tVal Loss:0.0157609 \tTrain Acc: 96.94117% \tVal Acc: 99.4705874%\n",
      "Validation Loss decreased from 0.017495 to 0.015761, saving the model weights\n",
      "Epoch: 468\tTrain Loss: 0.1100261 \tVal Loss:0.0141107 \tTrain Acc: 96.83823% \tVal Acc: 99.5882344%\n",
      "Validation Loss decreased from 0.015761 to 0.014111, saving the model weights\n",
      "Epoch: 469\tTrain Loss: 0.1044324 \tVal Loss:0.0157041 \tTrain Acc: 97.02941% \tVal Acc: 99.5882338%\n",
      "Epoch: 470\tTrain Loss: 0.1164218 \tVal Loss:0.0219431 \tTrain Acc: 96.47059% \tVal Acc: 99.4117635%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 471\tTrain Loss: 0.1319607 \tVal Loss:0.0194185 \tTrain Acc: 96.2647% \tVal Acc: 99.3529397%\n",
      "Epoch: 472\tTrain Loss: 0.1217306 \tVal Loss:0.0171505 \tTrain Acc: 96.25% \tVal Acc: 99.2941171%\n",
      "Epoch: 473\tTrain Loss: 0.1223118 \tVal Loss:0.0193340 \tTrain Acc: 96.47059% \tVal Acc: 99.4117635%\n",
      "Epoch: 474\tTrain Loss: 0.1244027 \tVal Loss:0.0200151 \tTrain Acc: 96.61765% \tVal Acc: 99.2352927%\n",
      "Epoch: 475\tTrain Loss: 0.1417365 \tVal Loss:0.0189887 \tTrain Acc: 96.02941% \tVal Acc: 99.4117630%\n",
      "Epoch: 476\tTrain Loss: 0.1385792 \tVal Loss:0.0208220 \tTrain Acc: 95.95588% \tVal Acc: 99.5294100%\n",
      "Epoch: 477\tTrain Loss: 0.1368734 \tVal Loss:0.0282534 \tTrain Acc: 96.05882% \tVal Acc: 99.1176462%\n",
      "Epoch: 478\tTrain Loss: 0.1355772 \tVal Loss:0.0436632 \tTrain Acc: 96.04412% \tVal Acc: 99.1176456%\n",
      "Epoch: 479\tTrain Loss: 0.1411443 \tVal Loss:0.0337354 \tTrain Acc: 95.75% \tVal Acc: 98.9999992%\n",
      "Epoch: 480\tTrain Loss: 0.1601478 \tVal Loss:0.0703281 \tTrain Acc: 94.86765% \tVal Acc: 98.1176454%\n",
      "Epoch: 481\tTrain Loss: 0.2256745 \tVal Loss:0.1009035 \tTrain Acc: 93.10294% \tVal Acc: 96.7058820%\n",
      "Epoch: 482\tTrain Loss: 0.2749400 \tVal Loss:0.1521222 \tTrain Acc: 91.52941% \tVal Acc: 96.1764693%\n",
      "Epoch: 483\tTrain Loss: 0.3237684 \tVal Loss:0.1129235 \tTrain Acc: 90.14706% \tVal Acc: 97.4117631%\n",
      "Epoch: 484\tTrain Loss: 0.2823824 \tVal Loss:0.0556069 \tTrain Acc: 91.63235% \tVal Acc: 98.5294098%\n",
      "Epoch: 485\tTrain Loss: 0.2876415 \tVal Loss:0.0831229 \tTrain Acc: 91.33823% \tVal Acc: 97.4705869%\n",
      "Epoch: 486\tTrain Loss: 0.2455495 \tVal Loss:0.0682660 \tTrain Acc: 92.73529% \tVal Acc: 98.1176466%\n",
      "Epoch: 487\tTrain Loss: 0.1954714 \tVal Loss:0.0223021 \tTrain Acc: 94.16176% \tVal Acc: 99.4117641%\n",
      "Epoch: 488\tTrain Loss: 0.1490359 \tVal Loss:0.0248740 \tTrain Acc: 95.5% \tVal Acc: 99.3529397%\n",
      "Epoch: 489\tTrain Loss: 0.1345349 \tVal Loss:0.0163805 \tTrain Acc: 96.02941% \tVal Acc: 99.5882338%\n",
      "Epoch: 490\tTrain Loss: 0.1182215 \tVal Loss:0.0197040 \tTrain Acc: 96.72059% \tVal Acc: 99.2941171%\n",
      "Epoch: 491\tTrain Loss: 0.1143567 \tVal Loss:0.0138969 \tTrain Acc: 96.67647% \tVal Acc: 99.5294112%\n",
      "Validation Loss decreased from 0.014111 to 0.013897, saving the model weights\n",
      "Epoch: 492\tTrain Loss: 0.1051420 \tVal Loss:0.0216620 \tTrain Acc: 97.02941% \tVal Acc: 99.2941171%\n",
      "Epoch: 493\tTrain Loss: 0.1021059 \tVal Loss:0.0155804 \tTrain Acc: 97.14706% \tVal Acc: 99.4117641%\n",
      "Epoch: 494\tTrain Loss: 0.0995244 \tVal Loss:0.0142609 \tTrain Acc: 97.11765% \tVal Acc: 99.5294106%\n",
      "Epoch: 495\tTrain Loss: 0.0965680 \tVal Loss:0.0155111 \tTrain Acc: 97.30882% \tVal Acc: 99.4117641%\n",
      "Epoch: 496\tTrain Loss: 0.0954704 \tVal Loss:0.0134612 \tTrain Acc: 97.27941% \tVal Acc: 99.5294112%\n",
      "Validation Loss decreased from 0.013897 to 0.013461, saving the model weights\n",
      "Epoch: 497\tTrain Loss: 0.1035775 \tVal Loss:0.0141206 \tTrain Acc: 96.73529% \tVal Acc: 99.4705874%\n",
      "Epoch: 498\tTrain Loss: 0.1016995 \tVal Loss:0.0124945 \tTrain Acc: 97.23529% \tVal Acc: 99.5882338%\n",
      "Validation Loss decreased from 0.013461 to 0.012495, saving the model weights\n",
      "Epoch: 499\tTrain Loss: 0.0916699 \tVal Loss:0.0120804 \tTrain Acc: 97.58823% \tVal Acc: 99.6470582%\n",
      "Validation Loss decreased from 0.012495 to 0.012080, saving the model weights\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "min_val_loss = np.Inf\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    train_accuracy = 0\n",
    "    val_accuracy = 0\n",
    "    \n",
    "    \n",
    "    hidden1, hidden2 = model.hidden_init(train_batch_size)    \n",
    "    #print('hidden[0].shape:- ',hidden[0].shape)\n",
    "    \n",
    "    for inputs,labels in train_loader:\n",
    "        #print(inputs.shape)\n",
    "\n",
    "        '''\n",
    "        Creating new variables for the hidden state, otherwise\n",
    "        we'd backprop through the entire training history\n",
    "        '''\n",
    "        #h = tuple([each.data for each in hidden])\n",
    "        \n",
    "        h1 = tuple([each.data for each in hidden1])\n",
    "        h2 = tuple([each.data for each in hidden2])\n",
    "        \n",
    "        # zero accumulated gradients\n",
    "        model.zero_grad()\n",
    "       \n",
    "        # get the output from the model\n",
    "        output, _ = model.forward(inputs, h1, h2, train_batch_size)\n",
    "        #print('OUTPUT', output)\n",
    "        \n",
    "        \n",
    "        #print('Labels Shape :-', (torch.max(labels, 1)[1]).shape)\n",
    "    \n",
    "        # calculate the loss and perform backprop\n",
    "        #print('Labels Long :-', labels.long())\n",
    "        loss = criterion(output,labels.long())\n",
    "        #print('LOSS IS :-', loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #calculate training accuracy\n",
    "        output = F.softmax(output, dim = 1)\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "        logging.debug(' top probab {} top class {}'.format(top_p.view(-1, top_p.shape[0]), top_class.view(-1, top_p.shape[0])))\n",
    "\n",
    "        equals = top_class == labels.long().view(*top_class.shape)\n",
    "        train_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        \n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        #nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        #print(train_loss)\n",
    "              \n",
    "    model.eval()\n",
    "    for inputs, labels in val_loader:\n",
    "                \n",
    "        val_h1 = tuple([each.data for each in hidden1])\n",
    "        val_h2 = tuple([each.data for each in hidden2])\n",
    "        \n",
    "        output, _ = model.forward(inputs, val_h1, val_h2,val_batch_size)\n",
    "       \n",
    "        loss = criterion(output,labels.long())\n",
    "        \n",
    "        val_loss += loss.item()\n",
    "        \n",
    "        #calculate validation accuracy\n",
    "        output = F.softmax(output, dim = 1)\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "        \n",
    "        #logging.debug(output)\n",
    "        #logging.debug('VALIDATION top probab {} VALIDATION top class {}'.format(top_p.view(-1, top_p.shape[0]), top_class.view(-1, top_p.shape[0])))\n",
    "\n",
    "        #print('Top Class:- ',top_class)\n",
    "        equals = top_class == labels.long().view(*top_class.shape)\n",
    "        #print('Equals:- ', equals)\n",
    "        val_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    #Averaging losses\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    val_loss = val_loss/len(val_loader)\n",
    "    val_accuracy = val_accuracy/len(val_loader)\n",
    "    train_accuracy = train_accuracy/len(train_loader)\n",
    "    \n",
    "    print('Epoch: {}\\tTrain Loss: {:.7f} \\tVal Loss:{:.7f} \\tTrain Acc: {:.7}% \\tVal Acc: {:.7f}%'.format(e, train_loss, val_loss, train_accuracy*100,val_accuracy*100))\n",
    "    \n",
    "    #saving the model if validation loss is decreased\n",
    "    if val_loss <= min_val_loss:\n",
    "        print('Validation Loss decreased from {:6f} to {:6f}, saving the model weights'.format(min_val_loss, val_loss))\n",
    "        torch.save(model.state_dict(), 'lstm_state_256_different_layers_testing.pt')\n",
    "        min_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUSIC GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stacked_LSTM(\n",
       "  (lstm1): LSTM(1, 256, batch_first=True)\n",
       "  (lstm2): LSTM(256, 38, batch_first=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=38, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights\n",
    "test_model = Stacked_LSTM(input_size,hidden_size,num_layer,output_size)\n",
    "test_model.load_state_dict(torch.load('lstm_state_256_different_layers_testing.pt'))\n",
    "test_model.eval()\n",
    "test_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load population database\n",
    "testing_data = np.ones(200)*0\n",
    "# testing_data = list(range(50,90))\n",
    "# testing_data.extend(testing_data[::-1])\n",
    "# testing_data = np.asarray(testing_data)\n",
    "testing_data = testing_data.reshape(testing_data.shape[0],1)\n",
    "\n",
    "initial_seq = [network_input[0][1:].cpu().numpy().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting\n",
    "def prediction_with_influence(influence,int2note,initial_seq, max_note, test_batch_size = 1):\n",
    "\n",
    "    predicted_notes = []\n",
    "    initial_seq[0].extend([[0]]*len(testing_data))\n",
    "    test_seq = torch.Tensor(initial_seq).cuda()\n",
    "    \n",
    "    h1, h2 = test_model.hidden_init(test_batch_size)\n",
    "\n",
    "    \n",
    "    for i in range(len(influence)):\n",
    "        \n",
    "        test_seq[0][sequence_length - 1 + i][0] = float(influence[i])\n",
    "        \n",
    "        test_slice = test_seq[0][i : i + sequence_length]        \n",
    "        test_slice = test_slice.view(1, test_slice.shape[0], test_slice.shape[1])\n",
    "                \n",
    "        test_hidden1 = tuple([each.data for each in h1])\n",
    "        test_hidden2 = tuple([each.data for each in h2])\n",
    "        \n",
    "        test_output,_ = test_model.forward(test_slice, test_hidden1, test_hidden2, test_batch_size)\n",
    "    \n",
    "        test_output = F.softmax(test_output, dim = 1)\n",
    "        top_p, top_class = test_output.topk(1,dim =1)\n",
    "        test_seq[0][sequence_length - 1 + i][0] = int2note[top_class.item()]/max_note\n",
    "        \n",
    "        predicted_notes.append(int2note[top_class.item()])\n",
    "        \n",
    "    return predicted_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_notes_lst = prediction_with_influence(testing_data,int_to_note,initial_seq, max_midi_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_notes_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e886229f28>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 369
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(list(np.ones(200)*89))\n",
    "plt.plot(list(np.ones(200)*50))\n",
    "#plt.plot(testing_data)\n",
    "plt.plot(predicted_notes_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({86: 10, 83: 13, 79: 1, 84: 11, 81: 4, 85: 161})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter(predicted_notes_lst)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
