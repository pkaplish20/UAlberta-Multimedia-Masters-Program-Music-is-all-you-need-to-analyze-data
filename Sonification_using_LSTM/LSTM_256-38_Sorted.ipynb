{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.tensorboard as tb\n",
    "from Preprocessing.preprocessing_sorted import PreprocessingTrainingData\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as  plt\n",
    "import os\n",
    "import logging\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#static parameters\n",
    "train_batch_size = 60\n",
    "val_batch_size = 60\n",
    "sequence_length=50\n",
    "test_batch_size = 1\n",
    "input_size = 1\n",
    "hidden_size = 256\n",
    "num_layer = 2\n",
    "output_size = 38\n",
    "clip = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from preprocessing.py\n",
    "dataset_path = os.path.join(os.path.abspath('..'),'Dataset\\\\Clementi dataset\\\\Clementi dataset' )\n",
    "network_input,network_output,max_midi_number,min_midi_number,int_to_note = PreprocessingTrainingData().preprocess_notes(dataset_path)\n",
    "network_input, network_output = network_input.cuda(), network_output.cuda()\n",
    "\n",
    "# print(network_input)\n",
    "#print(network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(37, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(network_output.max())\n",
    "print(network_output.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "89\n",
      "50\n",
      "{0: 50, 1: 52, 2: 53, 3: 54, 4: 55, 5: 56, 6: 57, 7: 58, 8: 59, 9: 60, 10: 61, 11: 62, 12: 63, 13: 64, 14: 65, 15: 66, 16: 67, 17: 68, 18: 69, 19: 70, 20: 71, 21: 72, 22: 73, 23: 74, 24: 75, 25: 76, 26: 77, 27: 78, 28: 79, 29: 80, 30: 81, 31: 82, 32: 83, 33: 84, 34: 85, 35: 86, 36: 88, 37: 89}\n"
     ]
    }
   ],
   "source": [
    "print(network_input.max())\n",
    "print(network_input.min())\n",
    "print(max_midi_number)\n",
    "print(min_midi_number)\n",
    "print(int_to_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utkar\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\utkar\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    values\n",
       "0         \n",
       "0        2\n",
       "1        3\n",
       "2        7\n",
       "3        2\n",
       "4       24\n",
       "5        3\n",
       "6       21\n",
       "7        4\n",
       "8       39\n",
       "9       64\n",
       "10      45\n",
       "11      65\n",
       "12      19\n",
       "13      65\n",
       "14      64\n",
       "15      65\n",
       "16      83\n",
       "17      65\n",
       "18      65\n",
       "19      64\n",
       "20      65\n",
       "21      78\n",
       "22      65\n",
       "23      95\n",
       "24      65\n",
       "25      67\n",
       "26      64\n",
       "27      65\n",
       "28      68\n",
       "29      30\n",
       "30      65\n",
       "31      32\n",
       "32      65\n",
       "33      65\n",
       "34      64\n",
       "35      65\n",
       "36      37\n",
       "37       5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 385
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "data is highly unbalanced\n",
    "# '''\n",
    "sns.distplot(torch.tensor(network_output).cpu())\n",
    "xx = pd.DataFrame(torch.tensor(network_output).cpu())\n",
    "xx.groupby(0).size().to_frame(name='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1800, 50, 1])\n",
      "torch.Size([1800])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "to make batch of equal sizes\n",
    "Quick Fix\n",
    "'''\n",
    "network_input = network_input[: -29]\n",
    "network_output = network_output[: -29]\n",
    "\n",
    "print(network_input.shape)\n",
    "print(network_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create Stacked LSTM model\n",
    "'''\n",
    "class Stacked_LSTM(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = 1, batch_first = True)\n",
    "        self.lstm2 = nn.LSTM(input_size = hidden_size, hidden_size = output_size, num_layers = 1, batch_first = True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(output_size, output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hidden1, hidden2,batch_size):\n",
    "        \n",
    "        output, hidden1 = self.lstm1(x, hidden1)        \n",
    "        #print(output.shape)\n",
    "        \n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        output, hidden2 = self.lstm2(output, hidden2)\n",
    "        #print(output.shape)\n",
    "        \n",
    "        # stack up lstm outputs\n",
    "        output = output.contiguous().view(-1, 38)\n",
    "        #print(output.shape)\n",
    "        \n",
    "        output = self.dropout(output)\n",
    "        output = self.linear(output)\n",
    "        #print('Linear Output :-',output.shape)\n",
    "        \n",
    "        #output = F.softmax(output, dim = 1)\n",
    "        #print('SOFTMAX OUTPUT :--', output)\n",
    "        \n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        output = output.view(batch_size, -1)\n",
    "        #print('Reshape to batch size first :-',output.shape)\n",
    "        \n",
    "        output = output[:, -self.output_size:] # get last batch of labels\n",
    "        #print('Final Output :-',output)\n",
    "        #print('RESHAPE SIZE :-', output.shape)\n",
    "        \n",
    "        return output, hidden2\n",
    "    \n",
    "    def hidden_init(self,batch_size):\n",
    "        \n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden1 = (weight.new(1, batch_size, self.hidden_size).zero_().cuda(),\n",
    "          weight.new(1, batch_size, self.hidden_size).zero_().cuda())\n",
    "        \n",
    "        hidden2 = (weight.new(1, batch_size, 38).zero_().cuda(),\n",
    "          weight.new(1, batch_size, 38).zero_().cuda())\n",
    "        return hidden1,hidden2\n",
    "\n",
    "#initialize the weights of LSTM using Xavier initialization    \n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Divide the dataset into train/val \n",
    "'''\n",
    "train_size = 0.8\n",
    "indices = list(range(len(network_input)))\n",
    "split = int(np.floor(train_size*len(network_input)))\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "train_sampler = SequentialSampler(train_idx)\n",
    "val_sampler = SequentialSampler(val_idx)\n",
    "\n",
    "dataset = TensorDataset(network_input,network_output)\n",
    "train_loader = DataLoader(dataset, batch_size= train_batch_size, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset, batch_size= val_batch_size,sampler= val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stacked_LSTM(\n",
       "  (lstm1): LSTM(1, 256, batch_first=True)\n",
       "  (lstm2): LSTM(256, 38, batch_first=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=38, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optimizer\n",
    "\n",
    "model = Stacked_LSTM(input_size,hidden_size,num_layer,output_size)\n",
    "model.apply(init_weights)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optimizer.AdamW(model.parameters())\n",
    "#optimizer = optimizer.RMSprop(model.parameters(), lr = 0.001, weight_decay = 0.01)\n",
    "\n",
    "\n",
    "#make sure to transfer model to GPU after initializing optimizer\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden = model.hidden_init(train_batch_size) \n",
    "#hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTrain Loss: 3.6161777 \tVal Loss:3.4479937 \tTrain Acc: 4.097222% \tVal Acc: 9.7222225%\n",
      "Validation Loss decreased from    inf to 3.447994, saving the model weights\n",
      "Epoch: 1\tTrain Loss: 3.5096459 \tVal Loss:3.2864229 \tTrain Acc: 3.541667% \tVal Acc: 9.7222225%\n",
      "Validation Loss decreased from 3.447994 to 3.286423, saving the model weights\n",
      "Epoch: 2\tTrain Loss: 3.4104355 \tVal Loss:3.2137272 \tTrain Acc: 4.652778% \tVal Acc: 8.8888891%\n",
      "Validation Loss decreased from 3.286423 to 3.213727, saving the model weights\n",
      "Epoch: 3\tTrain Loss: 3.3818594 \tVal Loss:3.1788160 \tTrain Acc: 3.680556% \tVal Acc: 8.8888891%\n",
      "Validation Loss decreased from 3.213727 to 3.178816, saving the model weights\n",
      "Epoch: 4\tTrain Loss: 3.3538115 \tVal Loss:3.1596198 \tTrain Acc: 4.027778% \tVal Acc: 8.8888891%\n",
      "Validation Loss decreased from 3.178816 to 3.159620, saving the model weights\n",
      "Epoch: 5\tTrain Loss: 3.3428827 \tVal Loss:3.1475785 \tTrain Acc: 5.208333% \tVal Acc: 8.8888891%\n",
      "Validation Loss decreased from 3.159620 to 3.147579, saving the model weights\n",
      "Epoch: 6\tTrain Loss: 3.3408763 \tVal Loss:3.1443195 \tTrain Acc: 5.694445% \tVal Acc: 8.8888891%\n",
      "Validation Loss decreased from 3.147579 to 3.144319, saving the model weights\n",
      "Epoch: 7\tTrain Loss: 3.3247355 \tVal Loss:3.1418258 \tTrain Acc: 5.555556% \tVal Acc: 9.4444446%\n",
      "Validation Loss decreased from 3.144319 to 3.141826, saving the model weights\n",
      "Epoch: 8\tTrain Loss: 3.3170860 \tVal Loss:3.1506366 \tTrain Acc: 5.625% \tVal Acc: 15.5555557%\n",
      "Epoch: 9\tTrain Loss: 3.3128522 \tVal Loss:3.1187478 \tTrain Acc: 5.0% \tVal Acc: 13.6111115%\n",
      "Validation Loss decreased from 3.141826 to 3.118748, saving the model weights\n",
      "Epoch: 10\tTrain Loss: 3.2884331 \tVal Loss:3.1005383 \tTrain Acc: 6.111111% \tVal Acc: 12.7777781%\n",
      "Validation Loss decreased from 3.118748 to 3.100538, saving the model weights\n",
      "Epoch: 11\tTrain Loss: 3.2657459 \tVal Loss:3.1213849 \tTrain Acc: 6.111111% \tVal Acc: 11.1111112%\n",
      "Epoch: 12\tTrain Loss: 3.2732427 \tVal Loss:3.1322106 \tTrain Acc: 5.902778% \tVal Acc: 10.0000001%\n",
      "Epoch: 13\tTrain Loss: 3.2757426 \tVal Loss:3.0896233 \tTrain Acc: 5.277778% \tVal Acc: 13.0555560%\n",
      "Validation Loss decreased from 3.100538 to 3.089623, saving the model weights\n",
      "Epoch: 14\tTrain Loss: 3.2404287 \tVal Loss:3.2042094 \tTrain Acc: 6.666667% \tVal Acc: 2.7777779%\n",
      "Epoch: 15\tTrain Loss: 3.2179817 \tVal Loss:2.9868464 \tTrain Acc: 8.055556% \tVal Acc: 12.2222225%\n",
      "Validation Loss decreased from 3.089623 to 2.986846, saving the model weights\n",
      "Epoch: 16\tTrain Loss: 3.1726636 \tVal Loss:2.9421115 \tTrain Acc: 7.430556% \tVal Acc: 13.8888893%\n",
      "Validation Loss decreased from 2.986846 to 2.942111, saving the model weights\n",
      "Epoch: 17\tTrain Loss: 3.1501350 \tVal Loss:2.9285973 \tTrain Acc: 7.222222% \tVal Acc: 14.1666671%\n",
      "Validation Loss decreased from 2.942111 to 2.928597, saving the model weights\n",
      "Epoch: 18\tTrain Loss: 3.1122320 \tVal Loss:2.9386539 \tTrain Acc: 8.263889% \tVal Acc: 15.0000002%\n",
      "Epoch: 19\tTrain Loss: 3.1139355 \tVal Loss:3.0156490 \tTrain Acc: 9.513889% \tVal Acc: 14.7222226%\n",
      "Epoch: 20\tTrain Loss: 3.1148245 \tVal Loss:3.1286678 \tTrain Acc: 9.166667% \tVal Acc: 8.0555557%\n",
      "Epoch: 21\tTrain Loss: 3.1159157 \tVal Loss:2.9809358 \tTrain Acc: 7.638889% \tVal Acc: 14.7222226%\n",
      "Epoch: 22\tTrain Loss: 3.0891588 \tVal Loss:2.8843455 \tTrain Acc: 9.027778% \tVal Acc: 19.4444449%\n",
      "Validation Loss decreased from 2.928597 to 2.884345, saving the model weights\n",
      "Epoch: 23\tTrain Loss: 3.0658362 \tVal Loss:2.8319050 \tTrain Acc: 8.402778% \tVal Acc: 16.3888890%\n",
      "Validation Loss decreased from 2.884345 to 2.831905, saving the model weights\n",
      "Epoch: 24\tTrain Loss: 3.0291022 \tVal Loss:2.8231200 \tTrain Acc: 9.791667% \tVal Acc: 15.0000003%\n",
      "Validation Loss decreased from 2.831905 to 2.823120, saving the model weights\n",
      "Epoch: 25\tTrain Loss: 2.9964442 \tVal Loss:2.8134257 \tTrain Acc: 10.48611% \tVal Acc: 14.4444448%\n",
      "Validation Loss decreased from 2.823120 to 2.813426, saving the model weights\n",
      "Epoch: 26\tTrain Loss: 2.9676440 \tVal Loss:2.7928136 \tTrain Acc: 10.13889% \tVal Acc: 14.1666671%\n",
      "Validation Loss decreased from 2.813426 to 2.792814, saving the model weights\n",
      "Epoch: 27\tTrain Loss: 2.9447055 \tVal Loss:2.7867840 \tTrain Acc: 11.04167% \tVal Acc: 13.6111115%\n",
      "Validation Loss decreased from 2.792814 to 2.786784, saving the model weights\n",
      "Epoch: 28\tTrain Loss: 2.9454478 \tVal Loss:2.7601117 \tTrain Acc: 10.625% \tVal Acc: 14.7222226%\n",
      "Validation Loss decreased from 2.786784 to 2.760112, saving the model weights\n",
      "Epoch: 29\tTrain Loss: 2.9294499 \tVal Loss:2.7554533 \tTrain Acc: 10.625% \tVal Acc: 14.1666671%\n",
      "Validation Loss decreased from 2.760112 to 2.755453, saving the model weights\n",
      "Epoch: 30\tTrain Loss: 2.9038970 \tVal Loss:2.7496810 \tTrain Acc: 11.38889% \tVal Acc: 12.2222225%\n",
      "Validation Loss decreased from 2.755453 to 2.749681, saving the model weights\n",
      "Epoch: 31\tTrain Loss: 2.8911356 \tVal Loss:2.7370387 \tTrain Acc: 11.11111% \tVal Acc: 13.8888893%\n",
      "Validation Loss decreased from 2.749681 to 2.737039, saving the model weights\n",
      "Epoch: 32\tTrain Loss: 2.8843870 \tVal Loss:2.7194893 \tTrain Acc: 10.69444% \tVal Acc: 13.3333335%\n",
      "Validation Loss decreased from 2.737039 to 2.719489, saving the model weights\n",
      "Epoch: 33\tTrain Loss: 2.8790410 \tVal Loss:2.7021908 \tTrain Acc: 11.73611% \tVal Acc: 12.2222225%\n",
      "Validation Loss decreased from 2.719489 to 2.702191, saving the model weights\n",
      "Epoch: 34\tTrain Loss: 2.8496408 \tVal Loss:2.7027845 \tTrain Acc: 12.91667% \tVal Acc: 12.5000002%\n",
      "Epoch: 35\tTrain Loss: 2.8212097 \tVal Loss:2.7036158 \tTrain Acc: 12.91667% \tVal Acc: 12.5000002%\n",
      "Epoch: 36\tTrain Loss: 2.8266356 \tVal Loss:2.7038842 \tTrain Acc: 12.15278% \tVal Acc: 13.6111115%\n",
      "Epoch: 37\tTrain Loss: 2.8159289 \tVal Loss:2.6879160 \tTrain Acc: 12.77778% \tVal Acc: 12.5000002%\n",
      "Validation Loss decreased from 2.702191 to 2.687916, saving the model weights\n",
      "Epoch: 38\tTrain Loss: 2.8079844 \tVal Loss:2.6646585 \tTrain Acc: 12.98611% \tVal Acc: 14.1666671%\n",
      "Validation Loss decreased from 2.687916 to 2.664658, saving the model weights\n",
      "Epoch: 39\tTrain Loss: 2.8060037 \tVal Loss:2.6682167 \tTrain Acc: 13.68056% \tVal Acc: 13.0555560%\n",
      "Epoch: 40\tTrain Loss: 2.7852296 \tVal Loss:2.6686101 \tTrain Acc: 13.61111% \tVal Acc: 13.6111115%\n",
      "Epoch: 41\tTrain Loss: 2.7645594 \tVal Loss:2.6728009 \tTrain Acc: 13.26389% \tVal Acc: 14.1666671%\n",
      "Epoch: 42\tTrain Loss: 2.7685001 \tVal Loss:2.6534972 \tTrain Acc: 12.91667% \tVal Acc: 12.2222227%\n",
      "Validation Loss decreased from 2.664658 to 2.653497, saving the model weights\n",
      "Epoch: 43\tTrain Loss: 2.7482503 \tVal Loss:2.6336393 \tTrain Acc: 14.02778% \tVal Acc: 12.5000005%\n",
      "Validation Loss decreased from 2.653497 to 2.633639, saving the model weights\n",
      "Epoch: 44\tTrain Loss: 2.7443938 \tVal Loss:2.6404661 \tTrain Acc: 14.79167% \tVal Acc: 11.9444447%\n",
      "Epoch: 45\tTrain Loss: 2.7499736 \tVal Loss:2.6235168 \tTrain Acc: 13.61111% \tVal Acc: 12.2222225%\n",
      "Validation Loss decreased from 2.633639 to 2.623517, saving the model weights\n",
      "Epoch: 46\tTrain Loss: 2.7274107 \tVal Loss:2.6398036 \tTrain Acc: 13.54167% \tVal Acc: 11.6666670%\n",
      "Epoch: 47\tTrain Loss: 2.7289167 \tVal Loss:2.5878412 \tTrain Acc: 14.44444% \tVal Acc: 12.2222226%\n",
      "Validation Loss decreased from 2.623517 to 2.587841, saving the model weights\n",
      "Epoch: 48\tTrain Loss: 2.6955523 \tVal Loss:2.5689287 \tTrain Acc: 16.45833% \tVal Acc: 18.3333335%\n",
      "Validation Loss decreased from 2.587841 to 2.568929, saving the model weights\n",
      "Epoch: 49\tTrain Loss: 2.7085870 \tVal Loss:2.5746787 \tTrain Acc: 15.90278% \tVal Acc: 17.2222227%\n",
      "Epoch: 50\tTrain Loss: 2.6850628 \tVal Loss:2.5350911 \tTrain Acc: 15.83333% \tVal Acc: 21.9444445%\n",
      "Validation Loss decreased from 2.568929 to 2.535091, saving the model weights\n",
      "Epoch: 51\tTrain Loss: 2.6687738 \tVal Loss:2.5506959 \tTrain Acc: 16.45833% \tVal Acc: 18.3333336%\n",
      "Epoch: 52\tTrain Loss: 2.6881573 \tVal Loss:2.5308580 \tTrain Acc: 16.52778% \tVal Acc: 17.2222226%\n",
      "Validation Loss decreased from 2.535091 to 2.530858, saving the model weights\n",
      "Epoch: 53\tTrain Loss: 2.6622623 \tVal Loss:2.5237220 \tTrain Acc: 16.73611% \tVal Acc: 19.1666670%\n",
      "Validation Loss decreased from 2.530858 to 2.523722, saving the model weights\n",
      "Epoch: 54\tTrain Loss: 2.6660552 \tVal Loss:2.5227112 \tTrain Acc: 16.52778% \tVal Acc: 17.7777780%\n",
      "Validation Loss decreased from 2.523722 to 2.522711, saving the model weights\n",
      "Epoch: 55\tTrain Loss: 2.6503931 \tVal Loss:2.4842038 \tTrain Acc: 16.59722% \tVal Acc: 21.6666672%\n",
      "Validation Loss decreased from 2.522711 to 2.484204, saving the model weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56\tTrain Loss: 2.6812657 \tVal Loss:2.5753951 \tTrain Acc: 17.91667% \tVal Acc: 13.3333335%\n",
      "Epoch: 57\tTrain Loss: 2.6644335 \tVal Loss:2.5314693 \tTrain Acc: 17.22222% \tVal Acc: 17.7777782%\n",
      "Epoch: 58\tTrain Loss: 2.6624126 \tVal Loss:2.4953632 \tTrain Acc: 17.01389% \tVal Acc: 22.2222224%\n",
      "Epoch: 59\tTrain Loss: 2.6483391 \tVal Loss:2.5068866 \tTrain Acc: 17.15278% \tVal Acc: 19.4444450%\n",
      "Epoch: 60\tTrain Loss: 2.6529973 \tVal Loss:2.5143514 \tTrain Acc: 15.76389% \tVal Acc: 18.6111116%\n",
      "Epoch: 61\tTrain Loss: 2.6688503 \tVal Loss:2.5158737 \tTrain Acc: 14.86111% \tVal Acc: 18.8888891%\n",
      "Epoch: 62\tTrain Loss: 2.6310066 \tVal Loss:2.4816039 \tTrain Acc: 16.80556% \tVal Acc: 19.7222225%\n",
      "Validation Loss decreased from 2.484204 to 2.481604, saving the model weights\n",
      "Epoch: 63\tTrain Loss: 2.6351730 \tVal Loss:2.4977857 \tTrain Acc: 16.31944% \tVal Acc: 20.5555558%\n",
      "Epoch: 64\tTrain Loss: 2.6262901 \tVal Loss:2.5349903 \tTrain Acc: 17.98611% \tVal Acc: 17.2222226%\n",
      "Epoch: 65\tTrain Loss: 2.6284908 \tVal Loss:2.5441226 \tTrain Acc: 17.70833% \tVal Acc: 16.3888893%\n",
      "Epoch: 66\tTrain Loss: 2.6197193 \tVal Loss:2.5599755 \tTrain Acc: 17.43056% \tVal Acc: 17.7777782%\n",
      "Epoch: 67\tTrain Loss: 2.6439487 \tVal Loss:2.5752264 \tTrain Acc: 16.66667% \tVal Acc: 17.7777782%\n",
      "Epoch: 68\tTrain Loss: 2.6277873 \tVal Loss:2.5249083 \tTrain Acc: 16.45833% \tVal Acc: 17.2222227%\n",
      "Epoch: 69\tTrain Loss: 2.6154764 \tVal Loss:2.4798775 \tTrain Acc: 17.36111% \tVal Acc: 21.6666671%\n",
      "Validation Loss decreased from 2.481604 to 2.479878, saving the model weights\n",
      "Epoch: 70\tTrain Loss: 2.5961526 \tVal Loss:2.4133300 \tTrain Acc: 18.125% \tVal Acc: 25.8333333%\n",
      "Validation Loss decreased from 2.479878 to 2.413330, saving the model weights\n",
      "Epoch: 71\tTrain Loss: 2.5764842 \tVal Loss:2.3468812 \tTrain Acc: 19.30556% \tVal Acc: 28.0555554%\n",
      "Validation Loss decreased from 2.413330 to 2.346881, saving the model weights\n",
      "Epoch: 72\tTrain Loss: 2.5462310 \tVal Loss:2.3442112 \tTrain Acc: 19.86111% \tVal Acc: 25.8333333%\n",
      "Validation Loss decreased from 2.346881 to 2.344211, saving the model weights\n",
      "Epoch: 73\tTrain Loss: 2.5299987 \tVal Loss:2.3212949 \tTrain Acc: 21.04167% \tVal Acc: 29.4444444%\n",
      "Validation Loss decreased from 2.344211 to 2.321295, saving the model weights\n",
      "Epoch: 74\tTrain Loss: 2.5171202 \tVal Loss:2.3547266 \tTrain Acc: 20.76389% \tVal Acc: 26.1111113%\n",
      "Epoch: 75\tTrain Loss: 2.5306153 \tVal Loss:2.3060096 \tTrain Acc: 20.41667% \tVal Acc: 31.9444445%\n",
      "Validation Loss decreased from 2.321295 to 2.306010, saving the model weights\n",
      "Epoch: 76\tTrain Loss: 2.5037599 \tVal Loss:2.3113245 \tTrain Acc: 20.76389% \tVal Acc: 28.6111116%\n",
      "Epoch: 77\tTrain Loss: 2.4950724 \tVal Loss:2.3353068 \tTrain Acc: 22.15278% \tVal Acc: 25.5555558%\n",
      "Epoch: 78\tTrain Loss: 2.5176973 \tVal Loss:2.3618046 \tTrain Acc: 20.48611% \tVal Acc: 26.9444451%\n",
      "Epoch: 79\tTrain Loss: 2.5216117 \tVal Loss:2.3220833 \tTrain Acc: 20.83333% \tVal Acc: 26.6666666%\n",
      "Epoch: 80\tTrain Loss: 2.4887704 \tVal Loss:2.2812080 \tTrain Acc: 21.11111% \tVal Acc: 28.0555559%\n",
      "Validation Loss decreased from 2.306010 to 2.281208, saving the model weights\n",
      "Epoch: 81\tTrain Loss: 2.4837163 \tVal Loss:2.2995172 \tTrain Acc: 22.22222% \tVal Acc: 30.8333335%\n",
      "Epoch: 82\tTrain Loss: 2.4640777 \tVal Loss:2.2660730 \tTrain Acc: 22.56944% \tVal Acc: 26.9444453%\n",
      "Validation Loss decreased from 2.281208 to 2.266073, saving the model weights\n",
      "Epoch: 83\tTrain Loss: 2.4879070 \tVal Loss:2.2295933 \tTrain Acc: 22.08333% \tVal Acc: 29.7222224%\n",
      "Validation Loss decreased from 2.266073 to 2.229593, saving the model weights\n",
      "Epoch: 84\tTrain Loss: 2.4345325 \tVal Loss:2.2216450 \tTrain Acc: 22.56945% \tVal Acc: 29.4444447%\n",
      "Validation Loss decreased from 2.229593 to 2.221645, saving the model weights\n",
      "Epoch: 85\tTrain Loss: 2.4357595 \tVal Loss:2.1869055 \tTrain Acc: 23.68056% \tVal Acc: 31.1111115%\n",
      "Validation Loss decreased from 2.221645 to 2.186906, saving the model weights\n",
      "Epoch: 86\tTrain Loss: 2.4069269 \tVal Loss:2.1970686 \tTrain Acc: 22.84722% \tVal Acc: 31.1111115%\n",
      "Epoch: 87\tTrain Loss: 2.4370806 \tVal Loss:2.2045770 \tTrain Acc: 22.22222% \tVal Acc: 30.0000004%\n",
      "Epoch: 88\tTrain Loss: 2.3969532 \tVal Loss:2.1989553 \tTrain Acc: 23.47222% \tVal Acc: 28.0555559%\n",
      "Epoch: 89\tTrain Loss: 2.4124729 \tVal Loss:2.2071957 \tTrain Acc: 23.75% \tVal Acc: 31.6666673%\n",
      "Epoch: 90\tTrain Loss: 2.4109307 \tVal Loss:2.2006037 \tTrain Acc: 23.61111% \tVal Acc: 31.1111110%\n",
      "Epoch: 91\tTrain Loss: 2.3959358 \tVal Loss:2.1622321 \tTrain Acc: 24.30556% \tVal Acc: 31.9444445%\n",
      "Validation Loss decreased from 2.186906 to 2.162232, saving the model weights\n",
      "Epoch: 92\tTrain Loss: 2.3911792 \tVal Loss:2.1376688 \tTrain Acc: 24.02778% \tVal Acc: 32.2222225%\n",
      "Validation Loss decreased from 2.162232 to 2.137669, saving the model weights\n",
      "Epoch: 93\tTrain Loss: 2.3811000 \tVal Loss:2.1077400 \tTrain Acc: 24.72222% \tVal Acc: 32.7777781%\n",
      "Validation Loss decreased from 2.137669 to 2.107740, saving the model weights\n",
      "Epoch: 94\tTrain Loss: 2.3583040 \tVal Loss:2.1618551 \tTrain Acc: 24.93056% \tVal Acc: 33.8888894%\n",
      "Epoch: 95\tTrain Loss: 2.3787850 \tVal Loss:2.1776903 \tTrain Acc: 24.16667% \tVal Acc: 32.2222223%\n",
      "Epoch: 96\tTrain Loss: 2.3572706 \tVal Loss:2.1132083 \tTrain Acc: 24.65278% \tVal Acc: 31.9444448%\n",
      "Epoch: 97\tTrain Loss: 2.3321581 \tVal Loss:2.0992394 \tTrain Acc: 25.97222% \tVal Acc: 32.7777776%\n",
      "Validation Loss decreased from 2.107740 to 2.099239, saving the model weights\n",
      "Epoch: 98\tTrain Loss: 2.3295894 \tVal Loss:2.0784467 \tTrain Acc: 26.66667% \tVal Acc: 32.7777781%\n",
      "Validation Loss decreased from 2.099239 to 2.078447, saving the model weights\n",
      "Epoch: 99\tTrain Loss: 2.3032438 \tVal Loss:2.0559693 \tTrain Acc: 26.04167% \tVal Acc: 35.2777779%\n",
      "Validation Loss decreased from 2.078447 to 2.055969, saving the model weights\n",
      "Epoch: 100\tTrain Loss: 2.3118213 \tVal Loss:2.0401006 \tTrain Acc: 26.52778% \tVal Acc: 32.5000003%\n",
      "Validation Loss decreased from 2.055969 to 2.040101, saving the model weights\n",
      "Epoch: 101\tTrain Loss: 2.2945271 \tVal Loss:2.0502353 \tTrain Acc: 27.43056% \tVal Acc: 34.4444441%\n",
      "Epoch: 102\tTrain Loss: 2.2806865 \tVal Loss:2.0489098 \tTrain Acc: 27.36111% \tVal Acc: 36.1111109%\n",
      "Epoch: 103\tTrain Loss: 2.2932454 \tVal Loss:2.0924012 \tTrain Acc: 25.55556% \tVal Acc: 33.0555556%\n",
      "Epoch: 104\tTrain Loss: 2.3163015 \tVal Loss:2.0216976 \tTrain Acc: 26.18056% \tVal Acc: 33.0555553%\n",
      "Validation Loss decreased from 2.040101 to 2.021698, saving the model weights\n",
      "Epoch: 105\tTrain Loss: 2.2740771 \tVal Loss:2.0502171 \tTrain Acc: 26.52778% \tVal Acc: 35.8333329%\n",
      "Epoch: 106\tTrain Loss: 2.3058806 \tVal Loss:2.0347803 \tTrain Acc: 27.15278% \tVal Acc: 35.5555559%\n",
      "Epoch: 107\tTrain Loss: 2.2893465 \tVal Loss:2.0374722 \tTrain Acc: 28.26389% \tVal Acc: 33.3333333%\n",
      "Epoch: 108\tTrain Loss: 2.2696944 \tVal Loss:2.0155083 \tTrain Acc: 28.40278% \tVal Acc: 34.7222224%\n",
      "Validation Loss decreased from 2.021698 to 2.015508, saving the model weights\n",
      "Epoch: 109\tTrain Loss: 2.2506557 \tVal Loss:1.9806630 \tTrain Acc: 26.94444% \tVal Acc: 38.6111110%\n",
      "Validation Loss decreased from 2.015508 to 1.980663, saving the model weights\n",
      "Epoch: 110\tTrain Loss: 2.2347217 \tVal Loss:2.0245542 \tTrain Acc: 29.65278% \tVal Acc: 36.1111109%\n",
      "Epoch: 111\tTrain Loss: 2.2267071 \tVal Loss:1.9626039 \tTrain Acc: 30.34722% \tVal Acc: 36.9444442%\n",
      "Validation Loss decreased from 1.980663 to 1.962604, saving the model weights\n",
      "Epoch: 112\tTrain Loss: 2.2303406 \tVal Loss:1.9708250 \tTrain Acc: 27.29167% \tVal Acc: 37.5000000%\n",
      "Epoch: 113\tTrain Loss: 2.2033455 \tVal Loss:2.0426861 \tTrain Acc: 30.41667% \tVal Acc: 34.9999994%\n",
      "Epoch: 114\tTrain Loss: 2.2989430 \tVal Loss:2.0493627 \tTrain Acc: 25.41667% \tVal Acc: 35.5555557%\n",
      "Epoch: 115\tTrain Loss: 2.2253511 \tVal Loss:1.9183273 \tTrain Acc: 28.88889% \tVal Acc: 39.4444451%\n",
      "Validation Loss decreased from 1.962604 to 1.918327, saving the model weights\n",
      "Epoch: 116\tTrain Loss: 2.2159202 \tVal Loss:1.9564559 \tTrain Acc: 30.41667% \tVal Acc: 41.3888887%\n",
      "Epoch: 117\tTrain Loss: 2.2280641 \tVal Loss:1.9311909 \tTrain Acc: 27.43056% \tVal Acc: 42.2222227%\n",
      "Epoch: 118\tTrain Loss: 2.1913019 \tVal Loss:1.9613412 \tTrain Acc: 31.45833% \tVal Acc: 38.3333335%\n",
      "Epoch: 119\tTrain Loss: 2.1651709 \tVal Loss:1.8939781 \tTrain Acc: 30.27778% \tVal Acc: 42.4999992%\n",
      "Validation Loss decreased from 1.918327 to 1.893978, saving the model weights\n",
      "Epoch: 120\tTrain Loss: 2.1460856 \tVal Loss:1.8484736 \tTrain Acc: 30.20833% \tVal Acc: 46.6666664%\n",
      "Validation Loss decreased from 1.893978 to 1.848474, saving the model weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 121\tTrain Loss: 2.1507950 \tVal Loss:1.8322873 \tTrain Acc: 32.22222% \tVal Acc: 43.0555557%\n",
      "Validation Loss decreased from 1.848474 to 1.832287, saving the model weights\n",
      "Epoch: 122\tTrain Loss: 2.1582946 \tVal Loss:1.8974942 \tTrain Acc: 30.97222% \tVal Acc: 41.9444447%\n",
      "Epoch: 123\tTrain Loss: 2.1439714 \tVal Loss:1.8430928 \tTrain Acc: 31.11111% \tVal Acc: 41.9444447%\n",
      "Epoch: 124\tTrain Loss: 2.1218420 \tVal Loss:1.8356796 \tTrain Acc: 32.56944% \tVal Acc: 44.1666668%\n",
      "Epoch: 125\tTrain Loss: 2.1202245 \tVal Loss:1.8393978 \tTrain Acc: 31.04167% \tVal Acc: 40.8333331%\n",
      "Epoch: 126\tTrain Loss: 2.0956503 \tVal Loss:1.7726351 \tTrain Acc: 32.56944% \tVal Acc: 45.2777778%\n",
      "Validation Loss decreased from 1.832287 to 1.772635, saving the model weights\n",
      "Epoch: 127\tTrain Loss: 2.0960314 \tVal Loss:1.7943544 \tTrain Acc: 33.95833% \tVal Acc: 44.4444438%\n",
      "Epoch: 128\tTrain Loss: 2.1141382 \tVal Loss:1.8389186 \tTrain Acc: 32.29167% \tVal Acc: 41.9444442%\n",
      "Epoch: 129\tTrain Loss: 2.1047068 \tVal Loss:1.7954662 \tTrain Acc: 33.40278% \tVal Acc: 44.1666663%\n",
      "Epoch: 130\tTrain Loss: 2.1634325 \tVal Loss:1.8414791 \tTrain Acc: 29.23611% \tVal Acc: 43.3333327%\n",
      "Epoch: 131\tTrain Loss: 2.1409850 \tVal Loss:1.7957198 \tTrain Acc: 30.13889% \tVal Acc: 43.6111103%\n",
      "Epoch: 132\tTrain Loss: 2.0427444 \tVal Loss:1.7395044 \tTrain Acc: 34.93056% \tVal Acc: 46.1111103%\n",
      "Validation Loss decreased from 1.772635 to 1.739504, saving the model weights\n",
      "Epoch: 133\tTrain Loss: 2.0183333 \tVal Loss:1.7580506 \tTrain Acc: 36.31944% \tVal Acc: 43.8888893%\n",
      "Epoch: 134\tTrain Loss: 2.0491896 \tVal Loss:1.7161831 \tTrain Acc: 34.30556% \tVal Acc: 51.3888881%\n",
      "Validation Loss decreased from 1.739504 to 1.716183, saving the model weights\n",
      "Epoch: 135\tTrain Loss: 2.0295543 \tVal Loss:1.7159896 \tTrain Acc: 35.13889% \tVal Acc: 43.6111107%\n",
      "Validation Loss decreased from 1.716183 to 1.715990, saving the model weights\n",
      "Epoch: 136\tTrain Loss: 1.9948133 \tVal Loss:1.7298483 \tTrain Acc: 35.76389% \tVal Acc: 44.7222223%\n",
      "Epoch: 137\tTrain Loss: 2.0735123 \tVal Loss:1.8394621 \tTrain Acc: 34.58333% \tVal Acc: 45.5555553%\n",
      "Epoch: 138\tTrain Loss: 2.2027775 \tVal Loss:2.0295915 \tTrain Acc: 30.625% \tVal Acc: 36.3888890%\n",
      "Epoch: 139\tTrain Loss: 2.2128157 \tVal Loss:1.9136106 \tTrain Acc: 29.72222% \tVal Acc: 38.0555555%\n",
      "Epoch: 140\tTrain Loss: 2.1166168 \tVal Loss:1.8388451 \tTrain Acc: 32.22222% \tVal Acc: 41.9444442%\n",
      "Epoch: 141\tTrain Loss: 2.0373722 \tVal Loss:1.7861294 \tTrain Acc: 35.13889% \tVal Acc: 44.7222218%\n",
      "Epoch: 142\tTrain Loss: 2.0065870 \tVal Loss:1.7615647 \tTrain Acc: 35.34722% \tVal Acc: 44.7222218%\n",
      "Epoch: 143\tTrain Loss: 2.0132393 \tVal Loss:1.8367006 \tTrain Acc: 35.55556% \tVal Acc: 42.7777777%\n",
      "Epoch: 144\tTrain Loss: 2.0128641 \tVal Loss:1.7318498 \tTrain Acc: 35.0% \tVal Acc: 45.8333333%\n",
      "Epoch: 145\tTrain Loss: 1.9856391 \tVal Loss:1.7089388 \tTrain Acc: 36.25% \tVal Acc: 48.0555559%\n",
      "Validation Loss decreased from 1.715990 to 1.708939, saving the model weights\n",
      "Epoch: 146\tTrain Loss: 1.9581668 \tVal Loss:1.6279005 \tTrain Acc: 36.25% \tVal Acc: 52.5000006%\n",
      "Validation Loss decreased from 1.708939 to 1.627901, saving the model weights\n",
      "Epoch: 147\tTrain Loss: 1.8948281 \tVal Loss:1.6375302 \tTrain Acc: 38.40278% \tVal Acc: 53.0555551%\n",
      "Epoch: 148\tTrain Loss: 1.8941197 \tVal Loss:1.6359901 \tTrain Acc: 40.48611% \tVal Acc: 48.3333329%\n",
      "Epoch: 149\tTrain Loss: 1.8930519 \tVal Loss:1.6057136 \tTrain Acc: 38.88889% \tVal Acc: 52.2222221%\n",
      "Validation Loss decreased from 1.627901 to 1.605714, saving the model weights\n",
      "Epoch: 150\tTrain Loss: 1.9424873 \tVal Loss:1.6687328 \tTrain Acc: 36.25% \tVal Acc: 52.7777771%\n",
      "Epoch: 151\tTrain Loss: 1.8974153 \tVal Loss:1.6089276 \tTrain Acc: 38.81944% \tVal Acc: 47.2222224%\n",
      "Epoch: 152\tTrain Loss: 1.8793283 \tVal Loss:1.5797825 \tTrain Acc: 38.61111% \tVal Acc: 50.5555560%\n",
      "Validation Loss decreased from 1.605714 to 1.579783, saving the model weights\n",
      "Epoch: 153\tTrain Loss: 1.8642983 \tVal Loss:1.5504311 \tTrain Acc: 39.02778% \tVal Acc: 53.0555561%\n",
      "Validation Loss decreased from 1.579783 to 1.550431, saving the model weights\n",
      "Epoch: 154\tTrain Loss: 1.8674590 \tVal Loss:1.5462068 \tTrain Acc: 39.51389% \tVal Acc: 51.6666661%\n",
      "Validation Loss decreased from 1.550431 to 1.546207, saving the model weights\n",
      "Epoch: 155\tTrain Loss: 1.8444744 \tVal Loss:1.5633565 \tTrain Acc: 38.88889% \tVal Acc: 52.7777771%\n",
      "Epoch: 156\tTrain Loss: 1.8202104 \tVal Loss:1.5295430 \tTrain Acc: 41.25% \tVal Acc: 54.4444442%\n",
      "Validation Loss decreased from 1.546207 to 1.529543, saving the model weights\n",
      "Epoch: 157\tTrain Loss: 1.8317532 \tVal Loss:1.4936021 \tTrain Acc: 39.79167% \tVal Acc: 56.3888888%\n",
      "Validation Loss decreased from 1.529543 to 1.493602, saving the model weights\n",
      "Epoch: 158\tTrain Loss: 1.8123600 \tVal Loss:1.4790566 \tTrain Acc: 44.30556% \tVal Acc: 57.2222223%\n",
      "Validation Loss decreased from 1.493602 to 1.479057, saving the model weights\n",
      "Epoch: 159\tTrain Loss: 1.7749727 \tVal Loss:1.4955132 \tTrain Acc: 43.26389% \tVal Acc: 53.8888892%\n",
      "Epoch: 160\tTrain Loss: 1.8194385 \tVal Loss:1.4681248 \tTrain Acc: 41.11111% \tVal Acc: 56.3888883%\n",
      "Validation Loss decreased from 1.479057 to 1.468125, saving the model weights\n",
      "Epoch: 161\tTrain Loss: 1.8157885 \tVal Loss:1.4718745 \tTrain Acc: 42.70833% \tVal Acc: 51.9444446%\n",
      "Epoch: 162\tTrain Loss: 1.7836766 \tVal Loss:1.4650354 \tTrain Acc: 42.70833% \tVal Acc: 56.3888897%\n",
      "Validation Loss decreased from 1.468125 to 1.465035, saving the model weights\n",
      "Epoch: 163\tTrain Loss: 1.7605163 \tVal Loss:1.4954756 \tTrain Acc: 42.01389% \tVal Acc: 54.1666667%\n",
      "Epoch: 164\tTrain Loss: 1.7284013 \tVal Loss:1.4100567 \tTrain Acc: 46.18056% \tVal Acc: 59.4444449%\n",
      "Validation Loss decreased from 1.465035 to 1.410057, saving the model weights\n",
      "Epoch: 165\tTrain Loss: 1.7465731 \tVal Loss:1.4532431 \tTrain Acc: 41.45833% \tVal Acc: 56.3888888%\n",
      "Epoch: 166\tTrain Loss: 1.9980727 \tVal Loss:1.6678947 \tTrain Acc: 36.52778% \tVal Acc: 47.5000004%\n",
      "Epoch: 167\tTrain Loss: 1.9784360 \tVal Loss:1.5616637 \tTrain Acc: 35.90278% \tVal Acc: 50.8333335%\n",
      "Epoch: 168\tTrain Loss: 1.8677665 \tVal Loss:1.5037365 \tTrain Acc: 40.13889% \tVal Acc: 55.2777772%\n",
      "Epoch: 169\tTrain Loss: 1.7456456 \tVal Loss:1.4194566 \tTrain Acc: 45.13889% \tVal Acc: 57.5000003%\n",
      "Epoch: 170\tTrain Loss: 1.7013322 \tVal Loss:1.3967351 \tTrain Acc: 45.27778% \tVal Acc: 58.0555553%\n",
      "Validation Loss decreased from 1.410057 to 1.396735, saving the model weights\n",
      "Epoch: 171\tTrain Loss: 1.7220900 \tVal Loss:1.3771000 \tTrain Acc: 44.51389% \tVal Acc: 58.0555558%\n",
      "Validation Loss decreased from 1.396735 to 1.377100, saving the model weights\n",
      "Epoch: 172\tTrain Loss: 1.7052878 \tVal Loss:1.4088571 \tTrain Acc: 45.06944% \tVal Acc: 54.7222222%\n",
      "Epoch: 173\tTrain Loss: 1.6623425 \tVal Loss:1.3496874 \tTrain Acc: 45.55556% \tVal Acc: 58.0555553%\n",
      "Validation Loss decreased from 1.377100 to 1.349687, saving the model weights\n",
      "Epoch: 174\tTrain Loss: 1.6921529 \tVal Loss:1.4058856 \tTrain Acc: 46.31944% \tVal Acc: 60.5555539%\n",
      "Epoch: 175\tTrain Loss: 1.7135410 \tVal Loss:1.4397312 \tTrain Acc: 43.26389% \tVal Acc: 53.6111111%\n",
      "Epoch: 176\tTrain Loss: 1.6832383 \tVal Loss:1.3749606 \tTrain Acc: 46.04167% \tVal Acc: 56.9444443%\n",
      "Epoch: 177\tTrain Loss: 1.6633489 \tVal Loss:1.3680231 \tTrain Acc: 46.94444% \tVal Acc: 58.3333333%\n",
      "Epoch: 178\tTrain Loss: 1.6583022 \tVal Loss:1.3430668 \tTrain Acc: 47.01389% \tVal Acc: 63.0555565%\n",
      "Validation Loss decreased from 1.349687 to 1.343067, saving the model weights\n",
      "Epoch: 179\tTrain Loss: 1.6389708 \tVal Loss:1.3058396 \tTrain Acc: 48.125% \tVal Acc: 61.3888890%\n",
      "Validation Loss decreased from 1.343067 to 1.305840, saving the model weights\n",
      "Epoch: 180\tTrain Loss: 1.6076163 \tVal Loss:1.2855768 \tTrain Acc: 47.5% \tVal Acc: 65.0000001%\n",
      "Validation Loss decreased from 1.305840 to 1.285577, saving the model weights\n",
      "Epoch: 181\tTrain Loss: 1.5716788 \tVal Loss:1.2425130 \tTrain Acc: 48.81944% \tVal Acc: 65.2777776%\n",
      "Validation Loss decreased from 1.285577 to 1.242513, saving the model weights\n",
      "Epoch: 182\tTrain Loss: 1.5680737 \tVal Loss:1.2328739 \tTrain Acc: 49.79167% \tVal Acc: 65.8333341%\n",
      "Validation Loss decreased from 1.242513 to 1.232874, saving the model weights\n",
      "Epoch: 183\tTrain Loss: 1.5790528 \tVal Loss:1.2460213 \tTrain Acc: 48.40278% \tVal Acc: 62.4999995%\n",
      "Epoch: 184\tTrain Loss: 1.5966007 \tVal Loss:1.3299733 \tTrain Acc: 49.375% \tVal Acc: 63.6111101%\n",
      "Epoch: 185\tTrain Loss: 1.7619704 \tVal Loss:1.4524912 \tTrain Acc: 43.54167% \tVal Acc: 54.9999997%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 186\tTrain Loss: 1.6737133 \tVal Loss:1.2427095 \tTrain Acc: 45.48611% \tVal Acc: 66.3888892%\n",
      "Epoch: 187\tTrain Loss: 1.6865737 \tVal Loss:1.2599642 \tTrain Acc: 44.30556% \tVal Acc: 63.3333330%\n",
      "Epoch: 188\tTrain Loss: 1.5942107 \tVal Loss:1.2349796 \tTrain Acc: 48.68056% \tVal Acc: 63.0555555%\n",
      "Epoch: 189\tTrain Loss: 1.5484352 \tVal Loss:1.1869032 \tTrain Acc: 49.72222% \tVal Acc: 69.7222213%\n",
      "Validation Loss decreased from 1.232874 to 1.186903, saving the model weights\n",
      "Epoch: 190\tTrain Loss: 1.5301210 \tVal Loss:1.1386236 \tTrain Acc: 51.45833% \tVal Acc: 69.1666673%\n",
      "Validation Loss decreased from 1.186903 to 1.138624, saving the model weights\n",
      "Epoch: 191\tTrain Loss: 1.4794559 \tVal Loss:1.1348720 \tTrain Acc: 52.98611% \tVal Acc: 70.8333333%\n",
      "Validation Loss decreased from 1.138624 to 1.134872, saving the model weights\n",
      "Epoch: 192\tTrain Loss: 1.4452928 \tVal Loss:1.1225703 \tTrain Acc: 53.47222% \tVal Acc: 68.0555552%\n",
      "Validation Loss decreased from 1.134872 to 1.122570, saving the model weights\n",
      "Epoch: 193\tTrain Loss: 1.4794813 \tVal Loss:1.1227663 \tTrain Acc: 53.61111% \tVal Acc: 70.8333343%\n",
      "Epoch: 194\tTrain Loss: 1.5150350 \tVal Loss:1.1382303 \tTrain Acc: 50.90278% \tVal Acc: 68.6111117%\n",
      "Epoch: 195\tTrain Loss: 1.4660952 \tVal Loss:1.1592978 \tTrain Acc: 53.54167% \tVal Acc: 67.2222232%\n",
      "Epoch: 196\tTrain Loss: 1.5005040 \tVal Loss:1.2191019 \tTrain Acc: 53.05556% \tVal Acc: 64.7222211%\n",
      "Epoch: 197\tTrain Loss: 1.4838697 \tVal Loss:1.0873621 \tTrain Acc: 51.45833% \tVal Acc: 69.7222223%\n",
      "Validation Loss decreased from 1.122570 to 1.087362, saving the model weights\n",
      "Epoch: 198\tTrain Loss: 1.4616777 \tVal Loss:1.1024750 \tTrain Acc: 52.70833% \tVal Acc: 69.4444438%\n",
      "Epoch: 199\tTrain Loss: 1.4634009 \tVal Loss:1.0712647 \tTrain Acc: 52.43056% \tVal Acc: 69.1666653%\n",
      "Validation Loss decreased from 1.087362 to 1.071265, saving the model weights\n",
      "Epoch: 200\tTrain Loss: 1.4101238 \tVal Loss:1.0541930 \tTrain Acc: 55.83333% \tVal Acc: 68.6111103%\n",
      "Validation Loss decreased from 1.071265 to 1.054193, saving the model weights\n",
      "Epoch: 201\tTrain Loss: 1.3911942 \tVal Loss:1.0676765 \tTrain Acc: 56.31944% \tVal Acc: 69.9999998%\n",
      "Epoch: 202\tTrain Loss: 1.3937976 \tVal Loss:1.0158996 \tTrain Acc: 55.69444% \tVal Acc: 73.8888899%\n",
      "Validation Loss decreased from 1.054193 to 1.015900, saving the model weights\n",
      "Epoch: 203\tTrain Loss: 1.3683653 \tVal Loss:1.0283857 \tTrain Acc: 55.625% \tVal Acc: 71.3888884%\n",
      "Epoch: 204\tTrain Loss: 1.3518046 \tVal Loss:0.9907229 \tTrain Acc: 55.83333% \tVal Acc: 74.7222215%\n",
      "Validation Loss decreased from 1.015900 to 0.990723, saving the model weights\n",
      "Epoch: 205\tTrain Loss: 1.3852046 \tVal Loss:1.0283586 \tTrain Acc: 55.48611% \tVal Acc: 71.9444454%\n",
      "Epoch: 206\tTrain Loss: 1.3369881 \tVal Loss:0.9591364 \tTrain Acc: 57.5% \tVal Acc: 76.3888876%\n",
      "Validation Loss decreased from 0.990723 to 0.959136, saving the model weights\n",
      "Epoch: 207\tTrain Loss: 1.3440508 \tVal Loss:1.0531545 \tTrain Acc: 57.5% \tVal Acc: 67.5000002%\n",
      "Epoch: 208\tTrain Loss: 1.3624852 \tVal Loss:1.0752773 \tTrain Acc: 55.625% \tVal Acc: 71.1111108%\n",
      "Epoch: 209\tTrain Loss: 1.3491200 \tVal Loss:0.9697305 \tTrain Acc: 57.84722% \tVal Acc: 73.3333319%\n",
      "Epoch: 210\tTrain Loss: 1.2926779 \tVal Loss:0.9245494 \tTrain Acc: 59.375% \tVal Acc: 78.3333331%\n",
      "Validation Loss decreased from 0.959136 to 0.924549, saving the model weights\n",
      "Epoch: 211\tTrain Loss: 1.2486832 \tVal Loss:0.9239952 \tTrain Acc: 60.69444% \tVal Acc: 77.7777781%\n",
      "Validation Loss decreased from 0.924549 to 0.923995, saving the model weights\n",
      "Epoch: 212\tTrain Loss: 1.2292404 \tVal Loss:0.9000418 \tTrain Acc: 60.83333% \tVal Acc: 75.0000000%\n",
      "Validation Loss decreased from 0.923995 to 0.900042, saving the model weights\n",
      "Epoch: 213\tTrain Loss: 1.2612579 \tVal Loss:0.8918267 \tTrain Acc: 61.04167% \tVal Acc: 76.3888896%\n",
      "Validation Loss decreased from 0.900042 to 0.891827, saving the model weights\n",
      "Epoch: 214\tTrain Loss: 1.2564813 \tVal Loss:0.8989124 \tTrain Acc: 60.41667% \tVal Acc: 77.2222231%\n",
      "Epoch: 215\tTrain Loss: 1.3270526 \tVal Loss:0.9136334 \tTrain Acc: 59.16667% \tVal Acc: 78.3333341%\n",
      "Epoch: 216\tTrain Loss: 1.3004967 \tVal Loss:0.9129491 \tTrain Acc: 58.81944% \tVal Acc: 76.9444456%\n",
      "Epoch: 217\tTrain Loss: 1.2807548 \tVal Loss:0.8807719 \tTrain Acc: 60.27778% \tVal Acc: 76.3888905%\n",
      "Validation Loss decreased from 0.891827 to 0.880772, saving the model weights\n",
      "Epoch: 218\tTrain Loss: 1.2829288 \tVal Loss:0.8656635 \tTrain Acc: 59.86111% \tVal Acc: 80.5555562%\n",
      "Validation Loss decreased from 0.880772 to 0.865664, saving the model weights\n",
      "Epoch: 219\tTrain Loss: 1.2118978 \tVal Loss:0.8904787 \tTrain Acc: 62.70833% \tVal Acc: 77.2222231%\n",
      "Epoch: 220\tTrain Loss: 1.2251724 \tVal Loss:0.8648462 \tTrain Acc: 62.91667% \tVal Acc: 80.0000012%\n",
      "Validation Loss decreased from 0.865664 to 0.864846, saving the model weights\n",
      "Epoch: 221\tTrain Loss: 1.2517363 \tVal Loss:0.8200585 \tTrain Acc: 60.48611% \tVal Acc: 83.0555548%\n",
      "Validation Loss decreased from 0.864846 to 0.820058, saving the model weights\n",
      "Epoch: 222\tTrain Loss: 1.1999638 \tVal Loss:0.8154403 \tTrain Acc: 61.52778% \tVal Acc: 80.8333317%\n",
      "Validation Loss decreased from 0.820058 to 0.815440, saving the model weights\n",
      "Epoch: 223\tTrain Loss: 1.1899015 \tVal Loss:0.8317617 \tTrain Acc: 62.63889% \tVal Acc: 79.1666667%\n",
      "Epoch: 224\tTrain Loss: 1.1716036 \tVal Loss:0.8089473 \tTrain Acc: 62.63889% \tVal Acc: 80.2777777%\n",
      "Validation Loss decreased from 0.815440 to 0.808947, saving the model weights\n",
      "Epoch: 225\tTrain Loss: 1.1655693 \tVal Loss:0.7601379 \tTrain Acc: 62.56944% \tVal Acc: 80.8333317%\n",
      "Validation Loss decreased from 0.808947 to 0.760138, saving the model weights\n",
      "Epoch: 226\tTrain Loss: 1.1441331 \tVal Loss:0.7531756 \tTrain Acc: 63.19444% \tVal Acc: 83.6111108%\n",
      "Validation Loss decreased from 0.760138 to 0.753176, saving the model weights\n",
      "Epoch: 227\tTrain Loss: 1.0853780 \tVal Loss:0.7217255 \tTrain Acc: 68.68056% \tVal Acc: 81.9444438%\n",
      "Validation Loss decreased from 0.753176 to 0.721725, saving the model weights\n",
      "Epoch: 228\tTrain Loss: 1.0607708 \tVal Loss:0.6848556 \tTrain Acc: 68.26389% \tVal Acc: 83.8888894%\n",
      "Validation Loss decreased from 0.721725 to 0.684856, saving the model weights\n",
      "Epoch: 229\tTrain Loss: 1.0557942 \tVal Loss:0.6819169 \tTrain Acc: 67.01389% \tVal Acc: 83.6111118%\n",
      "Validation Loss decreased from 0.684856 to 0.681917, saving the model weights\n",
      "Epoch: 230\tTrain Loss: 1.0683920 \tVal Loss:0.6917766 \tTrain Acc: 67.43056% \tVal Acc: 84.4444444%\n",
      "Epoch: 231\tTrain Loss: 1.0592130 \tVal Loss:0.6851780 \tTrain Acc: 67.98611% \tVal Acc: 83.6111099%\n",
      "Epoch: 232\tTrain Loss: 1.0685934 \tVal Loss:0.7142068 \tTrain Acc: 67.5% \tVal Acc: 82.4999988%\n",
      "Epoch: 233\tTrain Loss: 1.1111387 \tVal Loss:0.8519230 \tTrain Acc: 65.55556% \tVal Acc: 75.8333335%\n",
      "Epoch: 234\tTrain Loss: 1.2130031 \tVal Loss:0.8087203 \tTrain Acc: 60.76389% \tVal Acc: 78.3333331%\n",
      "Epoch: 235\tTrain Loss: 1.2404860 \tVal Loss:0.8756090 \tTrain Acc: 59.93056% \tVal Acc: 74.1666675%\n",
      "Epoch: 236\tTrain Loss: 1.3063075 \tVal Loss:0.7495338 \tTrain Acc: 59.58333% \tVal Acc: 82.2222213%\n",
      "Epoch: 237\tTrain Loss: 1.1762427 \tVal Loss:0.7531040 \tTrain Acc: 65.13889% \tVal Acc: 82.2222213%\n",
      "Epoch: 238\tTrain Loss: 1.1176122 \tVal Loss:0.6724031 \tTrain Acc: 65.41667% \tVal Acc: 85.5555564%\n",
      "Validation Loss decreased from 0.681917 to 0.672403, saving the model weights\n",
      "Epoch: 239\tTrain Loss: 1.1074719 \tVal Loss:0.6840550 \tTrain Acc: 65.90278% \tVal Acc: 81.9444448%\n",
      "Epoch: 240\tTrain Loss: 1.0413202 \tVal Loss:0.6016325 \tTrain Acc: 68.40278% \tVal Acc: 86.6666675%\n",
      "Validation Loss decreased from 0.672403 to 0.601633, saving the model weights\n",
      "Epoch: 241\tTrain Loss: 0.9950655 \tVal Loss:0.6531721 \tTrain Acc: 69.51389% \tVal Acc: 85.5555564%\n",
      "Epoch: 242\tTrain Loss: 0.9867921 \tVal Loss:0.6339137 \tTrain Acc: 70.41667% \tVal Acc: 84.7222229%\n",
      "Epoch: 243\tTrain Loss: 0.9742256 \tVal Loss:0.5853646 \tTrain Acc: 69.51389% \tVal Acc: 86.1111114%\n",
      "Validation Loss decreased from 0.601633 to 0.585365, saving the model weights\n",
      "Epoch: 244\tTrain Loss: 0.9499117 \tVal Loss:0.5762386 \tTrain Acc: 71.31944% \tVal Acc: 86.6666665%\n",
      "Validation Loss decreased from 0.585365 to 0.576239, saving the model weights\n",
      "Epoch: 245\tTrain Loss: 0.9223406 \tVal Loss:0.5977219 \tTrain Acc: 71.66667% \tVal Acc: 85.0000004%\n",
      "Epoch: 246\tTrain Loss: 0.8978312 \tVal Loss:0.5355086 \tTrain Acc: 72.22222% \tVal Acc: 87.5000010%\n",
      "Validation Loss decreased from 0.576239 to 0.535509, saving the model weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 247\tTrain Loss: 0.9031240 \tVal Loss:0.5340395 \tTrain Acc: 73.47222% \tVal Acc: 87.2222225%\n",
      "Validation Loss decreased from 0.535509 to 0.534039, saving the model weights\n",
      "Epoch: 248\tTrain Loss: 0.8670259 \tVal Loss:0.5628681 \tTrain Acc: 74.65278% \tVal Acc: 86.9444460%\n",
      "Epoch: 249\tTrain Loss: 0.9138094 \tVal Loss:0.5201782 \tTrain Acc: 72.70833% \tVal Acc: 87.7777765%\n",
      "Validation Loss decreased from 0.534039 to 0.520178, saving the model weights\n",
      "Epoch: 250\tTrain Loss: 0.8801294 \tVal Loss:0.5276121 \tTrain Acc: 72.29167% \tVal Acc: 88.6111101%\n",
      "Epoch: 251\tTrain Loss: 0.8929895 \tVal Loss:0.5146815 \tTrain Acc: 73.125% \tVal Acc: 88.8888886%\n",
      "Validation Loss decreased from 0.520178 to 0.514681, saving the model weights\n",
      "Epoch: 252\tTrain Loss: 0.8552054 \tVal Loss:0.5163469 \tTrain Acc: 74.02778% \tVal Acc: 87.7777785%\n",
      "Epoch: 253\tTrain Loss: 0.8265047 \tVal Loss:0.4844210 \tTrain Acc: 76.73611% \tVal Acc: 89.7222221%\n",
      "Validation Loss decreased from 0.514681 to 0.484421, saving the model weights\n",
      "Epoch: 254\tTrain Loss: 0.8272580 \tVal Loss:0.4975987 \tTrain Acc: 76.25% \tVal Acc: 87.7777775%\n",
      "Epoch: 255\tTrain Loss: 0.8262513 \tVal Loss:0.4677462 \tTrain Acc: 75.76389% \tVal Acc: 89.9999986%\n",
      "Validation Loss decreased from 0.484421 to 0.467746, saving the model weights\n",
      "Epoch: 256\tTrain Loss: 0.8277346 \tVal Loss:0.4920484 \tTrain Acc: 74.30556% \tVal Acc: 87.5000000%\n",
      "Epoch: 257\tTrain Loss: 0.8738024 \tVal Loss:0.4631249 \tTrain Acc: 73.125% \tVal Acc: 90.2777781%\n",
      "Validation Loss decreased from 0.467746 to 0.463125, saving the model weights\n",
      "Epoch: 258\tTrain Loss: 0.8081837 \tVal Loss:0.4637571 \tTrain Acc: 76.11111% \tVal Acc: 89.4444436%\n",
      "Epoch: 259\tTrain Loss: 0.8316568 \tVal Loss:0.4868041 \tTrain Acc: 76.875% \tVal Acc: 87.5000000%\n",
      "Epoch: 260\tTrain Loss: 0.8356561 \tVal Loss:0.5033696 \tTrain Acc: 74.79167% \tVal Acc: 85.5555544%\n",
      "Epoch: 261\tTrain Loss: 0.7999908 \tVal Loss:0.4274916 \tTrain Acc: 76.04167% \tVal Acc: 91.1111106%\n",
      "Validation Loss decreased from 0.463125 to 0.427492, saving the model weights\n",
      "Epoch: 262\tTrain Loss: 0.7854864 \tVal Loss:0.4157742 \tTrain Acc: 76.73611% \tVal Acc: 91.6666667%\n",
      "Validation Loss decreased from 0.427492 to 0.415774, saving the model weights\n",
      "Epoch: 263\tTrain Loss: 0.7888251 \tVal Loss:0.4214044 \tTrain Acc: 76.80556% \tVal Acc: 92.5000002%\n",
      "Epoch: 264\tTrain Loss: 0.8157722 \tVal Loss:0.4539932 \tTrain Acc: 74.93056% \tVal Acc: 91.6666667%\n",
      "Epoch: 265\tTrain Loss: 0.8502290 \tVal Loss:0.4350880 \tTrain Acc: 74.65278% \tVal Acc: 90.5555546%\n",
      "Epoch: 266\tTrain Loss: 0.8153067 \tVal Loss:0.4318228 \tTrain Acc: 75.83333% \tVal Acc: 89.4444436%\n",
      "Epoch: 267\tTrain Loss: 0.8323158 \tVal Loss:0.4871149 \tTrain Acc: 74.30556% \tVal Acc: 87.4999990%\n",
      "Epoch: 268\tTrain Loss: 0.8754520 \tVal Loss:0.4582124 \tTrain Acc: 71.31944% \tVal Acc: 88.8888886%\n",
      "Epoch: 269\tTrain Loss: 0.7893928 \tVal Loss:0.3922452 \tTrain Acc: 76.11111% \tVal Acc: 91.9444442%\n",
      "Validation Loss decreased from 0.415774 to 0.392245, saving the model weights\n",
      "Epoch: 270\tTrain Loss: 0.7137315 \tVal Loss:0.3564446 \tTrain Acc: 80.27778% \tVal Acc: 92.2222227%\n",
      "Validation Loss decreased from 0.392245 to 0.356445, saving the model weights\n",
      "Epoch: 271\tTrain Loss: 0.7118593 \tVal Loss:0.3408599 \tTrain Acc: 80.69444% \tVal Acc: 93.3333317%\n",
      "Validation Loss decreased from 0.356445 to 0.340860, saving the model weights\n",
      "Epoch: 272\tTrain Loss: 0.6767880 \tVal Loss:0.3266411 \tTrain Acc: 80.34722% \tVal Acc: 93.3333327%\n",
      "Validation Loss decreased from 0.340860 to 0.326641, saving the model weights\n",
      "Epoch: 273\tTrain Loss: 0.6591563 \tVal Loss:0.3489333 \tTrain Acc: 81.80556% \tVal Acc: 92.2222217%\n",
      "Epoch: 274\tTrain Loss: 0.6767650 \tVal Loss:0.3886721 \tTrain Acc: 79.93056% \tVal Acc: 90.8333331%\n",
      "Epoch: 275\tTrain Loss: 0.7453714 \tVal Loss:0.3746489 \tTrain Acc: 77.01389% \tVal Acc: 91.6666677%\n",
      "Epoch: 276\tTrain Loss: 0.7092391 \tVal Loss:0.4298568 \tTrain Acc: 79.375% \tVal Acc: 88.6111120%\n",
      "Epoch: 277\tTrain Loss: 0.7374379 \tVal Loss:0.3576477 \tTrain Acc: 78.19444% \tVal Acc: 90.5555556%\n",
      "Epoch: 278\tTrain Loss: 0.6573397 \tVal Loss:0.3220196 \tTrain Acc: 81.94444% \tVal Acc: 92.7777767%\n",
      "Validation Loss decreased from 0.326641 to 0.322020, saving the model weights\n",
      "Epoch: 279\tTrain Loss: 0.6546486 \tVal Loss:0.3285331 \tTrain Acc: 81.25% \tVal Acc: 92.2222217%\n",
      "Epoch: 280\tTrain Loss: 0.6541857 \tVal Loss:0.3209843 \tTrain Acc: 80.41667% \tVal Acc: 93.0555552%\n",
      "Validation Loss decreased from 0.322020 to 0.320984, saving the model weights\n",
      "Epoch: 281\tTrain Loss: 0.6314049 \tVal Loss:0.3687274 \tTrain Acc: 82.98611% \tVal Acc: 88.8888896%\n",
      "Epoch: 282\tTrain Loss: 0.6564399 \tVal Loss:0.3057032 \tTrain Acc: 81.04167% \tVal Acc: 93.6111103%\n",
      "Validation Loss decreased from 0.320984 to 0.305703, saving the model weights\n",
      "Epoch: 283\tTrain Loss: 0.6283516 \tVal Loss:0.3015802 \tTrain Acc: 82.5% \tVal Acc: 93.3333327%\n",
      "Validation Loss decreased from 0.305703 to 0.301580, saving the model weights\n",
      "Epoch: 284\tTrain Loss: 0.6263293 \tVal Loss:0.2992848 \tTrain Acc: 81.875% \tVal Acc: 92.7777787%\n",
      "Validation Loss decreased from 0.301580 to 0.299285, saving the model weights\n",
      "Epoch: 285\tTrain Loss: 0.5943520 \tVal Loss:0.2950138 \tTrain Acc: 83.26389% \tVal Acc: 91.6666667%\n",
      "Validation Loss decreased from 0.299285 to 0.295014, saving the model weights\n",
      "Epoch: 286\tTrain Loss: 0.5777464 \tVal Loss:0.2735540 \tTrain Acc: 84.30556% \tVal Acc: 94.4444438%\n",
      "Validation Loss decreased from 0.295014 to 0.273554, saving the model weights\n",
      "Epoch: 287\tTrain Loss: 0.5630932 \tVal Loss:0.2608288 \tTrain Acc: 85.13889% \tVal Acc: 93.3333337%\n",
      "Validation Loss decreased from 0.273554 to 0.260829, saving the model weights\n",
      "Epoch: 288\tTrain Loss: 0.5587000 \tVal Loss:0.3047188 \tTrain Acc: 84.23611% \tVal Acc: 93.0555562%\n",
      "Epoch: 289\tTrain Loss: 0.5563430 \tVal Loss:0.2578577 \tTrain Acc: 85.625% \tVal Acc: 93.8888888%\n",
      "Validation Loss decreased from 0.260829 to 0.257858, saving the model weights\n",
      "Epoch: 290\tTrain Loss: 0.5389305 \tVal Loss:0.2453580 \tTrain Acc: 85.83333% \tVal Acc: 94.7222223%\n",
      "Validation Loss decreased from 0.257858 to 0.245358, saving the model weights\n",
      "Epoch: 291\tTrain Loss: 0.5163529 \tVal Loss:0.2555074 \tTrain Acc: 85.97222% \tVal Acc: 93.6111112%\n",
      "Epoch: 292\tTrain Loss: 0.5230534 \tVal Loss:0.2328909 \tTrain Acc: 86.18056% \tVal Acc: 94.7222213%\n",
      "Validation Loss decreased from 0.245358 to 0.232891, saving the model weights\n",
      "Epoch: 293\tTrain Loss: 0.5353520 \tVal Loss:0.2684155 \tTrain Acc: 84.23611% \tVal Acc: 92.2222227%\n",
      "Epoch: 294\tTrain Loss: 0.5434300 \tVal Loss:0.2598565 \tTrain Acc: 84.02778% \tVal Acc: 94.7222223%\n",
      "Epoch: 295\tTrain Loss: 0.5344360 \tVal Loss:0.2486634 \tTrain Acc: 83.88889% \tVal Acc: 93.6111103%\n",
      "Epoch: 296\tTrain Loss: 0.6168536 \tVal Loss:0.2801647 \tTrain Acc: 81.73611% \tVal Acc: 92.7777777%\n",
      "Epoch: 297\tTrain Loss: 0.6076157 \tVal Loss:0.3624613 \tTrain Acc: 82.08333% \tVal Acc: 91.1111106%\n",
      "Epoch: 298\tTrain Loss: 0.6148702 \tVal Loss:0.3475889 \tTrain Acc: 82.22222% \tVal Acc: 90.2777781%\n",
      "Epoch: 299\tTrain Loss: 0.6986948 \tVal Loss:0.4996921 \tTrain Acc: 79.375% \tVal Acc: 87.2222225%\n",
      "Epoch: 300\tTrain Loss: 0.8103049 \tVal Loss:0.4413006 \tTrain Acc: 74.375% \tVal Acc: 87.7777775%\n",
      "Epoch: 301\tTrain Loss: 0.7805461 \tVal Loss:0.3470866 \tTrain Acc: 75.13889% \tVal Acc: 89.7222231%\n",
      "Epoch: 302\tTrain Loss: 0.9477880 \tVal Loss:0.3405749 \tTrain Acc: 70.83333% \tVal Acc: 91.1111116%\n",
      "Epoch: 303\tTrain Loss: 0.7603267 \tVal Loss:0.3130243 \tTrain Acc: 76.11111% \tVal Acc: 92.7777777%\n",
      "Epoch: 304\tTrain Loss: 0.6687231 \tVal Loss:0.2644485 \tTrain Acc: 79.30556% \tVal Acc: 93.8888888%\n",
      "Epoch: 305\tTrain Loss: 0.5672881 \tVal Loss:0.2192209 \tTrain Acc: 82.36111% \tVal Acc: 94.9999998%\n",
      "Validation Loss decreased from 0.232891 to 0.219221, saving the model weights\n",
      "Epoch: 306\tTrain Loss: 0.5207475 \tVal Loss:0.2006223 \tTrain Acc: 85.69444% \tVal Acc: 95.5555558%\n",
      "Validation Loss decreased from 0.219221 to 0.200622, saving the model weights\n",
      "Epoch: 307\tTrain Loss: 0.4830141 \tVal Loss:0.1828924 \tTrain Acc: 85.625% \tVal Acc: 95.8333323%\n",
      "Validation Loss decreased from 0.200622 to 0.182892, saving the model weights\n",
      "Epoch: 308\tTrain Loss: 0.4351668 \tVal Loss:0.1825457 \tTrain Acc: 89.375% \tVal Acc: 95.8333323%\n",
      "Validation Loss decreased from 0.182892 to 0.182546, saving the model weights\n",
      "Epoch: 309\tTrain Loss: 0.4413358 \tVal Loss:0.1792972 \tTrain Acc: 87.98611% \tVal Acc: 96.3888884%\n",
      "Validation Loss decreased from 0.182546 to 0.179297, saving the model weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 310\tTrain Loss: 0.4609472 \tVal Loss:0.1722299 \tTrain Acc: 87.63889% \tVal Acc: 96.6666669%\n",
      "Validation Loss decreased from 0.179297 to 0.172230, saving the model weights\n",
      "Epoch: 311\tTrain Loss: 0.4370371 \tVal Loss:0.1620302 \tTrain Acc: 88.40278% \tVal Acc: 95.8333333%\n",
      "Validation Loss decreased from 0.172230 to 0.162030, saving the model weights\n",
      "Epoch: 312\tTrain Loss: 0.4178191 \tVal Loss:0.1572766 \tTrain Acc: 89.16667% \tVal Acc: 96.3888884%\n",
      "Validation Loss decreased from 0.162030 to 0.157277, saving the model weights\n",
      "Epoch: 313\tTrain Loss: 0.4091134 \tVal Loss:0.1572998 \tTrain Acc: 88.54167% \tVal Acc: 96.6666659%\n",
      "Epoch: 314\tTrain Loss: 0.3973325 \tVal Loss:0.1569738 \tTrain Acc: 90.34722% \tVal Acc: 96.3888884%\n",
      "Validation Loss decreased from 0.157277 to 0.156974, saving the model weights\n",
      "Epoch: 315\tTrain Loss: 0.3966141 \tVal Loss:0.1558762 \tTrain Acc: 89.23611% \tVal Acc: 96.3888884%\n",
      "Validation Loss decreased from 0.156974 to 0.155876, saving the model weights\n",
      "Epoch: 316\tTrain Loss: 0.3923648 \tVal Loss:0.1471501 \tTrain Acc: 90.625% \tVal Acc: 96.9444444%\n",
      "Validation Loss decreased from 0.155876 to 0.147150, saving the model weights\n",
      "Epoch: 317\tTrain Loss: 0.4240453 \tVal Loss:0.1882898 \tTrain Acc: 88.47222% \tVal Acc: 94.4444448%\n",
      "Epoch: 318\tTrain Loss: 0.4144529 \tVal Loss:0.1847974 \tTrain Acc: 89.65278% \tVal Acc: 95.2777773%\n",
      "Epoch: 319\tTrain Loss: 0.3867413 \tVal Loss:0.2303706 \tTrain Acc: 89.65278% \tVal Acc: 93.6111122%\n",
      "Epoch: 320\tTrain Loss: 0.3997256 \tVal Loss:0.1594938 \tTrain Acc: 89.79167% \tVal Acc: 94.7222213%\n",
      "Epoch: 321\tTrain Loss: 0.4132004 \tVal Loss:0.1908784 \tTrain Acc: 88.54167% \tVal Acc: 94.4444438%\n",
      "Epoch: 322\tTrain Loss: 0.4542458 \tVal Loss:0.1812225 \tTrain Acc: 86.45833% \tVal Acc: 95.5555558%\n",
      "Epoch: 323\tTrain Loss: 0.4229714 \tVal Loss:0.1397084 \tTrain Acc: 88.68056% \tVal Acc: 96.3888884%\n",
      "Validation Loss decreased from 0.147150 to 0.139708, saving the model weights\n",
      "Epoch: 324\tTrain Loss: 0.3891097 \tVal Loss:0.1350367 \tTrain Acc: 89.30556% \tVal Acc: 97.7777779%\n",
      "Validation Loss decreased from 0.139708 to 0.135037, saving the model weights\n",
      "Epoch: 325\tTrain Loss: 0.4160325 \tVal Loss:0.1460287 \tTrain Acc: 88.75% \tVal Acc: 96.9444444%\n",
      "Epoch: 326\tTrain Loss: 0.4243216 \tVal Loss:0.2024790 \tTrain Acc: 88.125% \tVal Acc: 93.6111112%\n",
      "Epoch: 327\tTrain Loss: 0.4082901 \tVal Loss:0.1616929 \tTrain Acc: 89.58333% \tVal Acc: 96.3888884%\n",
      "Epoch: 328\tTrain Loss: 0.3738623 \tVal Loss:0.1277169 \tTrain Acc: 90.20833% \tVal Acc: 96.9444454%\n",
      "Validation Loss decreased from 0.135037 to 0.127717, saving the model weights\n",
      "Epoch: 329\tTrain Loss: 0.3541786 \tVal Loss:0.1480721 \tTrain Acc: 90.83333% \tVal Acc: 95.5555558%\n",
      "Epoch: 330\tTrain Loss: 0.3520825 \tVal Loss:0.1171224 \tTrain Acc: 90.90278% \tVal Acc: 97.4999994%\n",
      "Validation Loss decreased from 0.127717 to 0.117122, saving the model weights\n",
      "Epoch: 331\tTrain Loss: 0.3339760 \tVal Loss:0.1290495 \tTrain Acc: 92.08333% \tVal Acc: 96.6666659%\n",
      "Epoch: 332\tTrain Loss: 0.3375445 \tVal Loss:0.1114479 \tTrain Acc: 91.11111% \tVal Acc: 97.5000004%\n",
      "Validation Loss decreased from 0.117122 to 0.111448, saving the model weights\n",
      "Epoch: 333\tTrain Loss: 0.3343607 \tVal Loss:0.1242768 \tTrain Acc: 91.94444% \tVal Acc: 96.3888884%\n",
      "Epoch: 334\tTrain Loss: 0.3205193 \tVal Loss:0.1159044 \tTrain Acc: 91.66667% \tVal Acc: 96.6666669%\n",
      "Epoch: 335\tTrain Loss: 0.3519247 \tVal Loss:0.1469903 \tTrain Acc: 91.11111% \tVal Acc: 96.1111118%\n",
      "Epoch: 336\tTrain Loss: 0.3851262 \tVal Loss:0.1369986 \tTrain Acc: 89.30556% \tVal Acc: 96.3888884%\n",
      "Epoch: 337\tTrain Loss: 0.3542697 \tVal Loss:0.1216089 \tTrain Acc: 90.48611% \tVal Acc: 97.4999994%\n",
      "Epoch: 338\tTrain Loss: 0.3380742 \tVal Loss:0.1260258 \tTrain Acc: 91.11111% \tVal Acc: 96.1111108%\n",
      "Epoch: 339\tTrain Loss: 0.3395662 \tVal Loss:0.2640130 \tTrain Acc: 90.76389% \tVal Acc: 91.6666677%\n",
      "Epoch: 340\tTrain Loss: 0.4066276 \tVal Loss:0.2347839 \tTrain Acc: 89.23611% \tVal Acc: 93.3333337%\n",
      "Epoch: 341\tTrain Loss: 0.5823456 \tVal Loss:0.3426650 \tTrain Acc: 81.94445% \tVal Acc: 87.7777775%\n",
      "Epoch: 342\tTrain Loss: 0.8130320 \tVal Loss:0.7554452 \tTrain Acc: 74.93056% \tVal Acc: 80.8333347%\n",
      "Epoch: 343\tTrain Loss: 1.2322445 \tVal Loss:1.1087377 \tTrain Acc: 64.44444% \tVal Acc: 65.0000011%\n",
      "Epoch: 344\tTrain Loss: 1.2557812 \tVal Loss:0.5907398 \tTrain Acc: 61.38889% \tVal Acc: 83.6111099%\n",
      "Epoch: 345\tTrain Loss: 0.9358481 \tVal Loss:0.6475970 \tTrain Acc: 70.90278% \tVal Acc: 78.8888882%\n",
      "Epoch: 346\tTrain Loss: 0.7683488 \tVal Loss:0.2562617 \tTrain Acc: 75.48611% \tVal Acc: 92.2222227%\n",
      "Epoch: 347\tTrain Loss: 0.6799515 \tVal Loss:0.2623136 \tTrain Acc: 79.23611% \tVal Acc: 93.0555562%\n",
      "Epoch: 348\tTrain Loss: 0.5332021 \tVal Loss:0.1762487 \tTrain Acc: 84.30555% \tVal Acc: 95.2777783%\n",
      "Epoch: 349\tTrain Loss: 0.4325398 \tVal Loss:0.1494710 \tTrain Acc: 87.56944% \tVal Acc: 95.5555558%\n",
      "Epoch: 350\tTrain Loss: 0.3633960 \tVal Loss:0.1398212 \tTrain Acc: 90.0% \tVal Acc: 95.8333323%\n",
      "Epoch: 351\tTrain Loss: 0.3543510 \tVal Loss:0.1250848 \tTrain Acc: 91.80556% \tVal Acc: 96.3888884%\n",
      "Epoch: 352\tTrain Loss: 0.3346177 \tVal Loss:0.1315186 \tTrain Acc: 91.38889% \tVal Acc: 95.5555548%\n",
      "Epoch: 353\tTrain Loss: 0.3366801 \tVal Loss:0.1088030 \tTrain Acc: 91.52778% \tVal Acc: 96.9444444%\n",
      "Validation Loss decreased from 0.111448 to 0.108803, saving the model weights\n",
      "Epoch: 354\tTrain Loss: 0.2974629 \tVal Loss:0.1046736 \tTrain Acc: 91.80556% \tVal Acc: 98.0555544%\n",
      "Validation Loss decreased from 0.108803 to 0.104674, saving the model weights\n",
      "Epoch: 355\tTrain Loss: 0.3000083 \tVal Loss:0.1031729 \tTrain Acc: 92.01389% \tVal Acc: 97.2222219%\n",
      "Validation Loss decreased from 0.104674 to 0.103173, saving the model weights\n",
      "Epoch: 356\tTrain Loss: 0.2836478 \tVal Loss:0.1625354 \tTrain Acc: 93.95833% \tVal Acc: 95.0000008%\n",
      "Epoch: 357\tTrain Loss: 0.2944542 \tVal Loss:0.1007038 \tTrain Acc: 92.5% \tVal Acc: 97.2222219%\n",
      "Validation Loss decreased from 0.103173 to 0.100704, saving the model weights\n",
      "Epoch: 358\tTrain Loss: 0.2978222 \tVal Loss:0.0828168 \tTrain Acc: 92.36111% \tVal Acc: 98.3333319%\n",
      "Validation Loss decreased from 0.100704 to 0.082817, saving the model weights\n",
      "Epoch: 359\tTrain Loss: 0.2876427 \tVal Loss:0.0782271 \tTrain Acc: 93.40278% \tVal Acc: 98.6111114%\n",
      "Validation Loss decreased from 0.082817 to 0.078227, saving the model weights\n",
      "Epoch: 360\tTrain Loss: 0.2788383 \tVal Loss:0.0817369 \tTrain Acc: 93.26389% \tVal Acc: 98.6111104%\n",
      "Epoch: 361\tTrain Loss: 0.2608601 \tVal Loss:0.0886300 \tTrain Acc: 93.75% \tVal Acc: 97.7777779%\n",
      "Epoch: 362\tTrain Loss: 0.2524663 \tVal Loss:0.0970001 \tTrain Acc: 94.30556% \tVal Acc: 96.9444444%\n",
      "Epoch: 363\tTrain Loss: 0.2595418 \tVal Loss:0.0919115 \tTrain Acc: 93.54167% \tVal Acc: 97.5000004%\n",
      "Epoch: 364\tTrain Loss: 0.2649859 \tVal Loss:0.0929649 \tTrain Acc: 94.44444% \tVal Acc: 97.2222219%\n",
      "Epoch: 365\tTrain Loss: 0.2694422 \tVal Loss:0.0897460 \tTrain Acc: 93.05556% \tVal Acc: 97.2222219%\n",
      "Epoch: 366\tTrain Loss: 0.2485587 \tVal Loss:0.1162079 \tTrain Acc: 93.33333% \tVal Acc: 96.3888884%\n",
      "Epoch: 367\tTrain Loss: 0.2787391 \tVal Loss:0.0846031 \tTrain Acc: 92.43056% \tVal Acc: 97.7777779%\n",
      "Epoch: 368\tTrain Loss: 0.2773154 \tVal Loss:0.0781577 \tTrain Acc: 92.5% \tVal Acc: 98.3333329%\n",
      "Validation Loss decreased from 0.078227 to 0.078158, saving the model weights\n",
      "Epoch: 369\tTrain Loss: 0.2642511 \tVal Loss:0.0706688 \tTrain Acc: 93.47222% \tVal Acc: 98.6111114%\n",
      "Validation Loss decreased from 0.078158 to 0.070669, saving the model weights\n",
      "Epoch: 370\tTrain Loss: 0.2470959 \tVal Loss:0.0738382 \tTrain Acc: 93.81944% \tVal Acc: 98.3333329%\n",
      "Epoch: 371\tTrain Loss: 0.2691886 \tVal Loss:0.0855930 \tTrain Acc: 93.40278% \tVal Acc: 98.0555544%\n",
      "Epoch: 372\tTrain Loss: 0.2607966 \tVal Loss:0.1240925 \tTrain Acc: 93.26389% \tVal Acc: 96.6666669%\n",
      "Epoch: 373\tTrain Loss: 0.2560413 \tVal Loss:0.0751513 \tTrain Acc: 93.05556% \tVal Acc: 98.0555554%\n",
      "Epoch: 374\tTrain Loss: 0.2313441 \tVal Loss:0.0711933 \tTrain Acc: 94.58333% \tVal Acc: 98.3333329%\n",
      "Epoch: 375\tTrain Loss: 0.2210486 \tVal Loss:0.0589549 \tTrain Acc: 94.79167% \tVal Acc: 98.6111104%\n",
      "Validation Loss decreased from 0.070669 to 0.058955, saving the model weights\n",
      "Epoch: 376\tTrain Loss: 0.2305712 \tVal Loss:0.0938363 \tTrain Acc: 94.09722% \tVal Acc: 96.9444444%\n",
      "Epoch: 377\tTrain Loss: 0.2484267 \tVal Loss:0.0758975 \tTrain Acc: 93.75% \tVal Acc: 98.0555554%\n",
      "Epoch: 378\tTrain Loss: 0.2280889 \tVal Loss:0.0815642 \tTrain Acc: 94.65278% \tVal Acc: 97.5000004%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 379\tTrain Loss: 0.2219430 \tVal Loss:0.0614991 \tTrain Acc: 94.02778% \tVal Acc: 98.6111114%\n",
      "Epoch: 380\tTrain Loss: 0.2165846 \tVal Loss:0.0589016 \tTrain Acc: 94.93055% \tVal Acc: 98.0555554%\n",
      "Validation Loss decreased from 0.058955 to 0.058902, saving the model weights\n",
      "Epoch: 381\tTrain Loss: 0.1999811 \tVal Loss:0.0603714 \tTrain Acc: 95.06944% \tVal Acc: 97.7777779%\n",
      "Epoch: 382\tTrain Loss: 0.2128002 \tVal Loss:0.0664045 \tTrain Acc: 94.44444% \tVal Acc: 97.7777779%\n",
      "Epoch: 383\tTrain Loss: 0.2083677 \tVal Loss:0.0935837 \tTrain Acc: 94.51389% \tVal Acc: 96.9444444%\n",
      "Epoch: 384\tTrain Loss: 0.2175467 \tVal Loss:0.0572125 \tTrain Acc: 95.0% \tVal Acc: 98.8888880%\n",
      "Validation Loss decreased from 0.058902 to 0.057213, saving the model weights\n",
      "Epoch: 385\tTrain Loss: 0.2021659 \tVal Loss:0.0582814 \tTrain Acc: 95.0% \tVal Acc: 98.3333329%\n",
      "Epoch: 386\tTrain Loss: 0.2061744 \tVal Loss:0.0589535 \tTrain Acc: 94.375% \tVal Acc: 98.3333319%\n",
      "Epoch: 387\tTrain Loss: 0.2045249 \tVal Loss:0.0751083 \tTrain Acc: 95.20833% \tVal Acc: 97.4999994%\n",
      "Epoch: 388\tTrain Loss: 0.1957083 \tVal Loss:0.0761793 \tTrain Acc: 95.55556% \tVal Acc: 96.9444434%\n",
      "Epoch: 389\tTrain Loss: 0.2089382 \tVal Loss:0.0987322 \tTrain Acc: 95.55556% \tVal Acc: 96.3888894%\n",
      "Epoch: 390\tTrain Loss: 0.2163487 \tVal Loss:0.0960211 \tTrain Acc: 95.0% \tVal Acc: 96.6666669%\n",
      "Epoch: 391\tTrain Loss: 0.2886972 \tVal Loss:0.0951404 \tTrain Acc: 91.73611% \tVal Acc: 97.4999994%\n",
      "Epoch: 392\tTrain Loss: 0.3203007 \tVal Loss:0.1184465 \tTrain Acc: 90.90278% \tVal Acc: 96.3888894%\n",
      "Epoch: 393\tTrain Loss: 0.3656542 \tVal Loss:0.1253018 \tTrain Acc: 89.16667% \tVal Acc: 95.5555558%\n",
      "Epoch: 394\tTrain Loss: 0.3723479 \tVal Loss:0.1257043 \tTrain Acc: 89.375% \tVal Acc: 96.3888884%\n",
      "Epoch: 395\tTrain Loss: 0.4107664 \tVal Loss:0.1212909 \tTrain Acc: 88.75% \tVal Acc: 96.1111108%\n",
      "Epoch: 396\tTrain Loss: 0.3807707 \tVal Loss:0.1123515 \tTrain Acc: 88.88889% \tVal Acc: 96.3888884%\n",
      "Epoch: 397\tTrain Loss: 0.4340128 \tVal Loss:0.1303084 \tTrain Acc: 88.33333% \tVal Acc: 96.6666659%\n",
      "Epoch: 398\tTrain Loss: 0.3633807 \tVal Loss:0.2407237 \tTrain Acc: 88.81944% \tVal Acc: 93.6111112%\n",
      "Epoch: 399\tTrain Loss: 0.5370269 \tVal Loss:0.7996068 \tTrain Acc: 84.65278% \tVal Acc: 78.8888882%\n",
      "Epoch: 400\tTrain Loss: 0.6439400 \tVal Loss:0.2029694 \tTrain Acc: 80.83333% \tVal Acc: 94.4444458%\n",
      "Epoch: 401\tTrain Loss: 0.4252159 \tVal Loss:0.1332691 \tTrain Acc: 87.29167% \tVal Acc: 95.8333333%\n",
      "Epoch: 402\tTrain Loss: 0.3211018 \tVal Loss:0.1063703 \tTrain Acc: 91.04167% \tVal Acc: 96.9444434%\n",
      "Epoch: 403\tTrain Loss: 0.3083656 \tVal Loss:0.0908190 \tTrain Acc: 91.18056% \tVal Acc: 97.5000004%\n",
      "Epoch: 404\tTrain Loss: 0.3074052 \tVal Loss:0.0771221 \tTrain Acc: 91.45833% \tVal Acc: 98.0555554%\n",
      "Epoch: 405\tTrain Loss: 0.2442840 \tVal Loss:0.1060587 \tTrain Acc: 93.33333% \tVal Acc: 96.9444444%\n",
      "Epoch: 406\tTrain Loss: 0.2339269 \tVal Loss:0.0683136 \tTrain Acc: 94.30556% \tVal Acc: 98.0555554%\n",
      "Epoch: 407\tTrain Loss: 0.2225036 \tVal Loss:0.0641383 \tTrain Acc: 94.58333% \tVal Acc: 97.7777769%\n",
      "Epoch: 408\tTrain Loss: 0.2226203 \tVal Loss:0.0735976 \tTrain Acc: 93.81944% \tVal Acc: 97.7777779%\n",
      "Epoch: 409\tTrain Loss: 0.2099591 \tVal Loss:0.0624279 \tTrain Acc: 95.06944% \tVal Acc: 97.7777769%\n",
      "Epoch: 410\tTrain Loss: 0.2097502 \tVal Loss:0.0496473 \tTrain Acc: 94.375% \tVal Acc: 98.6111114%\n",
      "Validation Loss decreased from 0.057213 to 0.049647, saving the model weights\n",
      "Epoch: 411\tTrain Loss: 0.1906444 \tVal Loss:0.0497378 \tTrain Acc: 95.27778% \tVal Acc: 98.3333329%\n",
      "Epoch: 412\tTrain Loss: 0.1776893 \tVal Loss:0.0467485 \tTrain Acc: 95.69444% \tVal Acc: 98.6111104%\n",
      "Validation Loss decreased from 0.049647 to 0.046749, saving the model weights\n",
      "Epoch: 413\tTrain Loss: 0.1679371 \tVal Loss:0.0482288 \tTrain Acc: 96.875% \tVal Acc: 98.3333329%\n",
      "Epoch: 414\tTrain Loss: 0.1686476 \tVal Loss:0.0637411 \tTrain Acc: 96.45833% \tVal Acc: 97.4999994%\n",
      "Epoch: 415\tTrain Loss: 0.1835382 \tVal Loss:0.0970118 \tTrain Acc: 95.0% \tVal Acc: 96.9444444%\n",
      "Epoch: 416\tTrain Loss: 0.2060034 \tVal Loss:0.0480602 \tTrain Acc: 94.58333% \tVal Acc: 98.3333329%\n",
      "Epoch: 417\tTrain Loss: 0.1849061 \tVal Loss:0.0406848 \tTrain Acc: 95.625% \tVal Acc: 98.6111114%\n",
      "Validation Loss decreased from 0.046749 to 0.040685, saving the model weights\n",
      "Epoch: 418\tTrain Loss: 0.1621547 \tVal Loss:0.0410376 \tTrain Acc: 95.97222% \tVal Acc: 98.6111104%\n",
      "Epoch: 419\tTrain Loss: 0.1727986 \tVal Loss:0.0435275 \tTrain Acc: 96.18055% \tVal Acc: 98.3333329%\n",
      "Epoch: 420\tTrain Loss: 0.1473075 \tVal Loss:0.0467203 \tTrain Acc: 96.66667% \tVal Acc: 98.3333319%\n",
      "Epoch: 421\tTrain Loss: 0.1554619 \tVal Loss:0.0959471 \tTrain Acc: 96.11111% \tVal Acc: 97.2222219%\n",
      "Epoch: 422\tTrain Loss: 0.1658883 \tVal Loss:0.0612862 \tTrain Acc: 96.18056% \tVal Acc: 98.3333329%\n",
      "Epoch: 423\tTrain Loss: 0.1885197 \tVal Loss:0.0521833 \tTrain Acc: 95.34722% \tVal Acc: 98.3333329%\n",
      "Epoch: 424\tTrain Loss: 0.1917340 \tVal Loss:0.0537049 \tTrain Acc: 94.58333% \tVal Acc: 98.0555554%\n",
      "Epoch: 425\tTrain Loss: 0.1849397 \tVal Loss:0.0431286 \tTrain Acc: 95.34722% \tVal Acc: 98.6111104%\n",
      "Epoch: 426\tTrain Loss: 0.1611755 \tVal Loss:0.0447290 \tTrain Acc: 96.45833% \tVal Acc: 98.6111114%\n",
      "Epoch: 427\tTrain Loss: 0.1755001 \tVal Loss:0.0372736 \tTrain Acc: 95.55556% \tVal Acc: 99.1666665%\n",
      "Validation Loss decreased from 0.040685 to 0.037274, saving the model weights\n",
      "Epoch: 428\tTrain Loss: 0.1565481 \tVal Loss:0.0337543 \tTrain Acc: 96.31944% \tVal Acc: 98.8888890%\n",
      "Validation Loss decreased from 0.037274 to 0.033754, saving the model weights\n",
      "Epoch: 429\tTrain Loss: 0.1527827 \tVal Loss:0.0432951 \tTrain Acc: 96.04167% \tVal Acc: 98.0555554%\n",
      "Epoch: 430\tTrain Loss: 0.1553580 \tVal Loss:0.0399621 \tTrain Acc: 95.90278% \tVal Acc: 98.8888890%\n",
      "Epoch: 431\tTrain Loss: 0.1342851 \tVal Loss:0.0437407 \tTrain Acc: 97.43056% \tVal Acc: 98.6111114%\n",
      "Epoch: 432\tTrain Loss: 0.1422526 \tVal Loss:0.0974122 \tTrain Acc: 96.875% \tVal Acc: 96.6666659%\n",
      "Epoch: 433\tTrain Loss: 0.1618389 \tVal Loss:0.1149592 \tTrain Acc: 96.11111% \tVal Acc: 96.9444444%\n",
      "Epoch: 434\tTrain Loss: 0.1752494 \tVal Loss:0.0852345 \tTrain Acc: 95.55556% \tVal Acc: 97.2222219%\n",
      "Epoch: 435\tTrain Loss: 0.1471780 \tVal Loss:0.0758338 \tTrain Acc: 96.875% \tVal Acc: 97.4999994%\n",
      "Epoch: 436\tTrain Loss: 0.1456671 \tVal Loss:0.0650261 \tTrain Acc: 96.94444% \tVal Acc: 97.5000004%\n",
      "Epoch: 437\tTrain Loss: 0.1475385 \tVal Loss:0.0528208 \tTrain Acc: 96.18056% \tVal Acc: 98.6111104%\n",
      "Epoch: 438\tTrain Loss: 0.1569557 \tVal Loss:0.0402487 \tTrain Acc: 95.97222% \tVal Acc: 98.8888890%\n",
      "Epoch: 439\tTrain Loss: 0.1657420 \tVal Loss:0.0365769 \tTrain Acc: 95.97222% \tVal Acc: 99.1666675%\n",
      "Epoch: 440\tTrain Loss: 0.1552028 \tVal Loss:0.0578209 \tTrain Acc: 96.04167% \tVal Acc: 98.0555564%\n",
      "Epoch: 441\tTrain Loss: 0.1992276 \tVal Loss:0.0823513 \tTrain Acc: 95.41667% \tVal Acc: 96.6666669%\n",
      "Epoch: 442\tTrain Loss: 0.2177296 \tVal Loss:0.0781630 \tTrain Acc: 93.54167% \tVal Acc: 97.2222219%\n",
      "Epoch: 443\tTrain Loss: 0.1879373 \tVal Loss:0.0552824 \tTrain Acc: 95.97222% \tVal Acc: 98.0555554%\n",
      "Epoch: 444\tTrain Loss: 0.1769619 \tVal Loss:0.0394323 \tTrain Acc: 95.20833% \tVal Acc: 98.8888890%\n",
      "Epoch: 445\tTrain Loss: 0.1453174 \tVal Loss:0.0355498 \tTrain Acc: 96.94444% \tVal Acc: 98.8888890%\n",
      "Epoch: 446\tTrain Loss: 0.1335624 \tVal Loss:0.0457072 \tTrain Acc: 96.80556% \tVal Acc: 98.3333339%\n",
      "Epoch: 447\tTrain Loss: 0.1341082 \tVal Loss:0.0632039 \tTrain Acc: 96.80556% \tVal Acc: 97.5000004%\n",
      "Epoch: 448\tTrain Loss: 0.1556198 \tVal Loss:0.0382610 \tTrain Acc: 96.66667% \tVal Acc: 98.8888890%\n",
      "Epoch: 449\tTrain Loss: 0.1249341 \tVal Loss:0.0303011 \tTrain Acc: 97.36111% \tVal Acc: 99.1666665%\n",
      "Validation Loss decreased from 0.033754 to 0.030301, saving the model weights\n",
      "Epoch: 450\tTrain Loss: 0.1267087 \tVal Loss:0.0303823 \tTrain Acc: 96.80556% \tVal Acc: 98.8888890%\n",
      "Epoch: 451\tTrain Loss: 0.1262303 \tVal Loss:0.0346204 \tTrain Acc: 97.15278% \tVal Acc: 98.3333339%\n",
      "Epoch: 452\tTrain Loss: 0.1205321 \tVal Loss:0.1415016 \tTrain Acc: 96.94444% \tVal Acc: 96.9444444%\n",
      "Epoch: 453\tTrain Loss: 0.1555152 \tVal Loss:0.0978163 \tTrain Acc: 96.80556% \tVal Acc: 97.2222209%\n",
      "Epoch: 454\tTrain Loss: 0.1555689 \tVal Loss:0.0738636 \tTrain Acc: 95.83333% \tVal Acc: 97.4999994%\n",
      "Epoch: 455\tTrain Loss: 0.1470162 \tVal Loss:0.0601439 \tTrain Acc: 95.97222% \tVal Acc: 97.5000004%\n",
      "Epoch: 456\tTrain Loss: 0.1559285 \tVal Loss:0.0614040 \tTrain Acc: 96.18055% \tVal Acc: 97.5000004%\n",
      "Epoch: 457\tTrain Loss: 0.1736319 \tVal Loss:0.0560879 \tTrain Acc: 95.625% \tVal Acc: 98.0555564%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 458\tTrain Loss: 0.1716879 \tVal Loss:0.0445458 \tTrain Acc: 95.55556% \tVal Acc: 98.6111114%\n",
      "Epoch: 459\tTrain Loss: 0.1544534 \tVal Loss:0.0486715 \tTrain Acc: 96.31944% \tVal Acc: 98.3333329%\n",
      "Epoch: 460\tTrain Loss: 0.1642503 \tVal Loss:0.0474413 \tTrain Acc: 96.18056% \tVal Acc: 98.3333329%\n",
      "Epoch: 461\tTrain Loss: 0.1576049 \tVal Loss:0.0371984 \tTrain Acc: 95.625% \tVal Acc: 99.1666665%\n",
      "Epoch: 462\tTrain Loss: 0.1803226 \tVal Loss:0.0490276 \tTrain Acc: 94.79167% \tVal Acc: 97.7777779%\n",
      "Epoch: 463\tTrain Loss: 0.1853967 \tVal Loss:0.0435055 \tTrain Acc: 95.13889% \tVal Acc: 98.8888880%\n",
      "Epoch: 464\tTrain Loss: 0.1876464 \tVal Loss:0.0554841 \tTrain Acc: 94.58333% \tVal Acc: 98.3333319%\n",
      "Epoch: 465\tTrain Loss: 0.1857163 \tVal Loss:0.0618164 \tTrain Acc: 95.41667% \tVal Acc: 96.6666669%\n",
      "Epoch: 466\tTrain Loss: 0.2076410 \tVal Loss:0.0542204 \tTrain Acc: 94.375% \tVal Acc: 97.7777769%\n",
      "Epoch: 467\tTrain Loss: 0.2012300 \tVal Loss:0.0743779 \tTrain Acc: 94.30556% \tVal Acc: 97.2222219%\n",
      "Epoch: 468\tTrain Loss: 0.1650022 \tVal Loss:0.0336019 \tTrain Acc: 95.97222% \tVal Acc: 99.1666675%\n",
      "Epoch: 469\tTrain Loss: 0.1596308 \tVal Loss:0.0480904 \tTrain Acc: 95.06944% \tVal Acc: 97.7777779%\n",
      "Epoch: 470\tTrain Loss: 0.1618783 \tVal Loss:0.0690609 \tTrain Acc: 95.90278% \tVal Acc: 97.7777779%\n",
      "Epoch: 471\tTrain Loss: 0.1810108 \tVal Loss:0.0746313 \tTrain Acc: 95.41667% \tVal Acc: 97.5000004%\n",
      "Epoch: 472\tTrain Loss: 0.1413587 \tVal Loss:0.0472977 \tTrain Acc: 96.66667% \tVal Acc: 98.0555564%\n",
      "Epoch: 473\tTrain Loss: 0.1353462 \tVal Loss:0.0351166 \tTrain Acc: 97.15278% \tVal Acc: 98.6111114%\n",
      "Epoch: 474\tTrain Loss: 0.1220783 \tVal Loss:0.0293334 \tTrain Acc: 97.08333% \tVal Acc: 99.4444450%\n",
      "Validation Loss decreased from 0.030301 to 0.029333, saving the model weights\n",
      "Epoch: 475\tTrain Loss: 0.1113598 \tVal Loss:0.0303441 \tTrain Acc: 97.22222% \tVal Acc: 99.1666665%\n",
      "Epoch: 476\tTrain Loss: 0.1240330 \tVal Loss:0.0857527 \tTrain Acc: 97.29167% \tVal Acc: 97.2222219%\n",
      "Epoch: 477\tTrain Loss: 0.1413396 \tVal Loss:0.0559002 \tTrain Acc: 96.31944% \tVal Acc: 98.0555554%\n",
      "Epoch: 478\tTrain Loss: 0.1373071 \tVal Loss:0.0298553 \tTrain Acc: 96.45833% \tVal Acc: 99.1666675%\n",
      "Epoch: 479\tTrain Loss: 0.1233825 \tVal Loss:0.0325898 \tTrain Acc: 97.29167% \tVal Acc: 98.8888890%\n",
      "Epoch: 480\tTrain Loss: 0.1210080 \tVal Loss:0.0395500 \tTrain Acc: 97.08333% \tVal Acc: 98.3333329%\n",
      "Epoch: 481\tTrain Loss: 0.1413349 \tVal Loss:0.0992581 \tTrain Acc: 95.83333% \tVal Acc: 96.6666679%\n",
      "Epoch: 482\tTrain Loss: 0.2795769 \tVal Loss:0.5336022 \tTrain Acc: 92.01389% \tVal Acc: 85.8333329%\n",
      "Epoch: 483\tTrain Loss: 0.5608678 \tVal Loss:0.8145051 \tTrain Acc: 84.65278% \tVal Acc: 74.1666675%\n",
      "Epoch: 484\tTrain Loss: 0.9884953 \tVal Loss:1.5676654 \tTrain Acc: 72.01389% \tVal Acc: 58.0555548%\n",
      "Epoch: 485\tTrain Loss: 1.2054231 \tVal Loss:0.4393666 \tTrain Acc: 67.84722% \tVal Acc: 86.1111124%\n",
      "Epoch: 486\tTrain Loss: 1.5324922 \tVal Loss:0.8179283 \tTrain Acc: 61.66667% \tVal Acc: 75.8333340%\n",
      "Epoch: 487\tTrain Loss: 1.5903825 \tVal Loss:0.8212797 \tTrain Acc: 55.625% \tVal Acc: 75.5555550%\n",
      "Epoch: 488\tTrain Loss: 1.0935240 \tVal Loss:0.2153384 \tTrain Acc: 67.29167% \tVal Acc: 93.3333327%\n",
      "Epoch: 489\tTrain Loss: 0.6228521 \tVal Loss:0.1546931 \tTrain Acc: 80.69444% \tVal Acc: 94.1666673%\n",
      "Epoch: 490\tTrain Loss: 0.4271098 \tVal Loss:0.1167495 \tTrain Acc: 87.29167% \tVal Acc: 96.9444444%\n",
      "Epoch: 491\tTrain Loss: 0.3082933 \tVal Loss:0.0666554 \tTrain Acc: 90.69444% \tVal Acc: 97.7777769%\n",
      "Epoch: 492\tTrain Loss: 0.2313167 \tVal Loss:0.0533118 \tTrain Acc: 93.125% \tVal Acc: 98.3333329%\n",
      "Epoch: 493\tTrain Loss: 0.1982280 \tVal Loss:0.0474930 \tTrain Acc: 94.58333% \tVal Acc: 98.6111114%\n",
      "Epoch: 494\tTrain Loss: 0.1829032 \tVal Loss:0.0430368 \tTrain Acc: 96.18056% \tVal Acc: 98.8888880%\n",
      "Epoch: 495\tTrain Loss: 0.1647145 \tVal Loss:0.0415921 \tTrain Acc: 95.69444% \tVal Acc: 98.6111104%\n",
      "Epoch: 496\tTrain Loss: 0.1681450 \tVal Loss:0.0375737 \tTrain Acc: 95.48611% \tVal Acc: 98.6111104%\n",
      "Epoch: 497\tTrain Loss: 0.1692595 \tVal Loss:0.0363207 \tTrain Acc: 95.83333% \tVal Acc: 98.8888890%\n",
      "Epoch: 498\tTrain Loss: 0.1527617 \tVal Loss:0.0353342 \tTrain Acc: 96.18056% \tVal Acc: 98.8888890%\n",
      "Epoch: 499\tTrain Loss: 0.1414229 \tVal Loss:0.0348780 \tTrain Acc: 96.31944% \tVal Acc: 98.6111114%\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "min_val_loss = np.Inf\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    train_accuracy = 0\n",
    "    val_accuracy = 0\n",
    "    \n",
    "    \n",
    "    hidden1, hidden2 = model.hidden_init(train_batch_size)    \n",
    "    #print('hidden[0].shape:- ',hidden[0].shape)\n",
    "    \n",
    "    for inputs,labels in train_loader:\n",
    "        #print(inputs.shape)\n",
    "\n",
    "        '''\n",
    "        Creating new variables for the hidden state, otherwise\n",
    "        we'd backprop through the entire training history\n",
    "        '''\n",
    "        #h = tuple([each.data for each in hidden])\n",
    "        h1 = tuple([each.data for each in hidden1])\n",
    "        h2 = tuple([each.data for each in hidden2])\n",
    "        \n",
    "        # zero accumulated gradients\n",
    "        model.zero_grad()\n",
    "       \n",
    "        # get the output from the model\n",
    "        output, h = model.forward(inputs, h1, h2, train_batch_size)\n",
    "        #print('OUTPUT', output)\n",
    "        \n",
    "        \n",
    "        #print('Labels Shape :-', (torch.max(labels, 1)[1]).shape)\n",
    "    \n",
    "        # calculate the loss and perform backprop\n",
    "        #print('Labels Long :-', labels.long())\n",
    "        loss = criterion(output,labels.long())\n",
    "        #print('LOSS IS :-', loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #calculate training accuracy\n",
    "        output = F.softmax(output, dim = 1)\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "        #logging.debug(' top probab {} top class {}'.format(top_p.view(-1, top_p.shape[0]), top_class.view(-1, top_p.shape[0])))\n",
    "\n",
    "        equals = top_class == labels.long().view(*top_class.shape)\n",
    "        train_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        \n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        #nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        #print(train_loss)\n",
    "              \n",
    "    model.eval()\n",
    "    for inputs, labels in val_loader:\n",
    "                \n",
    "        val_h1 = tuple([each.data for each in hidden1])\n",
    "        val_h2 = tuple([each.data for each in hidden2])\n",
    "        \n",
    "        output, hidden = model.forward(inputs, val_h1, val_h2,val_batch_size)\n",
    "       \n",
    "        loss = criterion(output,labels.long())\n",
    "        \n",
    "        val_loss += loss.item()\n",
    "        \n",
    "        #calculate validation accuracy\n",
    "        output = F.softmax(output, dim = 1)\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "        \n",
    "        #logging.debug(output)\n",
    "        #logging.debug('VALIDATION top probab {} VALIDATION top class {}'.format(top_p.view(-1, top_p.shape[0]), top_class.view(-1, top_p.shape[0])))\n",
    "\n",
    "        #print('Top Class:- ',top_class)\n",
    "        equals = top_class == labels.long().view(*top_class.shape)\n",
    "        #print('Equals:- ', equals)\n",
    "        val_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    #Averaging losses\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    val_loss = val_loss/len(val_loader)\n",
    "    val_accuracy = val_accuracy/len(val_loader)\n",
    "    train_accuracy = train_accuracy/len(train_loader)\n",
    "    \n",
    "    print('Epoch: {}\\tTrain Loss: {:.7f} \\tVal Loss:{:.7f} \\tTrain Acc: {:.7}% \\tVal Acc: {:.7f}%'.format(e, train_loss, val_loss, train_accuracy*100,val_accuracy*100))\n",
    "    \n",
    "    #saving the model if validation loss is decreased\n",
    "    if val_loss <= min_val_loss:\n",
    "        print('Validation Loss decreased from {:6f} to {:6f}, saving the model weights'.format(min_val_loss, val_loss))\n",
    "        torch.save(model.state_dict(), 'lstm_state_256_different_layers.pt')\n",
    "        min_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUSIC GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stacked_LSTM(\n",
       "  (lstm1): LSTM(1, 256, batch_first=True)\n",
       "  (lstm2): LSTM(256, 38, batch_first=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=38, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights\n",
    "test_model = Stacked_LSTM(input_size,hidden_size,num_layer,output_size)\n",
    "test_model.load_state_dict(torch.load('lstm_state_256_different_layers.pt'))\n",
    "test_model.eval()\n",
    "test_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load population database\n",
    "#testing_data = np.ones(200)*0\n",
    "testing_data = list(range(50,90))\n",
    "testing_data.extend(testing_data[::-1])\n",
    "testing_data = np.asarray(testing_data)\n",
    "testing_data = testing_data.reshape(testing_data.shape[0],1)\n",
    "\n",
    "initial_seq = [network_input[0][1:].cpu().numpy().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting\n",
    "def prediction_with_influence(influence,int2note,initial_seq, max_note, test_batch_size = 1):\n",
    "\n",
    "    predicted_notes = []\n",
    "    initial_seq[0].extend([[0]]*len(testing_data))\n",
    "    test_seq = torch.Tensor(initial_seq).cuda()\n",
    "    \n",
    "    h1, h2 = test_model.hidden_init(test_batch_size)\n",
    "\n",
    "    \n",
    "    for i in range(len(influence)):\n",
    "        \n",
    "        test_seq[0][sequence_length - 1 + i][0] = float(influence[i])\n",
    "        \n",
    "        test_slice = test_seq[0][i : i + sequence_length]        \n",
    "        test_slice = test_slice.view(1, test_slice.shape[0], test_slice.shape[1])\n",
    "                \n",
    "        test_hidden1 = tuple([each.data for each in h1])\n",
    "        test_hidden2 = tuple([each.data for each in h2])\n",
    "        \n",
    "        test_output,_ = test_model.forward(test_slice, test_hidden1, test_hidden2, test_batch_size)\n",
    "    \n",
    "        test_output = F.softmax(test_output, dim = 1)\n",
    "        top_p, top_class = test_output.topk(1,dim =1)\n",
    "        test_seq[0][sequence_length - 1 + i][0] = int2note[top_class.item()]/max_note\n",
    "        \n",
    "        predicted_notes.append(int2note[top_class.item()])\n",
    "        \n",
    "    return predicted_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_notes_lst = prediction_with_influence(testing_data,int_to_note,initial_seq, max_midi_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_notes_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26d8cf37048>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 369
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(list(np.ones(200)*89))\n",
    "#plt.plot(list(np.ones(200)*50))\n",
    "plt.plot(testing_data)\n",
    "plt.plot(predicted_notes_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({85: 1, 84: 4, 86: 75})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter(predicted_notes_lst)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
